{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74d243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Student Names + (IDs): \n",
    "\n",
    "Abdelrahman Mohamed Kamal Abdelaziz (1220255)\n",
    "Mazen Ahmed Fouad Abdelwahab (1220269)\n",
    "Mohamed Hesham Ibrahim Hassanain (1220278)\n",
    "Ahmed Walaa Abdlelkhalek Abdelrahman (1220216)\n",
    "\n",
    "'''\n",
    "#Import(s)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "import cv2\n",
    "from skimage.feature import canny\n",
    "from skimage.color import rgb2gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c595dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images,titles=None):\n",
    "    n_ims = len(images)\n",
    "    if titles is None: titles = ['(%d)' % i for i in range(1,n_ims + 1)]\n",
    "    fig = plt.figure()\n",
    "    n = 1\n",
    "    for image,title in zip(images,titles):\n",
    "        a = fig.add_subplot(1,n_ims,n)\n",
    "        if image.ndim == 2: \n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "        n += 1\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_ims)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9664472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plate Localization\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Path1 = 'Localization Test/One Step All Angles No Headlights/Straight.jpeg'\n",
    "Path2 = 'Localization Test/Two Step All Angles No Headlights/Straight.jpeg'\n",
    "Path3 = 'Localization Test/Three Step All Angles No Headlights/Straight.jpeg'\n",
    "Path4 = 'Localization Test/One Step All Angles With Headlights/Straight.jpeg'\n",
    "Path5 = 'Localization Test/Two Step All Angles With Headlights/Straight.jpeg'\n",
    "\n",
    "Path11 = 'Localization Test/One Step All Angles No Headlights/Elevated.jpeg'\n",
    "Path12 = 'Localization Test/Two Step All Angles No Headlights/Elevated.jpeg'\n",
    "Path13 = 'Localization Test/Three Step All Angles No Headlights/Elevated.jpeg'\n",
    "Path14 = 'Localization Test/One Step All Angles With Headlights/Elevated.jpeg'\n",
    "Path15 = 'Localization Test/Two Step All Angles With Headlights/Elevated.jpeg'\n",
    "\n",
    "Path111 = 'Localization Test/One Step All Angles No Headlights/Slight Right.jpeg'\n",
    "Path112 = 'Localization Test/Two Step All Angles No Headlights/Slight Right.jpeg'\n",
    "Path113 = 'Localization Test/Three Step All Angles No Headlights/Slight Right.jpeg'\n",
    "\n",
    "Path1111 = 'Localization Test/One Step All Angles No Headlights/Slight Left.jpeg'\n",
    "Path1112 = 'Localization Test/Two Step All Angles No Headlights/Slight Left.jpeg'\n",
    "Path1113 = 'Localization Test/Three Step All Angles No Headlights/Slight Left.jpeg'\n",
    "Path1114 = 'Localization Test/One Step All Angles With Headlights/Left.jpeg'\n",
    "\n",
    "Path11111 = 'Localization Test/One Step All Angles No Headlights/Extreme Left.jpeg'\n",
    "Path11112 = 'Localization Test/One Step All Angles No Headlights/Extreme Right.jpeg'\n",
    "Path11113 = 'Localization Test/Two Step All Angles No Headlights/Extreme Left.jpeg'\n",
    "Path11114 = 'Localization Test/Two Step All Angles No Headlights/Extreme Right.jpeg'\n",
    "Path11115 = 'Localization Test/Three Step All Angles No Headlights/Extreme Left.jpeg'\n",
    "Path11116 = 'Localization Test/Three Step All Angles No Headlights/Extreme Right.jpeg'\n",
    "   \n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def Plate_Detection(image_path):\n",
    "\n",
    "    # Original Image\n",
    "    Original_Img = io.imread(image_path)[:,:,:3]\n",
    "    Height, Width, _ = Original_Img.shape\n",
    "\n",
    "    # Read Image and convert to grayscale\n",
    "    img = cv2.imread(image_path)[:,:,:3]\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply CLAHE to improve local contrast\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    gray_clahe = clahe.apply(gray)\n",
    "\n",
    "    # Apply Gaussian Blur to reduce noise\n",
    "    gray_blur = cv2.GaussianBlur(gray_clahe, (5,5), 0)\n",
    "\n",
    "    # Adaptive Thresholding to handle dark and bright regions\n",
    "    thresh = cv2.adaptiveThreshold(gray_blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 19, 9)\n",
    "\n",
    "    # Morphological closing to connect fragmented regions\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "    morph = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    plate_candidates = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        aspect_ratio = w / h\n",
    "        area_ratio = (w * h) / (Height * Width)\n",
    "        if (1.8 < aspect_ratio < 3.7) and (0.01 < area_ratio < 0.3):\n",
    "            plate_candidates.append((x, y, w, h))\n",
    "\n",
    "    if not plate_candidates:\n",
    "        print(\"No plate candidate found.\")\n",
    "        return None\n",
    "\n",
    "    # Choose the best candidate\n",
    "    Best_Score = -1\n",
    "    Best_Candidate = None\n",
    "\n",
    "    for (x, y, w, h) in plate_candidates:\n",
    "\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "        Current_Image = Original_Img[y:y+h, x:x+w]\n",
    "\n",
    "        # --- Edge Density ---\n",
    "        CannyEdges = canny(rgb2gray(Current_Image), sigma=1.0)\n",
    "        edge_ratio = np.count_nonzero(CannyEdges) / (h * w)\n",
    "\n",
    "        # --- Color / brightness variance ---\n",
    "        # use brightness (mean over channels) as a simple measure\n",
    "        brightness = Current_Image.mean(axis=2)\n",
    "        brightness_var = np.var(brightness)\n",
    "\n",
    "        # show_images([Current_Image], [f\"Candidate Plate Edge Ratio: {edge_ratio:.4f} , Brightness Var: {brightness_var:.4f}\"])\n",
    "\n",
    "        # --- Combined score ---\n",
    "        # Edge density is still the main factor, color helps down-weight bad ones\n",
    "        score = brightness_var\n",
    "\n",
    "        if score > Best_Score:\n",
    "            Best_Score = score\n",
    "            Best_Candidate = (x, y, w, h)\n",
    "\n",
    "\n",
    "    # Crop the best candidate\n",
    "    x, y, w, h = Best_Candidate\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    # show_images([img], [\"Best Plate Candidate\"])\n",
    "    plate_img = Original_Img[y:y+h, x:x+w] \n",
    "    \n",
    "    return plate_img\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "# Testing the Plate Detection Function on Different Images\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Origignal_Img1 = io.imread(Path1)\n",
    "Detected_Plate1 = Plate_Detection(Path1)\n",
    "if Detected_Plate1 is not None:\n",
    "    show_images([Origignal_Img1, Detected_Plate1], [\"One Step No Headlights\", \"Plate Image\"])\n",
    "\n",
    "Origignal_Img2 = io.imread(Path2)\n",
    "Detected_Plate2 = Plate_Detection(Path2)\n",
    "if Detected_Plate2 is not None:\n",
    "    show_images([Origignal_Img2, Detected_Plate2], [\"Two Steps No Headlights\", \"Plate Image\"])\n",
    "\n",
    "Origignal_Img3 = io.imread(Path3)\n",
    "Detected_Plate3 = Plate_Detection(Path3)\n",
    "if Detected_Plate3 is not None:\n",
    "    show_images([Origignal_Img3, Detected_Plate3], [\"Three Steps No Headlights\", \"Plate Image\"])\n",
    "\n",
    "Origignal_Img4 = io.imread(Path4)\n",
    "Detected_Plate4 = Plate_Detection(Path4)\n",
    "if Detected_Plate4 is not None:\n",
    "    show_images([Origignal_Img4, Detected_Plate4], [\"One Step Headlights\", \"Plate Image\"])\n",
    "\n",
    "Origignal_Img5 = io.imread(Path5)\n",
    "Detected_Plate5 = Plate_Detection(Path5)\n",
    "if Detected_Plate5 is not None:\n",
    "    show_images([Origignal_Img5, Detected_Plate5], [\"Two Steps Headlights\", \"Plate Image\"])\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Origignal_Img11 = io.imread(Path11)\n",
    "Detected_Plate11 = Plate_Detection(Path11)\n",
    "if Detected_Plate11 is not None:\n",
    "    show_images([Origignal_Img11, Detected_Plate11], [\"One Step Elevated No Headlights\", \"Plate Image\"]) \n",
    "\n",
    "Origignal_Img12 = io.imread(Path12)\n",
    "Detected_Plate12 = Plate_Detection(Path12)\n",
    "if Detected_Plate12 is not None:\n",
    "    show_images([Origignal_Img12, Detected_Plate12], [\"Two Step Elevated No Headlights\", \"Plate Image\"])\n",
    "\n",
    "Origignal_Img13 = io.imread(Path13)\n",
    "Detected_Plate13 = Plate_Detection(Path13)\n",
    "if Detected_Plate13 is not None:\n",
    "    show_images([Origignal_Img13, Detected_Plate13], [\"Three Step Elevated No Headlights\", \"Plate Image\"])\n",
    "\n",
    "Origignal_Img14 = io.imread(Path14)\n",
    "Detected_Plate14 = Plate_Detection(Path14) \n",
    "if Detected_Plate14 is not None:\n",
    "    show_images([Origignal_Img14, Detected_Plate14], [\"One Step Elevated Headlights\", \"Plate Image\"])\n",
    "\n",
    "Origignal_Img15 = io.imread(Path15)\n",
    "Detected_Plate15 = Plate_Detection(Path15)  \n",
    "if Detected_Plate15 is not None:\n",
    "    show_images([Origignal_Img15, Detected_Plate15], [\"Two Step Elevated Headlights\", \"Plate Image\"])\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Origignal_Img111 = io.imread(Path111)\n",
    "Detected_Plate111 = Plate_Detection(Path111)\n",
    "if Detected_Plate111 is not None:\n",
    "    show_images([Origignal_Img111, Detected_Plate111], [\"One Step Slight Right No Headlights\", \"Plate Image\"])\n",
    "\n",
    "Origignal_Img112 = io.imread(Path112)\n",
    "Detected_Plate112 = Plate_Detection(Path112)\n",
    "if Detected_Plate112 is not None:\n",
    "    show_images([Origignal_Img112, Detected_Plate112], [\"Two Step Slight Right No Headlights\", \"Plate Image\"])\n",
    "\n",
    "Origignal_Img113 = io.imread(Path113)\n",
    "Detected_Plate113 = Plate_Detection(Path113)\n",
    "if Detected_Plate113 is not None:\n",
    "    show_images([Origignal_Img113, Detected_Plate113], [\"Three Step Slight Right No Headlights\", \"Plate Image\"])\n",
    "\n",
    "# Origignal_Img114 = io.imread(Path114)\n",
    "# Detected_Plate114 = Plate_Detection(Path114)\n",
    "# if Detected_Plate114 is not None:\n",
    "#     show_images([Origignal_Img114, Detected_Plate114], [\"One Step Slight Right Headlights\", \"Plate Image\"])\n",
    "\n",
    "# Origignal_Img115 = io.imread(Path115)\n",
    "# Detected_Plate115 = Plate_Detection(Path115)\n",
    "# if Detected_Plate115 is not None:\n",
    "#     show_images([Origignal_Img115, Detected_Plate115], [\"Two Step Slight Right Headlights\", \"Plate Image\"])\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Origignal_Img1111 = io.imread(Path1111)\n",
    "Detected_Plate1111 = Plate_Detection(Path1111)\n",
    "if Detected_Plate1111 is not None:\n",
    "    show_images([Origignal_Img1111, Detected_Plate1111], [\"One Step Slight Left No Headlights\", \"Plate Image\"])\n",
    "\n",
    "Origignal_Img1112 = io.imread(Path1112)\n",
    "Detected_Plate1112 = Plate_Detection(Path1112)\n",
    "if Detected_Plate1112 is not None:\n",
    "    show_images([Origignal_Img1112, Detected_Plate1112], [\"Two Step Slight Left No Headlights\", \"Plate Image\"])\n",
    "\n",
    "Origignal_Img1113 = io.imread(Path1113)\n",
    "Detected_Plate1113 = Plate_Detection(Path1113)\n",
    "if Detected_Plate1113 is not None:\n",
    "    show_images([Origignal_Img1113, Detected_Plate1113], [\"Three Step Slight Left No Headlights\", \"Plate Image\"])\n",
    "\n",
    "Origignal_Img1114 = io.imread(Path1114)\n",
    "Detected_Plate1114 = Plate_Detection(Path1114)\n",
    "if Detected_Plate1114 is not None:\n",
    "    show_images([Origignal_Img1114, Detected_Plate1114], [\"One Step Slight Left Headlights\", \"Plate Image\"])\n",
    "\n",
    "# Origignal_Img1115 = io.imread(Path1115)\n",
    "# Detected_Plate1115 = Plate_Detection(Path1115)\n",
    "# if Detected_Plate1115 is not None:\n",
    "#     show_images([Origignal_Img1115, Detected_Plate1115], [\"Two Step Slight Left Headlights\", \"Plate Image\"])\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Original_Img11111 = io.imread(Path11111)\n",
    "Detected_Plate11111 = Plate_Detection(Path11111)\n",
    "if Detected_Plate11111 is not None:\n",
    "    show_images([Original_Img11111, Detected_Plate11111], [\"One Step Extreme Left No Headlights\", \"Plate Image\"])\n",
    "\n",
    "Original_Img11112 = io.imread(Path11112)\n",
    "Detected_Plate11112 = Plate_Detection(Path11112)\n",
    "if Detected_Plate11112 is not None:\n",
    "    show_images([Original_Img11112, Detected_Plate11112], [\"One Step Extreme Right No Headlights\", \"Plate Image\"])\n",
    "\n",
    "Original_Img11113 = io.imread(Path11113)\n",
    "Detected_Plate11113 = Plate_Detection(Path11113)\n",
    "if Detected_Plate11113 is not None:\n",
    "    show_images([Original_Img11113, Detected_Plate11113], [\"Two Step Extreme Left No Headlights\", \"Plate Image\"])\n",
    "\n",
    "Original_Img11114 = io.imread(Path11114)\n",
    "Detected_Plate11114 = Plate_Detection(Path11114)\n",
    "if Detected_Plate11114 is not None:\n",
    "    show_images([Original_Img11114, Detected_Plate11114], [\"Two Step Extreme Right No Headlights\", \"Plate Image\"])\n",
    "\n",
    "Original_Img11115 = io.imread(Path11115)\n",
    "Detected_Plate11115 = Plate_Detection(Path11115)\n",
    "if Detected_Plate11115 is not None:\n",
    "    show_images([Original_Img11115, Detected_Plate11115], [\"Three Step Extreme Left No Headlights\", \"Plate Image\"])\n",
    "\n",
    "Original_Img11116 = io.imread(Path11116)\n",
    "Detected_Plate11116 = Plate_Detection(Path11116)\n",
    "if Detected_Plate11116 is not None:\n",
    "    show_images([Original_Img11116, Detected_Plate11116], [\"Three Step Extreme Right No Headlights\", \"Plate Image\"])\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Original_Img11117 = io.imread('trella.png')[:,:,:3]\n",
    "Detected_Plate11117 = Plate_Detection('trella.png')\n",
    "if Detected_Plate11117 is not None:\n",
    "    show_images([Original_Img11117, Detected_Plate11117], [\"Trella\", \"Plate Image\"])\n",
    "\n",
    "# import os\n",
    "\n",
    "# BASE_PATH = \"Localization Test/Vehicles\"\n",
    "\n",
    "# START_ID = 1\n",
    "# END_ID   = 2087\n",
    "\n",
    "# for i in range(START_ID, END_ID + 1):\n",
    "#     fname = f\"{i:04d}.jpg\"        # 0001.jpg, 0002.jpg, ...\n",
    "#     fpath = os.path.join(BASE_PATH, fname)\n",
    "\n",
    "#     if not os.path.exists(fpath):\n",
    "#         print(f\"[SKIP] Missing: {fpath}\")\n",
    "#         continue\n",
    "\n",
    "#     try:\n",
    "#         img = io.imread(fpath)    # RGB (as you want)\n",
    "#         title = f\"Vehicle_{fname}\"\n",
    "#         print(f\"[RUN] {title}\")\n",
    "#         Detected_Plate11116=Plate_Detection(fpath)\n",
    "#         if Detected_Plate11116 is not None:\n",
    "#             show_images([img, Detected_Plate11116], [\"img\", \"detect\"])\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"[ERROR] {fname}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59edabab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def strip_corners_from_mask_edges(comp01, debug=False):\n",
    "    \"\"\"\n",
    "    comp01: binary mask (H,W) of ONLY the strip component (0/1 or 0/255)\n",
    "    Returns: (4,2) float32 corners in FULL image coords:\n",
    "             [tl, tr, br, bl]  (already ordered)\n",
    "    \"\"\"\n",
    "\n",
    "    comp = (comp01 > 0)\n",
    "    H, W = comp.shape\n",
    "\n",
    "    ys, xs = np.where(comp)\n",
    "    if xs.size < 30:\n",
    "        return None\n",
    "\n",
    "    # x-span where the strip exists\n",
    "    x_left  = int(np.percentile(xs, 2))\n",
    "    x_right = int(np.percentile(xs, 98))\n",
    "    if x_right <= x_left + 5:\n",
    "        return None\n",
    "\n",
    "    # For each x, find top and bottom y in that column\n",
    "    top_pts = []\n",
    "    bot_pts = []\n",
    "\n",
    "    for x in range(x_left, x_right + 1):\n",
    "        col = np.where(comp[:, x])[0]\n",
    "        if col.size == 0:\n",
    "            continue\n",
    "        top_pts.append([x, float(col[0])])      # smallest y\n",
    "        bot_pts.append([x, float(col[-1])])     # largest y\n",
    "\n",
    "    top_pts = np.array(top_pts, dtype=np.float32)\n",
    "    bot_pts = np.array(bot_pts, dtype=np.float32)\n",
    "\n",
    "    if top_pts.shape[0] < 20 or bot_pts.shape[0] < 20:\n",
    "        return None\n",
    "\n",
    "    # robust trimming to ignore jagged ends / noise\n",
    "    def _trim_points(pts, keep=0.80):\n",
    "        n = pts.shape[0]\n",
    "        k0 = int((1.0-keep)*0.5*n)\n",
    "        k1 = int(n - k0)\n",
    "        return pts[k0:k1]\n",
    "\n",
    "    top_pts = _trim_points(top_pts, keep=0.80)\n",
    "    bot_pts = _trim_points(bot_pts, keep=0.80)\n",
    "\n",
    "    # Fit y = a*x + b using least squares (cv2.fitLine is OK too, but keep it simple)\n",
    "    def _fit_line_y(ax_pts):\n",
    "        x = ax_pts[:, 0]\n",
    "        y = ax_pts[:, 1]\n",
    "        A = np.stack([x, np.ones_like(x)], axis=1)\n",
    "        a, b = np.linalg.lstsq(A, y, rcond=None)[0]\n",
    "        return float(a), float(b)\n",
    "\n",
    "    a_top, b_top = _fit_line_y(top_pts)\n",
    "    a_bot, b_bot = _fit_line_y(bot_pts)\n",
    "\n",
    "    # Evaluate at x_left/x_right\n",
    "    tl = np.array([x_left,  a_top*x_left  + b_top], dtype=np.float32)\n",
    "    tr = np.array([x_right, a_top*x_right + b_top], dtype=np.float32)\n",
    "    bl = np.array([x_left,  a_bot*x_left  + b_bot], dtype=np.float32)\n",
    "    br = np.array([x_right, a_bot*x_right + b_bot], dtype=np.float32)\n",
    "\n",
    "    quad = np.array([tl, tr, br, bl], dtype=np.float32)\n",
    "\n",
    "    # sanity: clamp y into image\n",
    "    quad[:, 1] = np.clip(quad[:, 1], 0, H-1)\n",
    "\n",
    "    # final order (safe)\n",
    "    quad = _order_quad_tl_tr_br_bl(quad)\n",
    "\n",
    "    if debug:\n",
    "        area = abs(cv2.contourArea(quad))\n",
    "        print(f\"[mask-edge corners] xL={x_left} xR={x_right} area={area:.1f} \"\n",
    "              f\"top: y={tl[1]:.1f}->{tr[1]:.1f}, bot: y={bl[1]:.1f}->{br[1]:.1f}\")\n",
    "\n",
    "    return quad\n",
    "\n",
    "\n",
    "def cv2_getPerspectiveTransform_like(src_pts, dst_pts):\n",
    "    \"\"\"\n",
    "    Drop-in replacement for cv2.getPerspectiveTransform(src, dst)\n",
    "    where src and dst are (4,2).\n",
    "\n",
    "    Returns:\n",
    "        H (3,3) float64\n",
    "    \"\"\"\n",
    "    src = np.asarray(src_pts, dtype=np.float64).reshape(4, 2)\n",
    "    dst = np.asarray(dst_pts, dtype=np.float64).reshape(4, 2)\n",
    "\n",
    "    # Solve for homography with h33 = 1\n",
    "    A = np.zeros((8, 8), dtype=np.float64)\n",
    "    b = np.zeros((8,), dtype=np.float64)\n",
    "\n",
    "    for i in range(4):\n",
    "        x, y = src[i]\n",
    "        u, v = dst[i]\n",
    "\n",
    "        # u = (h11*x + h12*y + h13) / (h31*x + h32*y + 1)\n",
    "        A[2*i, 0] = x\n",
    "        A[2*i, 1] = y\n",
    "        A[2*i, 2] = 1\n",
    "        A[2*i, 6] = -u * x\n",
    "        A[2*i, 7] = -u * y\n",
    "        b[2*i] = u\n",
    "\n",
    "        # v = (h21*x + h22*y + h23) / (h31*x + h32*y + 1)\n",
    "        A[2*i+1, 3] = x\n",
    "        A[2*i+1, 4] = y\n",
    "        A[2*i+1, 5] = 1\n",
    "        A[2*i+1, 6] = -v * x\n",
    "        A[2*i+1, 7] = -v * y\n",
    "        b[2*i+1] = v\n",
    "\n",
    "    p = np.linalg.solve(A, b)\n",
    "\n",
    "    H = np.array([\n",
    "        [p[0], p[1], p[2]],\n",
    "        [p[3], p[4], p[5]],\n",
    "        [p[6], p[7], 1.0]\n",
    "    ], dtype=np.float64)\n",
    "\n",
    "    return H\n",
    "\n",
    "\n",
    "def _replicate_index(i, n):\n",
    "    if i < 0:\n",
    "        return 0\n",
    "    if i >= n:\n",
    "        return n - 1\n",
    "    return i\n",
    "\n",
    "\n",
    "def cv2_warpPerspective_like(img, H, dsize, flags=None, borderMode=None, borderValue=0):\n",
    "    \"\"\"\n",
    "    Drop-in replacement for cv2.warpPerspective(img, H, dsize, flags=..., borderMode=...)\n",
    "\n",
    "    Implements:\n",
    "      - inverse mapping (like OpenCV default)\n",
    "      - INTER_LINEAR\n",
    "      - BORDER_REPLICATE\n",
    "\n",
    "    Args:\n",
    "      img: (H,W) or (H,W,C)\n",
    "      H: (3,3) homography mapping src->dst (like cv2)\n",
    "      dsize: (outW, outH)\n",
    "      flags: ignored except assumed INTER_LINEAR\n",
    "      borderMode: ignored except assumed BORDER_REPLICATE\n",
    "    \"\"\"\n",
    "    src = np.asarray(img)\n",
    "    outW, outH = int(dsize[0]), int(dsize[1])\n",
    "\n",
    "    Hm = np.asarray(H, dtype=np.float64)\n",
    "    Hinv = np.linalg.inv(Hm)  # OpenCV does inverse mapping internally\n",
    "\n",
    "    inH, inW = src.shape[:2]\n",
    "    hasC = (src.ndim == 3)\n",
    "    C = src.shape[2] if hasC else 1\n",
    "\n",
    "    # work in float for interpolation, then cast back\n",
    "    src_f = src.astype(np.float64)\n",
    "\n",
    "    if not hasC:\n",
    "        out = np.empty((outH, outW), dtype=np.float64)\n",
    "    else:\n",
    "        out = np.empty((outH, outW, C), dtype=np.float64)\n",
    "\n",
    "    # For speed: precompute row terms that depend on v\n",
    "    for v in range(outH):\n",
    "        # These are coefficients for u in numerator/denom\n",
    "        a0 = Hinv[0, 0]\n",
    "        a1 = Hinv[0, 1] * v + Hinv[0, 2]\n",
    "        b0 = Hinv[1, 0]\n",
    "        b1 = Hinv[1, 1] * v + Hinv[1, 2]\n",
    "        c0 = Hinv[2, 0]\n",
    "        c1 = Hinv[2, 1] * v + Hinv[2, 2]\n",
    "\n",
    "        for u in range(outW):\n",
    "            denom = c0 * u + c1\n",
    "            if denom == 0:\n",
    "                # replicate border -> clamp to nearest valid (choose 0,0)\n",
    "                if not hasC:\n",
    "                    out[v, u] = src_f[0, 0]\n",
    "                else:\n",
    "                    out[v, u, :] = src_f[0, 0, :]\n",
    "                continue\n",
    "\n",
    "            x = (a0 * u + a1) / denom\n",
    "            y = (b0 * u + b1) / denom\n",
    "\n",
    "            # bilinear sampling with BORDER_REPLICATE\n",
    "            x0 = int(np.floor(x))\n",
    "            y0 = int(np.floor(y))\n",
    "            x1 = x0 + 1\n",
    "            y1 = y0 + 1\n",
    "\n",
    "            ax = x - x0\n",
    "            ay = y - y0\n",
    "\n",
    "            x0c = _replicate_index(x0, inW)\n",
    "            x1c = _replicate_index(x1, inW)\n",
    "            y0c = _replicate_index(y0, inH)\n",
    "            y1c = _replicate_index(y1, inH)\n",
    "\n",
    "            if not hasC:\n",
    "                p00 = src_f[y0c, x0c]\n",
    "                p10 = src_f[y0c, x1c]\n",
    "                p01 = src_f[y1c, x0c]\n",
    "                p11 = src_f[y1c, x1c]\n",
    "\n",
    "                top = (1 - ax) * p00 + ax * p10\n",
    "                bot = (1 - ax) * p01 + ax * p11\n",
    "                out[v, u] = (1 - ay) * top + ay * bot\n",
    "            else:\n",
    "                p00 = src_f[y0c, x0c, :]\n",
    "                p10 = src_f[y0c, x1c, :]\n",
    "                p01 = src_f[y1c, x0c, :]\n",
    "                p11 = src_f[y1c, x1c, :]\n",
    "\n",
    "                top = (1 - ax) * p00 + ax * p10\n",
    "                bot = (1 - ax) * p01 + ax * p11\n",
    "                out[v, u, :] = (1 - ay) * top + ay * bot\n",
    "\n",
    "    # cast back to original dtype like cv2\n",
    "    if np.issubdtype(src.dtype, np.integer):\n",
    "        info = np.iinfo(src.dtype)\n",
    "        out = np.clip(out, info.min, info.max).astype(src.dtype)\n",
    "    else:\n",
    "        out = out.astype(src.dtype)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "#  DEBUG VIEW\n",
    "# ================================================================\n",
    "def _show_mask_debug(mask, title):\n",
    "    plt.figure(figsize=(4, 2))\n",
    "    plt.imshow(mask, cmap=\"gray\")\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# ======================================================================\n",
    "#  HELPER: draw candidate rectangles on debug image\n",
    "# ======================================================================\n",
    "def draw_candidates_debug(img, candidates, best_idx):\n",
    "    debug_img = img.copy()\n",
    "\n",
    "    for i, c in enumerate(candidates):\n",
    "        color = (0,255,0) if i==best_idx else \\\n",
    "                (random.randint(50,255), random.randint(50,255), random.randint(50,255))\n",
    "\n",
    "        x0, y0, x1, y1 = c[\"x0\"], c[\"y0\"], c[\"x1\"], c[\"y1\"]\n",
    "        cv2.rectangle(debug_img, (x0,y0), (x1,y1), color, 2)\n",
    "        cv2.putText(debug_img, f\"{c['score']:.2f}\", (x0, y0-4),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "\n",
    "    return debug_img\n",
    "\n",
    "def _order_quad_tl_tr_br_bl(pts4):\n",
    "    pts = np.array(pts4, dtype=np.float32)\n",
    "    s = pts.sum(axis=1)              # x+y\n",
    "    d = pts[:,0] - pts[:,1]          # x-y\n",
    "    tl = pts[np.argmin(s)]\n",
    "    br = pts[np.argmax(s)]\n",
    "    tr = pts[np.argmax(d)]\n",
    "    bl = pts[np.argmin(d)]\n",
    "    return np.array([tl, tr, br, bl], dtype=np.float32)\n",
    "\n",
    "def deskew_stage2B_strip_perspective_if_needed(\n",
    "    img_rgb,\n",
    "    strip_corners_xy,     # 4x2 corners IN img_rgb coords\n",
    "    debug=False,\n",
    "    trap_ratio_thr=0.08,  # how trapezoid before we apply\n",
    "    min_strip_area=80.0   # ignore tiny / unstable quads\n",
    "):\n",
    "    \"\"\"\n",
    "    Stage 2B: Projective correction using ONLY the 4 corners of the blue strip.\n",
    "    Returns dict with 'rgb' and 'did_apply'.\n",
    "    \"\"\"\n",
    "\n",
    "    if strip_corners_xy is None:\n",
    "        return {\"rgb\": img_rgb, \"did_apply\": False, \"reason\": \"no_corners\"}\n",
    "\n",
    "    quad = np.array(strip_corners_xy, dtype=np.float32)\n",
    "    if quad.shape != (4, 2):\n",
    "        return {\"rgb\": img_rgb, \"did_apply\": False, \"reason\": \"bad_shape\"}\n",
    "\n",
    "    quad = _order_quad_tl_tr_br_bl(quad)\n",
    "\n",
    "    # quick sanity: area of quad\n",
    "    area = float(abs(cv2.contourArea(quad)))\n",
    "    if area < min_strip_area:\n",
    "        return {\"rgb\": img_rgb, \"did_apply\": False, \"reason\": \"tiny_quad\"}\n",
    "\n",
    "    tl, tr, br, bl = quad\n",
    "\n",
    "    def _dist(a, b):\n",
    "        return float(np.hypot(a[0]-b[0], a[1]-b[1]))\n",
    "\n",
    "    top_w    = _dist(tl, tr)\n",
    "    bot_w    = _dist(bl, br)\n",
    "    left_h   = _dist(tl, bl)\n",
    "    right_h  = _dist(tr, br)\n",
    "\n",
    "    # trapezoid-ness measures (1.0 is perfect rectangle)\n",
    "    w_ratio = (top_w + 1e-6) / (bot_w + 1e-6)\n",
    "    h_ratio = (left_h + 1e-6) / (right_h + 1e-6)\n",
    "\n",
    "    need = (abs(w_ratio - 1.0) > trap_ratio_thr) or (abs(h_ratio - 1.0) > trap_ratio_thr)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"[2B] area={area:.1f} top/bot={w_ratio:.3f} left/right={h_ratio:.3f} -> apply={need}\")\n",
    "\n",
    "    if not need:\n",
    "        return {\"rgb\": img_rgb, \"did_apply\": False, \"reason\": \"already_rect\"}\n",
    "\n",
    "    # target rectangle size based on measured strip size\n",
    "    dst_w = int(max(top_w, bot_w))\n",
    "    dst_h = int(max(left_h, right_h))\n",
    "    dst_w = max(dst_w, 10)\n",
    "    dst_h = max(dst_h, 6)\n",
    "\n",
    "    dst = np.array([\n",
    "        [0,      0],\n",
    "        [dst_w-1,0],\n",
    "        [dst_w-1,dst_h-1],\n",
    "        [0,      dst_h-1]\n",
    "    ], dtype=np.float32)\n",
    "    Himg, Wimg = img_rgb.shape[:2]\n",
    "    Hm = cv2_getPerspectiveTransform_like(quad, dst)\n",
    "    warped = cv2_warpPerspective_like(img_rgb, Hm, (Wimg, Himg))   #,flags=cv2.INTER_LINEAR,borderMode=cv2.BORDER_REPLICATE    HERE !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    return {\"rgb\": warped, \"did_apply\": True, \"reason\": \"warped\"}\n",
    "\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "#  TIERS\n",
    "# ================================================================\n",
    "BLUE_PARAMS_STRICT = dict(BLUE_SAT_THRESH=140, BLUE_VAL_THRESH=110, BLUE_HUE_MIN=80, BLUE_HUE_MAX=120, BLUE_DELTA=12)\n",
    "BLUE_PARAMS_MID    = dict(BLUE_SAT_THRESH=115, BLUE_VAL_THRESH=95,  BLUE_HUE_MIN=80, BLUE_HUE_MAX=120, BLUE_DELTA=14)\n",
    "BLUE_PARAMS_LENIENT= dict(BLUE_SAT_THRESH=60,  BLUE_VAL_THRESH=80,  BLUE_HUE_MIN=75, BLUE_HUE_MAX=125, BLUE_DELTA=18)\n",
    "BLUE_PARAMS_VERY_LENIENT = dict(BLUE_SAT_THRESH=30, BLUE_VAL_THRESH=60, BLUE_HUE_MIN=70, BLUE_HUE_MAX=135, BLUE_DELTA=22)\n",
    "\n",
    "BLUE_PARAMS_ULTRA_LENIENT = dict(\n",
    "    BLUE_SAT_THRESH=18,\n",
    "    BLUE_VAL_THRESH=45,\n",
    "    BLUE_HUE_MIN=65,\n",
    "    BLUE_HUE_MAX=145,\n",
    "    BLUE_DELTA=26\n",
    ")\n",
    "\n",
    "BLUE_PARAMS_MAX_LENIENT = dict(\n",
    "    BLUE_SAT_THRESH=8,\n",
    "    BLUE_VAL_THRESH=35,\n",
    "    BLUE_HUE_MIN=55,\n",
    "    BLUE_HUE_MAX=160,\n",
    "    BLUE_DELTA=32\n",
    ")\n",
    "\n",
    "BLUE_PARAMS_NUCLEAR = dict(\n",
    "    BLUE_SAT_THRESH = 3,\n",
    "    BLUE_VAL_THRESH = 25,\n",
    "    BLUE_HUE_MIN    = 45,\n",
    "    BLUE_HUE_MAX    = 170,\n",
    "    BLUE_DELTA      = 40\n",
    ")\n",
    "\n",
    "BLUE_PARAM_TIERS = [\n",
    "    (\"STRICT\",       BLUE_PARAMS_STRICT),\n",
    "    (\"MID\",          BLUE_PARAMS_MID),\n",
    "    (\"LENIENT\",      BLUE_PARAMS_LENIENT),\n",
    "    (\"VERY_LENIENT\", BLUE_PARAMS_VERY_LENIENT),\n",
    "    (\"ULTRA_LENIENT\", BLUE_PARAMS_ULTRA_LENIENT),\n",
    "    (\"MAX_LENIENT\",   BLUE_PARAMS_MAX_LENIENT),\n",
    "    (\"NUCLEAR\",       BLUE_PARAMS_NUCLEAR),\n",
    "]\n",
    "\n",
    "TIER_BONUS = {\n",
    "    \"STRICT\": 0.18,\n",
    "    \"MID\": 0.12,\n",
    "    \"LENIENT\": 0.06,\n",
    "    \"VERY_LENIENT\": 0.00,\n",
    "    \"ULTRA_LENIENT\": -0.06,\n",
    "    \"MAX_LENIENT\":   -0.10,\n",
    "    \"NUCLEAR\":       -0.10,\n",
    "}\n",
    "\n",
    "# ================================================================\n",
    "#  SCORING HYPERPARAMS\n",
    "# ================================================================\n",
    "HUE_CENTER = 100\n",
    "HUE_SIGMA  = 18.0\n",
    "\n",
    "WHITE_S_MAX = 90\n",
    "WHITE_V_MIN = 120\n",
    "\n",
    "W_CC_DOM   = 0.22\n",
    "W_ROW_BAND = 0.18\n",
    "W_BLUE     = 0.26\n",
    "W_SAT      = 0.10\n",
    "W_BELOW    = 0.18\n",
    "W_TOP_PRIOR= 0.06\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "def _adaptive_blue_mask_with_params(img_rgb, params, debug=False, tag=\"\"):\n",
    "    hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)\n",
    "    H, S, V = cv2.split(hsv)\n",
    "\n",
    "    sat_thr = params[\"BLUE_SAT_THRESH\"]\n",
    "    val_thr = params[\"BLUE_VAL_THRESH\"]\n",
    "    hue_min = params[\"BLUE_HUE_MIN\"]\n",
    "    hue_max = params[\"BLUE_HUE_MAX\"]\n",
    "    delta   = params[\"BLUE_DELTA\"]\n",
    "\n",
    "    colored = (S > sat_thr) & (V > val_thr)\n",
    "    H_colored = H[colored]\n",
    "\n",
    "    hue_mask = (H_colored >= hue_min) & (H_colored <= hue_max)\n",
    "    blue_hues = H_colored[hue_mask]\n",
    "\n",
    "    if blue_hues.size == 0:\n",
    "        if debug:\n",
    "            print(f\"[{tag}] No blue hues found in candidate window.\")\n",
    "        return np.zeros_like(H, dtype=np.uint8), None, None\n",
    "\n",
    "    hist, bin_edges = np.histogram(blue_hues, bins=36, range=(0, 180))\n",
    "    peak_bin = int(np.argmax(hist))\n",
    "    h_peak = 0.5 * (bin_edges[peak_bin] + bin_edges[peak_bin + 1])\n",
    "\n",
    "    h_low  = max(0,   int(h_peak - delta))\n",
    "    h_high = min(179, int(h_peak + delta))\n",
    "\n",
    "    lower_blue = np.array([h_low,  sat_thr, val_thr], dtype=np.uint8)\n",
    "    upper_blue = np.array([h_high, 255,     255],     dtype=np.uint8)\n",
    "\n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "\n",
    "    if debug:\n",
    "        n = int(mask.sum() // 255)\n",
    "        print(f\"[{tag}] Peak={h_peak:.1f}, H=({h_low},{h_high}), S>{sat_thr}, V>{val_thr}, pixels={n}\")\n",
    "\n",
    "    return mask, lower_blue, upper_blue\n",
    "\n",
    "\n",
    "def _hue_distance_circular(h, center):\n",
    "    d = np.abs(h.astype(np.float32) - float(center))\n",
    "    return np.minimum(d, 180.0 - d)\n",
    "\n",
    "\n",
    "def _score_component(mask, hsv, comp_mask, bbox, tier_name, debug=False):\n",
    "    Himg, Wimg = mask.shape[:2]\n",
    "    x, y, w, h = bbox\n",
    "    area = float(comp_mask.sum())\n",
    "    total = float((mask > 0).sum()) + 1e-6\n",
    "\n",
    "    cc_dom = area / total\n",
    "\n",
    "    y_center = y + 0.5*h\n",
    "    top_prior = 1.0 - np.clip(y_center / (0.65 * Himg + 1e-6), 0.0, 1.0)\n",
    "\n",
    "    sub = mask[y:y+h, x:x+w] > 0\n",
    "    if sub.size == 0:\n",
    "        return -1e9, {}\n",
    "    row_counts = sub.sum(axis=1).astype(np.float32)\n",
    "    if row_counts.max() <= 0:\n",
    "        row_band = 0.0\n",
    "    else:\n",
    "        peak = row_counts.max()\n",
    "        mean = row_counts.mean() + 1e-6\n",
    "        peakiness = float(peak / mean)\n",
    "        thr = 0.6 * peak\n",
    "        strong = row_counts >= thr\n",
    "        longest = 0\n",
    "        cur = 0\n",
    "        for v in strong:\n",
    "            if v:\n",
    "                cur += 1\n",
    "                longest = max(longest, cur)\n",
    "            else:\n",
    "                cur = 0\n",
    "        run_frac = float(longest / (h + 1e-6))\n",
    "        row_band = np.tanh((peakiness - 1.5) / 2.0) * 0.6 + run_frac * 0.4\n",
    "        row_band = float(np.clip(row_band, 0.0, 1.0))\n",
    "\n",
    "    Hc = hsv[...,0][comp_mask]\n",
    "    Sc = hsv[...,1][comp_mask]\n",
    "    if Hc.size == 0:\n",
    "        blue_score = 0.0\n",
    "        sat_score  = 0.0\n",
    "    else:\n",
    "        d = _hue_distance_circular(Hc, HUE_CENTER)\n",
    "        mean_d = float(d.mean())\n",
    "        blue_score = float(np.exp(- (mean_d**2) / (2.0 * (HUE_SIGMA**2))))\n",
    "        sat_score = float(np.clip(Sc.mean() / 255.0, 0.0, 1.0))\n",
    "\n",
    "    y0 = int(y + h)\n",
    "    y1 = int(min(Himg, y + h + 1.5*h))\n",
    "    if y1 <= y0 + 2:\n",
    "        below_white = 0.0\n",
    "    else:\n",
    "        below = hsv[y0:y1, x:x+w]\n",
    "        S_b = below[...,1].astype(np.uint8)\n",
    "        V_b = below[...,2].astype(np.uint8)\n",
    "        white = (S_b < WHITE_S_MAX) & (V_b > WHITE_V_MIN)\n",
    "        below_white = float(white.mean())\n",
    "\n",
    "    tier_bonus = TIER_BONUS.get(tier_name, 0.0)\n",
    "\n",
    "    score = (\n",
    "        W_CC_DOM    * cc_dom +\n",
    "        W_ROW_BAND  * row_band +\n",
    "        W_BLUE      * blue_score +\n",
    "        W_SAT       * sat_score +\n",
    "        W_BELOW     * below_white +\n",
    "        W_TOP_PRIOR * top_prior +\n",
    "        tier_bonus\n",
    "    )\n",
    "\n",
    "    if debug:\n",
    "        print(f\"    [{tier_name}] bbox={x,y,w,h} \"\n",
    "              f\"score={score:.3f} | cc={cc_dom:.2f} row={row_band:.2f} blue={blue_score:.2f} \"\n",
    "              f\"sat={sat_score:.2f} belowW={below_white:.2f} top={top_prior:.2f} +bonus={tier_bonus:.2f}\")\n",
    "\n",
    "    return float(score), dict(bbox=(x,y,w,h))\n",
    "\n",
    "\n",
    "def adaptive_blue_mask(img_rgb, debug=False):\n",
    "    # NOTE: keep everything minimal\n",
    "    Himg, Wimg = img_rgb.shape[:2]\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # NEW: probe STRICT + MID, and if both are \"near empty\", rescue\n",
    "    # ------------------------------------------------------------\n",
    "    RESCUE_WHITE_THR = 200  # you can tune this\n",
    "    did_rescue = False\n",
    "\n",
    "    # quick probe on ORIGINAL img\n",
    "    maskS, _, _ = _adaptive_blue_mask_with_params(img_rgb, BLUE_PARAMS_STRICT, debug=False, tag=\"PROBE_STRICT\")\n",
    "    maskM, _, _ = _adaptive_blue_mask_with_params(img_rgb, BLUE_PARAMS_MID,    debug=False, tag=\"PROBE_MID\")\n",
    "\n",
    "    nS = int(maskS.sum() // 255) if maskS is not None else 0\n",
    "    nM = int(maskM.sum() // 255) if maskM is not None else 0\n",
    "\n",
    "    img_work = img_rgb\n",
    "\n",
    "    if (nS < RESCUE_WHITE_THR) and (nM < RESCUE_WHITE_THR):\n",
    "        did_rescue = True\n",
    "        if debug:\n",
    "            print(f\"[RESCUE TRIGGER] STRICT={nS} MID={nM} < {RESCUE_WHITE_THR} -> calling rescue_blue_strip_rgb_extreme()\")\n",
    "\n",
    "        img_rescued = rescue_blue_strip_rgb_extreme(img_rgb, debug=True)\n",
    "\n",
    "        if debug:\n",
    "            plt.figure(figsize=(10,4))\n",
    "            plt.subplot(1,2,1); plt.imshow(img_rgb);     plt.title(\"Original (before rescue)\"); plt.axis(\"off\")\n",
    "            plt.subplot(1,2,2); plt.imshow(img_rescued); plt.title(\"After rescue_blue_strip_rgb_extreme\"); plt.axis(\"off\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        img_work = img_rescued\n",
    "\n",
    "    # now proceed normally, BUT using img_work (original or rescued)\n",
    "    hsv = cv2.cvtColor(img_work, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    best = dict(\n",
    "        score=-1e9,\n",
    "        mask=None, lb=None, ub=None, tier=None, bbox=None,\n",
    "        did_rescue=did_rescue,\n",
    "        best_comp_id=None,\n",
    "        best_labels=None\n",
    "    )\n",
    "\n",
    "    for tier_name, params in BLUE_PARAM_TIERS:\n",
    "        mask, lb, ub = _adaptive_blue_mask_with_params(img_work, params, debug=debug, tag=tier_name)\n",
    "\n",
    "        # keep your dilation exactly as-is\n",
    "        mask = cv2.dilate(mask, cv2.getStructuringElement(cv2.MORPH_RECT, (9, 3)), iterations=1)\n",
    "\n",
    "        if debug:\n",
    "            _show_mask_debug(mask, f\"{tier_name} mask (raw+dilated)\")\n",
    "\n",
    "        if lb is None or mask.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        bin_mask = (mask > 0).astype(np.uint8)\n",
    "        num, labels, stats, centroids = cv2.connectedComponentsWithStats(bin_mask, connectivity=8)\n",
    "\n",
    "        for comp_id in range(1, num):\n",
    "            x, y, w, h, area = stats[comp_id]\n",
    "            if area < 20:\n",
    "                continue\n",
    "\n",
    "            comp_mask = (labels == comp_id)\n",
    "            score, details = _score_component(mask, hsv, comp_mask, (x,y,w,h), tier_name, debug=debug)\n",
    "\n",
    "            if score > best[\"score\"]:\n",
    "                best.update(\n",
    "                    score=score,\n",
    "                    mask=mask, lb=lb, ub=ub, tier=tier_name, bbox=(x,y,w,h),\n",
    "                    best_comp_id=comp_id,\n",
    "                    best_labels=labels\n",
    "                )\n",
    "\n",
    "    if best[\"mask\"] is None:\n",
    "        return np.zeros((Himg, Wimg), dtype=np.uint8), None, None, None, None, None, img_work\n",
    "\n",
    "    # -----------------------------\n",
    "    # NEW: compute 4 rotated corners of BEST strip component\n",
    "    # -----------------------------\n",
    "# -----------------------------\n",
    "# NEW: compute 4 corners of BEST strip component\n",
    "# Try TRUE quad from contour; fallback to minAreaRect rectangle\n",
    "# -----------------------------\n",
    "\n",
    "\n",
    "\n",
    "    # strip_corners = None\n",
    "    # strip_corners_src = \"none\"\n",
    "\n",
    "    # if best[\"best_labels\"] is not None and best[\"best_comp_id\"] is not None:\n",
    "    #     comp = (best[\"best_labels\"] == best[\"best_comp_id\"]).astype(np.uint8) * 255\n",
    "\n",
    "    #     contours, _ = cv2.findContours(comp, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    #     if contours:\n",
    "    #         cnt = max(contours, key=cv2.contourArea)\n",
    "    #         if cv2.contourArea(cnt) >= 30:\n",
    "\n",
    "    #             # try to approximate to 4-point polygon (real trapezoid if perspective exists)\n",
    "    #             peri = cv2.arcLength(cnt, True)\n",
    "    #             approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)\n",
    "\n",
    "    #             if len(approx) == 4:\n",
    "    #                 strip_corners = approx.reshape(4, 2).astype(np.float32)\n",
    "    #                 strip_corners_src = \"approx4\"\n",
    "    #             else:\n",
    "    #                 # fallback: minAreaRect gives rectangle (always w_ratio≈1, h_ratio≈1)\n",
    "    #                 rect = cv2.minAreaRect(cnt)\n",
    "    #                 strip_corners = cv2.boxPoints(rect).astype(np.float32)\n",
    "    #                 strip_corners_src = f\"minAreaRect(len={len(approx)})\"\n",
    "\n",
    "\n",
    "\n",
    "    strip_corners = None\n",
    "    strip_corners_src = \"none\"\n",
    "\n",
    "    if best[\"best_labels\"] is not None and best[\"best_comp_id\"] is not None:\n",
    "        comp = (best[\"best_labels\"] == best[\"best_comp_id\"]).astype(np.uint8) * 255\n",
    "\n",
    "        # NEW PRIMARY METHOD: mask edge lines -> trapezoid corners\n",
    "        strip_corners = strip_corners_from_mask_edges(comp, debug=debug)\n",
    "        if strip_corners is not None:\n",
    "            strip_corners_src = \"mask_edges\"\n",
    "\n",
    "        else:\n",
    "            # fallback 1: approxPolyDP if it returns 4 points\n",
    "            contours, _ = cv2.findContours(comp, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            if contours:\n",
    "                cnt = max(contours, key=cv2.contourArea)\n",
    "                peri = cv2.arcLength(cnt, True)\n",
    "                approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)\n",
    "\n",
    "                if len(approx) == 4:\n",
    "                    strip_corners = approx.reshape(4, 2).astype(np.float32)\n",
    "                    strip_corners_src = \"approx4\"\n",
    "                else:\n",
    "                    # last fallback: minAreaRect (rectangle)\n",
    "                    rect = cv2.minAreaRect(cnt)\n",
    "                    strip_corners = cv2.boxPoints(rect).astype(np.float32)\n",
    "                    strip_corners_src = f\"minAreaRect(len={len(approx)})\"\n",
    "\n",
    "\n",
    "\n",
    "    if debug:\n",
    "        x,y,w,h = best[\"bbox\"]\n",
    "        print(f\"\\n✅ CHOSEN OVERALL: tier={best['tier']} score={best['score']:.3f} bbox={(x,y,w,h)} rescue_used={did_rescue}\\n\")\n",
    "        if strip_corners is not None:\n",
    "            print(f\"[STRIP CORNERS] src={strip_corners_src}\\n\", strip_corners)\n",
    "\n",
    "\n",
    "    return best[\"mask\"], best[\"lb\"], best[\"ub\"], best[\"tier\"], best[\"bbox\"], strip_corners, img_work\n",
    "\n",
    "\n",
    "\n",
    "#/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "def crop_left_right_by_blue_adaptive(img_bgr, debug=False, enable_perspective=True):\n",
    "\n",
    "    H, W = img_bgr.shape[:2]\n",
    "\n",
    "\n",
    "    mask, lb, ub, tier, bbox, strip_corners, img_work = adaptive_blue_mask(img_bgr, False)   #HERE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "    if debug:\n",
    "        print(\"✅ Tier used:\", tier)\n",
    "\n",
    "    if lb is None:\n",
    "        if debug:\n",
    "            print(\"❌ No blue detected\")\n",
    "        return None, None, mask, None\n",
    "\n",
    "    # IMPORTANT: continue on img_work (original or rescued)\n",
    "    hsv = cv2.cvtColor(img_work, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    row_counts = mask.sum(axis=1)//255\n",
    "    max_row = row_counts.max()\n",
    "    if max_row == 0:\n",
    "        return None, None, mask, None\n",
    "\n",
    "    row_thresh = 0.30*max_row\n",
    "    blue_rows = row_counts > row_thresh\n",
    "\n",
    "    bands = []\n",
    "    cur_start = None\n",
    "    for y, flag in enumerate(blue_rows):\n",
    "        if flag and cur_start is None:\n",
    "            cur_start = y\n",
    "        elif not flag and cur_start is not None:\n",
    "            bands.append((cur_start, y))\n",
    "            cur_start = None\n",
    "    if cur_start is not None:\n",
    "        bands.append((cur_start, len(blue_rows)))\n",
    "\n",
    "    # =====================================================\n",
    "    # ✅ NEW: two-pass gating thresholds (only used for filtering)\n",
    "    # =====================================================\n",
    "    PASS1_MIN_BAND_H_FRAC = 0.02\n",
    "    PASS1_MIN_BAND_W_FRAC = 0.10\n",
    "\n",
    "    PASS2_MIN_BAND_H_FRAC = 0.008\n",
    "    PASS2_MIN_BAND_W_FRAC = 0.05\n",
    "\n",
    "    def _collect_candidates(min_band_h_frac, min_band_w_frac):\n",
    "        candidates = []\n",
    "\n",
    "        for (y0_band, y1_band) in bands:\n",
    "            band_h = y1_band - y0_band\n",
    "            if band_h < min_band_h_frac * H:\n",
    "                continue\n",
    "\n",
    "            submask = mask[y0_band:y1_band, :]\n",
    "\n",
    "            ys2, xs2 = np.where(submask > 0)\n",
    "            if xs2.size == 0:\n",
    "                continue\n",
    "\n",
    "            x0_band = int(np.percentile(xs2, 1))\n",
    "            x1_band = int(np.percentile(xs2, 99))\n",
    "            band_w  = x1_band - x0_band\n",
    "\n",
    "            if band_w < min_band_w_frac * W or band_w > 0.95 * W:\n",
    "                continue\n",
    "\n",
    "            ar_band = band_w / (band_h + 1e-6)\n",
    "            s_ar_band = np.tanh((ar_band - 2.0) / 2.0)\n",
    "            s_ar_band = float(np.clip(s_ar_band, 0.0, 1.0))\n",
    "\n",
    "            region_hsv = hsv[:, x0_band:x1_band]\n",
    "            _, Sc, Vc = cv2.split(region_hsv)\n",
    "\n",
    "            S_MAX = 130\n",
    "            V_MIN = 80\n",
    "            white_mask = (Sc < S_MAX) & (Vc > V_MIN)\n",
    "            white_ratio = float(white_mask.mean())\n",
    "\n",
    "            s_white = white_ratio\n",
    "\n",
    "            k = 3.0\n",
    "            y0_pl = max(0,   int(y0_band - 0.2*band_h))\n",
    "            y1_pl = min(H-1, int(y0_band + k*band_h))\n",
    "            plate_h = y1_pl - y0_pl\n",
    "            ar_plate = band_w / (plate_h + 1e-6)\n",
    "\n",
    "            expected_ar = 2.0\n",
    "            sigma = 0.8\n",
    "            s_ar_plate = float(np.exp(-((ar_plate - expected_ar)**2) / (2 * sigma**2)))\n",
    "\n",
    "            score = (\n",
    "                0.20*s_ar_band +\n",
    "                0.50*s_white   +\n",
    "                0.30*s_ar_plate\n",
    "            )\n",
    "\n",
    "            candidates.append({\n",
    "                \"x0\": x0_band, \"y0\": y0_band,\n",
    "                \"x1\": x1_band, \"y1\": y1_band,\n",
    "                \"width\": band_w,\n",
    "                \"height\": band_h,\n",
    "                \"score\": float(score),\n",
    "                \"white_ratio\": white_ratio,\n",
    "                \"s_white\": s_white,\n",
    "                \"s_ar_band\": s_ar_band,\n",
    "                \"s_ar_plate\": s_ar_plate\n",
    "            })\n",
    "\n",
    "        return candidates\n",
    "\n",
    "    candidates = _collect_candidates(PASS1_MIN_BAND_H_FRAC, PASS1_MIN_BAND_W_FRAC)\n",
    "\n",
    "    if not candidates:\n",
    "        candidates = _collect_candidates(PASS2_MIN_BAND_H_FRAC, PASS2_MIN_BAND_W_FRAC)\n",
    "        if debug and candidates:\n",
    "            print(\"[2-PASS] Pass1 empty -> using lenient gates for far/small plate case\")\n",
    "\n",
    "    if not candidates:\n",
    "        return img_work, (0,0,W-1,H-1), mask, img_work\n",
    "\n",
    "    candidates_sorted = sorted(\n",
    "        candidates,\n",
    "        key=lambda c: (c[\"score\"], c[\"white_ratio\"], c[\"width\"], c[\"height\"]),\n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    best = candidates_sorted[0]\n",
    "    best_idx = candidates.index(best)\n",
    "\n",
    "    margin = int(0.02*W)\n",
    "    x0 = max(0, best[\"x0\"] - margin)\n",
    "    x1 = min(W-1, best[\"x1\"] + margin)\n",
    "\n",
    "    y_strip_top = int(best[\"y0\"])\n",
    "    strip_h     = int(best[\"height\"])\n",
    "\n",
    "    plate_h = int(3.5 * strip_h)\n",
    "\n",
    "    y_top = max(0, y_strip_top)\n",
    "    y_bottom = y_top + plate_h + int(0.10 * strip_h)\n",
    "    y_bottom = min(H - 1, y_bottom)\n",
    "\n",
    "        # =====================================================\n",
    "    # ✅ NEW: tiny safety padding (top/left/right) so we don't cut plate edges                             MAW OK OR NOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO\n",
    "    # =====================================================\n",
    "    # PAD_X_FRAC = 0.010   # ~1% of image width\n",
    "    # PAD_TOP_FRAC = 0.010 # ~1% of image height\n",
    "    # PAD_X_PX_MIN = 2\n",
    "    # PAD_TOP_PX_MIN = 2\n",
    "\n",
    "    # pad_x  = max(PAD_X_PX_MIN,  int(PAD_X_FRAC  * W))\n",
    "    # # pad_ty = max(PAD_TOP_PX_MIN, int(PAD_TOP_FRAC * H))\n",
    "    # pad_ty = max(2, int(0.15 * strip_h))  # e.g., 15% of strip height\n",
    "\n",
    "\n",
    "    # # expand crop slightly\n",
    "    # x0 = max(0, x0 - pad_x)     # left\n",
    "    # x1 = min(W - 1, x1 + pad_x) # right\n",
    "    # y_top = max(0, y_top - pad_ty)  # top only (keep bottom as-is)\n",
    "\n",
    "    # # (optional) keep bottom inside bounds (already clamped, but safe)\n",
    "    # y_bottom = min(H - 1, y_bottom)\n",
    "\n",
    "\n",
    "    cropped = img_work[y_top:y_bottom+1, x0:x1]\n",
    "\n",
    "\n",
    "    # ===================== DEBUG: Stage 2B inspection =====================\n",
    "    if debug:\n",
    "        print(\"\\n================= [DEBUG 2B] =================\")\n",
    "        print(\"[DEBUG 2B] img_work used instead of original:\", (img_work is not img_bgr))\n",
    "        print(\"[DEBUG 2B] crop x0,x1,y_top,y_bottom:\", x0, x1, y_top, y_bottom)\n",
    "        print(\"[DEBUG 2B] cropped shape:\", cropped.shape)\n",
    "\n",
    "        if strip_corners is None:\n",
    "            print(\"[DEBUG 2B] strip_corners = None  (no corners computed!)\")\n",
    "        else:\n",
    "            print(\"[DEBUG 2B] strip_corners (FULL coords):\\n\", strip_corners)\n",
    "\n",
    "            # convert to cropped coords\n",
    "            strip_corners_crop = strip_corners.copy().astype(np.float32)\n",
    "            strip_corners_crop[:, 0] -= float(x0)\n",
    "            strip_corners_crop[:, 1] -= float(y_top)\n",
    "\n",
    "            print(\"[DEBUG 2B] strip_corners (CROPPED coords):\\n\", strip_corners_crop)\n",
    "\n",
    "            # order and compute trapezoid measures like Stage 2B\n",
    "            quad = _order_quad_tl_tr_br_bl(strip_corners_crop)\n",
    "            tl, tr, br, bl = quad\n",
    "\n",
    "            def _dist(a, b):\n",
    "                return float(np.hypot(a[0]-b[0], a[1]-b[1]))\n",
    "\n",
    "            top_w  = _dist(tl, tr)\n",
    "            bot_w  = _dist(bl, br)\n",
    "            left_h = _dist(tl, bl)\n",
    "            right_h= _dist(tr, br)\n",
    "\n",
    "            w_ratio = (top_w + 1e-6) / (bot_w + 1e-6)\n",
    "            h_ratio = (left_h + 1e-6) / (right_h + 1e-6)\n",
    "\n",
    "\n",
    "                        # =====================================================\n",
    "            # ✅ NEW: cap extreme ratios (if too crazy -> skip perspective)\n",
    "            # =====================================================\n",
    "            MAX_RATIO_CAP = 2.0  # your requested cap\n",
    "\n",
    "            w_ratio_sym = max(w_ratio, 1.0 / (w_ratio + 1e-6))   # symmetric ratio >= 1\n",
    "            h_ratio_sym = max(h_ratio, 1.0 / (h_ratio + 1e-6))   # symmetric ratio >= 1\n",
    "\n",
    "            if (w_ratio_sym > MAX_RATIO_CAP) or (h_ratio_sym > MAX_RATIO_CAP):\n",
    "                if debug:\n",
    "                    print(f\"[2B] SKIP: extreme ratio (w_sym={w_ratio_sym:.3f}, h_sym={h_ratio_sym:.3f}) > {MAX_RATIO_CAP}\")\n",
    "                    enable_perspective=False\n",
    "\n",
    "\n",
    "            area = float(abs(cv2.contourArea(quad)))\n",
    "            print(f\"[DEBUG 2B] quad area={area:.1f} top_w={top_w:.1f} bot_w={bot_w:.1f} w_ratio={w_ratio:.3f}\")\n",
    "            print(f\"[DEBUG 2B] left_h={left_h:.1f} right_h={right_h:.1f} h_ratio={h_ratio:.3f}\")\n",
    "\n",
    "            # draw overlay on cropped image\n",
    "            overlay = cropped.copy()\n",
    "            qint = np.round(quad).astype(np.int32)\n",
    "            cv2.polylines(overlay, [qint], True, (255, 0, 0), 2)  # blue polygon\n",
    "\n",
    "            # label corners\n",
    "            pts = {\"TL\": tl, \"TR\": tr, \"BR\": br, \"BL\": bl}\n",
    "            for name, p in pts.items():\n",
    "                px, py = int(round(p[0])), int(round(p[1]))\n",
    "                cv2.circle(overlay, (px, py), 4, (0, 255, 0), -1)\n",
    "                cv2.putText(overlay, name, (px + 5, py - 5),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "            plt.figure(figsize=(10,4))\n",
    "            plt.subplot(1,2,1); plt.imshow(cropped);  plt.title(\"Cropped (before 2B)\"); plt.axis(\"off\")\n",
    "            plt.subplot(1,2,2); plt.imshow(overlay);  plt.title(\"Cropped + strip corners\"); plt.axis(\"off\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        print(\"================================================\\n\")\n",
    "    # =================== END DEBUG: Stage 2B inspection ===================\n",
    "\n",
    "\n",
    "    # =====================================================\n",
    "    # ✅ NEW: Stage 2B plug-in (using strip corners only)\n",
    "    # Convert strip_corners from FULL img_work coords -> CROPPED coords\n",
    "    # =====================================================\n",
    "    if enable_perspective and (strip_corners is not None):\n",
    "        strip_corners_crop = strip_corners.copy()\n",
    "        strip_corners_crop[:, 0] -= float(x0)\n",
    "        strip_corners_crop[:, 1] -= float(y_top)\n",
    "\n",
    "        out2b = deskew_stage2B_strip_perspective_if_needed(\n",
    "            cropped, strip_corners_crop, debug=debug\n",
    "        )\n",
    "        if out2b[\"did_apply\"]:\n",
    "            cropped = out2b[\"rgb\"]\n",
    "            if debug:\n",
    "                print(\"[2B] applied:\", out2b.get(\"reason\", \"\"))\n",
    "\n",
    "\n",
    "\n",
    "    debug_img = draw_candidates_debug(img_work, candidates, best_idx)\n",
    "\n",
    "    # if debug:\n",
    "    #     print(\"\\n========= CANDIDATE BREAKDOWN =========\")\n",
    "    #     for i, c in enumerate(candidates):\n",
    "    #         print(f\"[{i}] score={c['score']:.3f}, \"\n",
    "    #               f\"white_ratio={c['white_ratio']:.3f}, \"                                     HERE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    #               f\"s_white={c['s_white']:.2f}, \"\n",
    "    #               f\"ARband={c['s_ar_band']:.2f}, \"\n",
    "    #               f\"ARplate={c['s_ar_plate']:.2f}, \"\n",
    "    #               f\"range=({c['x0']},{c['x1']}) \"\n",
    "    #               f\"vertical=({c['y0']},{c['y1']})\")\n",
    "    #     print(\"Chosen:\", best)\n",
    "    #     print(\"========================================\\n\")\n",
    "\n",
    "    return cropped, (best[\"x0\"], best[\"y0\"], best[\"x1\"], best[\"y1\"]), mask, debug_img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def debug_blue_crop(plate_img, title, enable_perspective=True):\n",
    "\n",
    "    if plate_img is None:\n",
    "        print(f\"{title}: plate_img is None, skipping.\")\n",
    "        return None\n",
    "\n",
    "    cropped, bbox, mask, debug_img = crop_left_right_by_blue_adaptive(\n",
    "    plate_img, debug=True, enable_perspective=enable_perspective\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "    images = [plate_img]\n",
    "    titles = [f\"{title} - Original\"]\n",
    "\n",
    "    if mask is not None:\n",
    "        images.append(mask)\n",
    "        titles.append(\"Blue mask\")\n",
    "\n",
    "    if debug_img is not None:\n",
    "        images.append(debug_img)\n",
    "        titles.append(\"All candidates\")\n",
    "    else:\n",
    "        print(f\"{title}: debug_img is None (likely no candidates / no blue).\")\n",
    "\n",
    "    if cropped is not None:\n",
    "        images.append(cropped)\n",
    "        titles.append(\"Final crop\")\n",
    "    else:\n",
    "        print(f\"{title}: cropped is None (no blue detected).\")\n",
    "\n",
    "    show_images(images, titles)\n",
    "    plt.close('all')\n",
    "\n",
    "    return cropped\n",
    "\n",
    "\n",
    "def rescue_blue_strip_rgb_extreme(img_rgb, debug=False):\n",
    "\n",
    "    \"\"\"\n",
    "    MUCH harsher rescue:\n",
    "      - normalize + CLAHE + stronger gamma on V\n",
    "      - build a better seed (prefers blue-ish + horizontal band)\n",
    "      - inside seed: PUSH S/V strongly toward target (S~100, V~90+)\n",
    "      - optional stronger hue pull toward blue center\n",
    "    \"\"\"\n",
    "\n",
    "    hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV).astype(np.float32)\n",
    "    H = hsv[..., 0]\n",
    "    S = hsv[..., 1]\n",
    "    V = hsv[..., 2]\n",
    "\n",
    "    # -----------------------------\n",
    "    # (1) Robust normalize V (stronger)\n",
    "    # -----------------------------\n",
    "    v1 = np.percentile(V, 1)\n",
    "    v2 = np.percentile(V, 99)\n",
    "    if v2 > v1 + 1e-3:\n",
    "        Vn = (V - v1) * (255.0 / (v2 - v1))\n",
    "        Vn = np.clip(Vn, 0, 255)\n",
    "    else:\n",
    "        Vn = V.copy()\n",
    "    \n",
    "    V8 = Vn.astype(np.uint8)\n",
    "    clahe = cv2.createCLAHE(clipLimit=6.0, tileGridSize=(5, 5))\n",
    "    Vc = clahe.apply(V8).astype(np.float32)\n",
    "\n",
    "    gamma = 0.3   # was 0.65, now harsher\n",
    "    Vg = 255.0 * np.power(np.clip(Vc / 255.0, 0, 1), gamma)\n",
    "\n",
    "    # slight extra lift to midtones\n",
    "    Vg = np.clip(Vg + 10.0, 0, 255)\n",
    "\n",
    "    hsv2 = hsv.copy()\n",
    "    hsv2[..., 2] = Vg\n",
    "    # -----------------------------\n",
    "    hsv2_u8 = hsv2.astype(np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "    lower_seed = np.array([70,  0,  0], dtype=np.uint8)\n",
    "    upper_seed = np.array([135, 255, 255], dtype=np.uint8)\n",
    "    seed0 = cv2.inRange(hsv2_u8, lower_seed, upper_seed)\n",
    "\n",
    "\n",
    "    S_min_after = 15\n",
    "    seed0 = seed0 & ((hsv2_u8[...,1] >= S_min_after).astype(np.uint8) * 255)\n",
    "\n",
    "    # cleanup\n",
    "    seed0 = cv2.medianBlur(seed0, 5)\n",
    "\n",
    "    # horizontal emphasis: open with long horizontal kernel\n",
    "    seed1 = cv2.morphologyEx(\n",
    "        seed0, cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (15, 3)),\n",
    "        iterations=1\n",
    "    )\n",
    "\n",
    "    # connect horizontally\n",
    "    seed1 = cv2.morphologyEx(\n",
    "        seed1, cv2.MORPH_CLOSE,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (25, 5)),\n",
    "        iterations=1\n",
    "    )\n",
    "\n",
    "    seed01 = (seed1 > 0)\n",
    "\n",
    "    # -----------------------------\n",
    "    # (5) EXTREME push of S/V inside seed\n",
    "    # target-ish: S ~ 95-100, V ~ 80-100\n",
    "    # -----------------------------\n",
    "    S2 = S.copy()\n",
    "    V2 = Vg.copy()\n",
    "\n",
    "    # Push S upward HARD:\n",
    "    #   - If S is tiny, multiplication does nothing, so we also ADD a lot\n",
    "    S2[seed01] = np.clip(S2[seed01] * 2.8 + 80, 0, 255)\n",
    "\n",
    "    # Push V upward HARD (but still capped):\n",
    "    V2[seed01] = np.clip(V2[seed01] * 1.35 + 35, 0, 255)\n",
    "\n",
    "    # Optional: clamp seed area to minimum \"good\" S/V\n",
    "    # (forces your desired style)\n",
    "    S2[seed01] = np.maximum(S2[seed01], 255)   # ~90% of 255\n",
    "    V2[seed01] = np.maximum(V2[seed01], 230)   # ~75% of 255\n",
    "\n",
    "    # -----------------------------\n",
    "    # (6) Stronger hue pull toward blue center\n",
    "    # -----------------------------\n",
    "    H2 = H.copy()\n",
    "    blue_center = 100.0\n",
    "    pull = 0.55   # was 0.25, now harsher\n",
    "\n",
    "    good = seed01  # since we already enforced S_min_after\n",
    "    H2[good] = (1 - pull) * H2[good] + pull * blue_center\n",
    "    H2 = np.clip(H2, 0, 179)\n",
    "\n",
    "    hsv_out = np.stack([H2, S2, V2], axis=-1).astype(np.uint8)\n",
    "    out_rgb = cv2.cvtColor(hsv_out, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "    if debug:\n",
    "        nseed = int(seed01.sum())\n",
    "        print(f\"[RESCUE EXTREME] seed_pixels={nseed} gamma={gamma} clahe=4.0 pull={pull}\")\n",
    "\n",
    "    return out_rgb\n",
    "\n",
    "\n",
    "New_Origignal_Img1111 = io.imread(\"Localization Test/NewTestCases/white car harsh right angle.jpg\")\n",
    "New_Origigna2_Img1111 = io.imread(\"Localization Test/NewTestCases/white car harshest angle.jpg\")\n",
    "New_Origigna3_Img1111 = io.imread(\"Localization Test/NewTestCases/white car slight angle .jpg\")\n",
    "New_Origigna4_Img1111 = io.imread(\"Localization Test/NewTestCases/white car straight.jpg\")\n",
    "New_Origigna5_Img1111 = io.imread(\"Localization Test/NewTestCases/white car very elevated angle.jpg\")\n",
    "New_Origigna6_Img1111 = io.imread(\"Localization Test/NewTestCases/white car very harsh left angle with alot of noise.jpg\")\n",
    "\n",
    "# New_Origigna7_Img1111 = io.imread(\"Localization Test/NewTestCases/angle no bright.jpeg\")\n",
    "New_Origigna8_Img1111 = io.imread(\"Localization Test/NewTestCases/blury gedan.jpeg\")\n",
    "New_Origigna9_Img1111 = io.imread(\"Localization Test/NewTestCases/bright with angle.jpeg\")\n",
    "New_Origigna12_Img1111 = io.imread(\"Localization Test/NewTestCases/very dirty and noisy.jpeg\")\n",
    "New_Origigna13_Img1111 = io.imread(\"Localization Test/NewTestCases/very light bright.jpeg\")\n",
    "New_Origigna14_Img1111 = io.imread(\"Localization Test/NewTestCases/veryyyy far.jpeg\")\n",
    "New_Origigna14_Img111411111 = io.imread(\"WhatsApp Image 2025-12-18 at 1.32.03 PM.jpeg\")\n",
    "\n",
    "\n",
    "# cropped_Plate1=debug_blue_crop(New_Origigna14_Img111111111,\"Detected_New_Origignal_Img1111\") \n",
    "# cropped_Plate1=debug_blue_crop(cropped_Plate1,\"Detected_New_Origignal_Img1111\",False)\n",
    "\n",
    "# cropped_Plate1=debug_blue_crop(New_Origigna14_Img111111211,\"Detected_New_Origignal_Img1111\") \n",
    "# cropped_Plate1=debug_blue_crop(cropped_Plate1,\"Detected_New_Origignal_Img1111\",False)\n",
    "\n",
    "# cropped_Plate1=debug_blue_crop(New_Origigna14_Img111411111,\"Detected_New_Origignal_Img1111\") \n",
    "# cropped_Plate1=debug_blue_crop(cropped_Plate1,\"Detected_New_Origignal_Img1111\",False)\n",
    "\n",
    "# cropped_Plate1=debug_blue_crop(New_Origignal_Img1111,\"Detected_New_Origignal_Img1111\")\n",
    "# cropped_Plate1=debug_blue_crop(cropped_Plate1,\"Detected_New_Origignal_Img1111\",False) \n",
    "\n",
    "# cropped_Plate2=debug_blue_crop(New_Origigna2_Img1111,\"Detected_New_Origigna2_Img1111\")    \n",
    "# cropped_Plate2=debug_blue_crop(cropped_Plate2,\"Detected_New_Origigna2_Img1111\",False)  \n",
    "\n",
    "# cropped_Plate3=debug_blue_crop(New_Origigna3_Img1111,\"Detected_New_Origigna3_Img1111\")    \n",
    "# cropped_Plate3=debug_blue_crop(cropped_Plate3,\"Detected_New_Origigna3_Img1111\",False)    \n",
    "\n",
    "# cropped_Plate4=debug_blue_crop(New_Origigna4_Img1111,\"Detected_New_Origigna4_Img1111\")    \n",
    "# cropped_Plate4=debug_blue_crop(cropped_Plate4,\"Detected_New_Origigna4_Img1111\",False) \n",
    "# cropped_Plate5=debug_blue_crop(New_Origigna5_Img1111,\"Detected_New_Origigna5_Img1111\")    \n",
    "# cropped_Plate5=debug_blue_crop(cropped_Plate5,\"Detected_New_Origigna5_Img1111\",False)     \n",
    "# cropped_Plate6=debug_blue_crop(New_Origigna6_Img1111,\"Detected_New_Origigna6_Img1111\")\n",
    "# cropped_Plate6=debug_blue_crop(cropped_Plate6,\"Detected_New_Origigna6_Img1111\",False)  \n",
    "\n",
    "# cropped_Plate7=debug_blue_crop(Origignal_Img1,\"Detected_New_Origignal_Img1111\")    \n",
    "# cropped_Plate7=debug_blue_crop(cropped_Plate7,\"Detected_New_Origignal_Img1111\",False)    \n",
    "# cropped_Plate8=debug_blue_crop(Origignal_Img2,\"Detected_New_Origigna2_Img1111\")    \n",
    "# cropped_Plate8=debug_blue_crop(cropped_Plate8,\"Detected_New_Origigna2_Img1111\",False)    \n",
    "# cropped_Plate9=debug_blue_crop(Origignal_Img3,\"Detected_New_Origigna3_Img1111\")    \n",
    "# cropped_Plate9=debug_blue_crop(cropped_Plate9,\"Detected_New_Origigna3_Img1111\",False)     \n",
    "# cropped_Plate10=debug_blue_crop(Origignal_Img4,\"Detected_New_Origigna4_Img1111\")    \n",
    "# cropped_Plate10=debug_blue_crop(cropped_Plate10,\"Detected_New_Origigna4_Img1111\",False)      \n",
    "# cropped_Plate11=debug_blue_crop(Origignal_Img5,\"Detected_New_Origigna5_Img1111\")\n",
    "# cropped_Plate11=debug_blue_crop(cropped_Plate11,\"Detected_New_Origigna5_Img1111\",False)\n",
    "\n",
    "\n",
    "# cropped_Plate12=debug_blue_crop(Origignal_Img11,\"Detected_New_Origigna6_Img1111\") \n",
    "# cropped_Plate12=debug_blue_crop(cropped_Plate12,\"Detected_New_Origigna6_Img1111\",False)  \n",
    "# cropped_Plate13=debug_blue_crop(Origignal_Img12,\"Detected_New_Origignal_Img1111\")    \n",
    "# cropped_Plate13=debug_blue_crop(cropped_Plate13,\"Detected_New_Origignal_Img1111\",False)    \n",
    "# cropped_Plate14=debug_blue_crop(Origignal_Img13,\"Detected_New_Origigna2_Img1111\")    \n",
    "# cropped_Plate14=debug_blue_crop(cropped_Plate14,\"Detected_New_Origigna2_Img1111\",False)      \n",
    "# cropped_Plate15=debug_blue_crop(Origignal_Img14,\"Detected_New_Origigna3_Img1111\")    \n",
    "# cropped_Plate15=debug_blue_crop(cropped_Plate15,\"Detected_New_Origigna3_Img1111\",False)    \n",
    "# cropped_Plate16=debug_blue_crop(Origignal_Img15,\"Detected_New_Origigna4_Img1111\")\n",
    "# cropped_Plate16=debug_blue_crop(cropped_Plate16,\"Detected_New_Origigna4_Img1111\",False)\n",
    "\n",
    "# cropped_Plate17=debug_blue_crop(Origignal_Img111,\"Detected_New_Origigna5_Img1111\")    \n",
    "# cropped_Plate17=debug_blue_crop(cropped_Plate17,\"Detected_New_Origigna5_Img1111\",False)     \n",
    "# cropped_Plate18=debug_blue_crop(Origignal_Img112,\"Detected_New_Origigna6_Img1111\") \n",
    "# cropped_Plate18=debug_blue_crop(cropped_Plate18,\"Detected_New_Origigna6_Img1111\",False) \n",
    "# cropped_Plate19=debug_blue_crop(Origignal_Img113,\"Detected_New_Origignal_Img1111\")    \n",
    "# cropped_Plate19=debug_blue_crop(cropped_Plate19,\"Detected_New_Origignal_Img1111\",False)    \n",
    "\n",
    "# cropped_Plate22=debug_blue_crop(Origignal_Img1111,\"Detected_New_Origigna4_Img1111\")    \n",
    "# cropped_Plate22=debug_blue_crop(cropped_Plate22,\"Detected_New_Origigna4_Img1111\",False)   \n",
    "# cropped_Plate23=debug_blue_crop(Origignal_Img1112,\"Detected_New_Origigna5_Img1111\")    \n",
    "# cropped_Plate23=debug_blue_crop(cropped_Plate23,\"Detected_New_Origigna5_Img1111\",False)    \n",
    "# cropped_Plate24=debug_blue_crop(Origignal_Img1113,\"Detected_New_Origigna6_Img1111\") \n",
    "# cropped_Plate24=debug_blue_crop(cropped_Plate24,\"Detected_New_Origigna6_Img1111\",False)   \n",
    "# cropped_Plate25=debug_blue_crop(Origignal_Img1114,\"Detected_New_Origignal_Img1111\")    \n",
    "# cropped_Plate25=debug_blue_crop(cropped_Plate25,\"Detected_New_Origignal_Img1111\",False)      \n",
    " \n",
    "\n",
    "# cropped_Plate27=debug_blue_crop(Original_Img11111,\"Detected_New_Origigna4_Img1111\")    \n",
    "# cropped_Plate27=debug_blue_crop(cropped_Plate27,\"Detected_New_Origigna4_Img1111\",False)    \n",
    "# cropped_Plate28=debug_blue_crop(Original_Img11112,\"Detected_New_Origigna5_Img1111\")    \n",
    "# cropped_Plate28=debug_blue_crop(cropped_Plate28,\"Detected_New_Origigna5_Img1111\",False)     \n",
    "# cropped_Plate29=debug_blue_crop(Original_Img11113,\"Detected_New_Origigna6_Img1111\") \n",
    "# cropped_Plate29=debug_blue_crop(cropped_Plate29,\"Detected_New_Origigna6_Img1111\",False)  \n",
    "# cropped_Plate30=debug_blue_crop(Original_Img11114,\"Detected_New_Origignal_Img1111\")    \n",
    "# cropped_Plate30=debug_blue_crop(cropped_Plate30,\"Detected_New_Origignal_Img1111\",False)    \n",
    "# cropped_Plate31=debug_blue_crop(Original_Img11115,\"Detected_New_Origigna2_Img1111\") \n",
    "# cropped_Plate31=debug_blue_crop(cropped_Plate31,\"Detected_New_Origigna2_Img1111\",False)   \n",
    "\n",
    "# # cropped_Plate32=debug_blue_crop(New_Origigna7_Img1111,\"Detected_New_Origigna4_Img1111\")    \n",
    "# # cropped_Plate32=debug_blue_crop(cropped_Plate32,\"Detected_New_Origigna4_Img1111\",False)   \n",
    "# cropped_Plate33=debug_blue_crop(New_Origigna8_Img1111,\"Detected_New_Origigna5_Img1111\")    \n",
    "# cropped_Plate33=debug_blue_crop(cropped_Plate33,\"Detected_New_Origigna5_Img1111\",False)      \n",
    "# cropped_Plate34=debug_blue_crop(New_Origigna9_Img1111,\"Detected_New_Origigna6_Img1111\") \n",
    "# cropped_Plate34=debug_blue_crop(cropped_Plate34,\"Detected_New_Origigna6_Img1111\",False)   \n",
    "# cropped_Plate37=debug_blue_crop(New_Origigna12_Img1111,\"Detected_New_Origigna4_Img1111\")    \n",
    "# cropped_Plate37=debug_blue_crop(cropped_Plate37,\"Detected_New_Origigna4_Img1111\",False)    \n",
    "# cropped_Plate38=debug_blue_crop(New_Origigna13_Img1111,\"Detected_New_Origigna5_Img1111\")    \n",
    "# cropped_Plate38=debug_blue_crop(cropped_Plate38,\"Detected_New_Origigna5_Img1111\",False)    \n",
    "# cropped_Plate39=debug_blue_crop(New_Origigna14_Img1111,\"Detected_New_Origigna6_Img1111\") \n",
    "# cropped_Plate39=debug_blue_crop(cropped_Plate39,\"Detected_New_Origigna6_Img1111\",False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import os\n",
    "# from skimage import io\n",
    "\n",
    "# BASE_PATH = \"Localization Test/Vehicles\"\n",
    "\n",
    "# START_ID = 1\n",
    "# END_ID   = 2087\n",
    "\n",
    "# for i in range(START_ID, END_ID,1):\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     plt.ioff()  # disable interactive rendering\n",
    "#     fname = f\"{i:04d}.jpg\"        # 0001.jpg, 0002.jpg, ...\n",
    "#     fpath = os.path.join(BASE_PATH, fname)\n",
    "\n",
    "#     if not os.path.exists(fpath):\n",
    "#         print(f\"[SKIP] Missing: {fpath}\")\n",
    "#         continue\n",
    "\n",
    "#     try:\n",
    "#         img = io.imread(fpath)    # RGB (as you want)\n",
    "#         title = f\"Vehicle_{fname}\"\n",
    "#         print(f\"[RUN] {title}\")\n",
    "#         img1=debug_blue_crop(img, title)\n",
    "#         img2=debug_blue_crop(img1, title,False)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"[ERROR] {fname}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BASE_PATH = \"Localization Test/Vehicles\"\n",
    "OUT_DIR   = \"Localization Test/FinalCrops\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "IDS = [\n",
    "    2087, 2084, 2083, 2082, 2081, 2080, 2079, 2078,\n",
    "    2076, 2073, 2072, 2070, 2069, 2068, 2066, 2065,\n",
    "    2063, 2062, 2060, 2058, 2057, 2056, 2055, 2054,\n",
    "    2051, 2049, 2047, 2044, 2043, 2041,\n",
    "    2039, 2038, 2037, 2036, 2035, 2034,\n",
    "    2033, 2031, 2030, 2029, 2026, 2025,\n",
    "\n",
    "    1, 2, 6, 10, 13, 14, 15, 16, 25, 33, 34, 35,\n",
    "    39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
    "    51, 52, 57, 58, 59, 60, 61, 62, 63, 64, 65,\n",
    "    124\n",
    "]\n",
    "\n",
    "plt.ioff()\n",
    "\n",
    "for i in IDS:\n",
    "    fname = f\"{i:04d}.jpg\"\n",
    "    fpath = os.path.join(BASE_PATH, fname)\n",
    "\n",
    "    if not os.path.exists(fpath):\n",
    "        print(f\"[SKIP] Missing: {fname}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        img = io.imread(fpath)\n",
    "        title = f\"Vehicle_{fname}\"\n",
    "        print(f\"[RUN] {title}\")\n",
    "\n",
    "        img1 = debug_blue_crop(img, title, enable_perspective=True)\n",
    "        img2 = debug_blue_crop(img1, title, enable_perspective=False)\n",
    "\n",
    "        if img2 is not None:\n",
    "            out_path = os.path.join(OUT_DIR, f\"{i:04d}_final.png\")\n",
    "            io.imsave(out_path, img2)\n",
    "            print(f\"[SAVE] {out_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] {fname}: {e}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82e95d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import easyocr\n",
    "os.environ['TESSDATA_PREFIX'] = os.path.abspath(\"Dataset\")\n",
    "# os.environ.pop('TESSDATA_PREFIX', None)\n",
    "def add_padding(img, pad=10):\n",
    "    return cv2.copyMakeBorder(\n",
    "        img, pad, pad, pad, pad,\n",
    "        borderType=cv2.BORDER_CONSTANT,\n",
    "        value=255\n",
    "    )\n",
    "\n",
    "def add_paddingblack(img, pad=200):\n",
    "    return cv2.copyMakeBorder(\n",
    "        img, pad, pad, pad, pad,\n",
    "        borderType=cv2.BORDER_CONSTANT,\n",
    "        value=0\n",
    "    )\n",
    "\n",
    "def recognize_arabic_digit(image_path, show_preprocessed=False):\n",
    "    \"\"\"\n",
    "    Recognize a single Arabic digit from an image.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to image file.\n",
    "        show_preprocessed (bool): If True, shows the binary preprocessed image.\n",
    "    \n",
    "    Returns:\n",
    "        str: Detected Arabic digit or empty string if not recognized.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Load image\n",
    "    # img = io.imread(image_path)\n",
    "    # img=add_paddingblack(img)\n",
    "    # img=add_padding(img)\n",
    "    img=d_mask\n",
    "    \n",
    "    # # 2. Convert to grayscale if needed\n",
    "    # gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img\n",
    "    \n",
    "    # # 3. Resize image up to help OCR\n",
    "    # gray = cv2.resize(gray, None, fx=5, fy=5, interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    # # 4. Smooth image to reduce noise\n",
    "    # blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "    \n",
    "    # # 5. Threshold to get binary image\n",
    "    # _, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # # 6. Invert if background is dark\n",
    "    # if np.mean(thresh) < 127:\n",
    "    #     thresh = cv2.bitwise_not(thresh)\n",
    "    \n",
    "    # Optional: show preprocessed image\n",
    "    if show_preprocessed:\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    # 7. Configure Tesseract for single character + Arabic digits only\n",
    "    # config = f'--oem 3 --psm 10 -c tessedit_char_whitelist={ARABIC_DIGITS}'\n",
    "    \n",
    "    # 8. Run OCR\n",
    "    # text = pytesseract.image_to_string(thresh, lang='ara')\n",
    "\n",
    "    reader = easyocr.Reader(['ar'])\n",
    "    results = reader.readtext(img)\n",
    "    texts = [text for bbox, text, prob in results]\n",
    "\n",
    "\n",
    "    # 9. Clean result\n",
    "    # text = text.strip()\n",
    "    return texts\n",
    "\n",
    "# Example usage:\n",
    "digit = recognize_arabic_digit(\"letter_0.png\", show_preprocessed=True)\n",
    "print(\"Detected Arabic digit EASYOCR:\", repr(digit))\n",
    "# print(\"Detected Arabic digit:\", repr(digit))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac737b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MAAW NEW SEG\n",
    "'''\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.measure import label, regionprops\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "def extract_plate(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, 80, 200)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7,7))\n",
    "    closed = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    cnts, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnt = max(cnts, key=cv2.contourArea)\n",
    "\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "    return img[y:y+h, x:x+w]\n",
    "\n",
    "\n",
    "def crop_digits_letters_region(plate):\n",
    "    h, w = plate.shape[:2]\n",
    "\n",
    "    # Egyptian plate layout: bottom ~65% contains digits + letters\n",
    "    y0 = int(0.35 * h)\n",
    "    y1 = int(0.95 * h)\n",
    "\n",
    "    return plate[y0:y1, :]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def split_digits_letters(region_bgr):\n",
    "    h, w = region_bgr.shape[:2]\n",
    "\n",
    "    # Egyptian plate layout rule (robust to tilt)\n",
    "    split_col = int(0.58 * w)\n",
    "\n",
    "    digits = region_bgr[:, :split_col]\n",
    "    letters = region_bgr[:, split_col:]\n",
    "\n",
    "    return digits, letters\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "def get_components(region):\n",
    "    gray = cv2.cvtColor(region, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Improve contrast\n",
    "    gray = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "\n",
    "    # Global threshold (much cleaner)\n",
    "    _, bin_img = cv2.threshold(\n",
    "        gray, 0, 255,\n",
    "        cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU\n",
    "    )\n",
    "\n",
    "    # Remove small noise\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "    bin_img = cv2.morphologyEx(bin_img, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Merge letter dots\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7,7))\n",
    "    bin_img = cv2.morphologyEx(bin_img, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    labeled = label(bin_img)\n",
    "    boxes = []\n",
    "\n",
    "    H, W = bin_img.shape\n",
    "    for r in regionprops(labeled):\n",
    "        if r.area < 500:\n",
    "            continue\n",
    "        y0, x0, y1, x1 = r.bbox\n",
    "        h, w = y1 - y0, x1 - x0\n",
    "        if h < 0.35*H or w < 0.05*W:\n",
    "            continue\n",
    "        boxes.append((x0,y0,x1,y1))\n",
    "\n",
    "    boxes = sorted(boxes, key=lambda b: b[0])\n",
    "\n",
    "    # Enforce Egyptian plate rules\n",
    "    if len(boxes) > 3:\n",
    "        # Keep the 3 widest components (letters are wide)\n",
    "        boxes = sorted(boxes, key=lambda b: (b[2] - b[0]), reverse=True)[:3]\n",
    "        boxes = sorted(boxes, key=lambda b: b[0])\n",
    "\n",
    "\n",
    "    if len(boxes) > 4:\n",
    "        boxes = sorted(boxes, key=lambda b: (b[2] - b[0]), reverse=True)[:4]\n",
    "        boxes = sorted(boxes, key=lambda b: b[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return bin_img, boxes\n",
    "'''\n",
    "\n",
    "def touches_border(x0, y0, x1, y1, W, H, margin=2):\n",
    "    return (x0 <= margin) or (y0 <= margin) or (x1 >= W - margin) or (y1 >= H - margin)\n",
    "\n",
    "def get_components(region_bgr, kind=\"digits\"):\n",
    "    gray = cv2.cvtColor(region_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "\n",
    "    # Clean binary mask (white chars on black)\n",
    "    _, bin_img = cv2.threshold(\n",
    "        gray, 0, 255,\n",
    "        cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU\n",
    "    )\n",
    "\n",
    "    # Small noise removal (keep strokes)\n",
    "    bin_img = cv2.morphologyEx(\n",
    "        bin_img,\n",
    "        cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "    )\n",
    "\n",
    "    # DIFFERENT closing for digits vs letters\n",
    "    if kind == \"letters\":\n",
    "        # Connect Arabic dots + separated parts vertically (important for ى, ي, ن, ق...)\n",
    "        close_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 11))  # tall vertical\n",
    "    else:\n",
    "        # Digits: avoid merging neighbors\n",
    "        close_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 7))\n",
    "\n",
    "    bin_img = cv2.morphologyEx(bin_img, cv2.MORPH_CLOSE, close_kernel)\n",
    "\n",
    "    labeled = label(bin_img)\n",
    "    boxes = []\n",
    "\n",
    "    H, W = bin_img.shape\n",
    "\n",
    "    # Area thresholds (digits can be smaller than letters)\n",
    "    min_area = 180 if kind == \"digits\" else 300\n",
    "\n",
    "    for r in regionprops(labeled):\n",
    "        if r.area < min_area:\n",
    "            continue\n",
    "\n",
    "        y0, x0, y1, x1 = r.bbox\n",
    "        h = y1 - y0\n",
    "        w = x1 - x0\n",
    "\n",
    "        # Reject border fragments (fixes the right frame being a \"letter\")\n",
    "        if touches_border(x0, y0, x1, y1, W, H, margin=2):\n",
    "            continue\n",
    "\n",
    "        # Basic size constraints\n",
    "        if h < 0.35 * H:\n",
    "            continue\n",
    "        if w < 0.03 * W:\n",
    "            continue\n",
    "\n",
    "        # Reject thin vertical frame-like components\n",
    "        aspect = w / float(h)\n",
    "        if aspect < 0.08:   # very thin & tall => border / separator\n",
    "            continue\n",
    "\n",
    "        boxes.append((x0, y0, x1, y1))\n",
    "\n",
    "    # left->right\n",
    "    boxes = sorted(boxes, key=lambda b: b[0])\n",
    "    return bin_img, boxes\n",
    "\n",
    "\n",
    "def draw_boxes(mask, boxes):\n",
    "    out = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n",
    "    for x0,y0,x1,y1 in boxes:\n",
    "        cv2.rectangle(out,(x0,y0),(x1,y1),(255,0,0),2)\n",
    "    return out\n",
    "\n",
    "\n",
    "def extract_chars(region, boxes, reverse=False):\n",
    "    boxes = sorted(boxes, key=lambda b: b[0], reverse=reverse)\n",
    "    chars = []\n",
    "    for x0,y0,x1,y1 in boxes:\n",
    "        chars.append(region[y0:y1, x0:x1])\n",
    "    return chars\n",
    "\n",
    "\n",
    "\n",
    "def trim_borders(img, px=6):\n",
    "    h, w = img.shape[:2]\n",
    "    return img[px:h-px, px:w-px]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "img_bgr = cropped_Plate7\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plate = extract_plate(img_bgr)\n",
    "\n",
    "dl_region = crop_digits_letters_region(plate)\n",
    "dl_region = trim_borders(dl_region, px=4)\n",
    "\n",
    "# FINAL robust split\n",
    "digits_region, letters_region = split_digits_letters(dl_region)\n",
    "\n",
    "d_mask, d_boxes = get_components(digits_region, kind=\"digits\")\n",
    "l_mask, l_boxes = get_components(letters_region, kind=\"letters\")\n",
    "\n",
    "\n",
    "# Keep at most 4 digits: choose by area (largest blobs)\n",
    "if len(d_boxes) > 4:\n",
    "    d_boxes = sorted(d_boxes, key=lambda b: (b[2]-b[0])*(b[3]-b[1]), reverse=True)[:4]\n",
    "    d_boxes = sorted(d_boxes, key=lambda b: b[0])\n",
    "\n",
    "# Keep at most 3 letters: choose by area (largest blobs)\n",
    "if len(l_boxes) > 3:\n",
    "    l_boxes = sorted(l_boxes, key=lambda b: (b[2]-b[0])*(b[3]-b[1]), reverse=True)[:3]\n",
    "    l_boxes = sorted(l_boxes, key=lambda b: b[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "BASE_OUT_DIR = \"output_chars\"\n",
    "#BASE_OUT_DIR = \"Image-Processing-Project\"\n",
    "DIGITS_DIR = os.path.join(BASE_OUT_DIR, \"digits\")\n",
    "LETTERS_DIR = os.path.join(BASE_OUT_DIR, \"letters\")\n",
    "\n",
    "os.makedirs(DIGITS_DIR, exist_ok=True)\n",
    "os.makedirs(LETTERS_DIR, exist_ok=True)\n",
    "\n",
    "def clear_old_files(folder, pattern):\n",
    "    for f in glob.glob(os.path.join(folder, pattern)):\n",
    "        os.remove(f)\n",
    "\n",
    "# Clear previous results\n",
    "clear_old_files(DIGITS_DIR, \"digit_*.png\")\n",
    "clear_old_files(LETTERS_DIR, \"letter_*.png\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "digits = extract_chars(d_mask, d_boxes, reverse=False)\n",
    "letters = extract_chars(l_mask, l_boxes, reverse=True)\n",
    "TARGET_SIZE = (150, 150)\n",
    "\n",
    "# Save digits\n",
    "for i, d in enumerate(digits):\n",
    "    d_resized = cv2.resize(d, TARGET_SIZE, interpolation=cv2.INTER_AREA)\n",
    "    save_path = os.path.join(DIGITS_DIR, f\"digit_{i}.png\")\n",
    "    cv2.imwrite(save_path, d_resized)\n",
    "\n",
    "# Save letters\n",
    "for i, l in enumerate(letters):\n",
    "    l_resized = cv2.resize(l, TARGET_SIZE, interpolation=cv2.INTER_AREA)\n",
    "    save_path = os.path.join(LETTERS_DIR, f\"letter_{i}.png\")\n",
    "    cv2.imwrite(save_path, l_resized)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "d_boxes_img = draw_boxes(d_mask, d_boxes)\n",
    "l_boxes_img = draw_boxes(l_mask, l_boxes)\n",
    "\n",
    "\n",
    "show_images(\n",
    "    [\n",
    "        img_rgb,\n",
    "        cv2.cvtColor(plate, cv2.COLOR_BGR2RGB),\n",
    "        cv2.cvtColor(dl_region, cv2.COLOR_BGR2RGB),\n",
    "        cv2.cvtColor(digits_region, cv2.COLOR_BGR2RGB),\n",
    "        cv2.cvtColor(letters_region, cv2.COLOR_BGR2RGB)\n",
    "    ],\n",
    "    [\"Original\", \"Plate Crop\", \"Digits+Letters\", \"Digits Region\", \"Letters Region\"]\n",
    ")\n",
    "\n",
    "\n",
    "show_images([d_mask, l_mask], [\"Digits Mask\", \"Letters Mask\"])\n",
    "show_images([d_boxes_img, l_boxes_img], [\"Digits Boxes\", \"Letters Boxes\"])\n",
    "\n",
    "show_images(digits, [f\"Digit {i+1}\" for i in range(len(digits))])\n",
    "show_images(letters, [f\"Letter {i+1}\" for i in range(len(letters))])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "MAAW NEW SEG\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f156149",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MAAW SEGMENTATION\n",
    "'''\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray, rgba2rgb\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.morphology import (\n",
    "    remove_small_holes,\n",
    "    remove_small_objects,\n",
    "    binary_closing,\n",
    "    square,\n",
    ")\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.transform import resize\n",
    "from skimage.color import gray2rgb\n",
    "\n",
    "\n",
    "def crop_bottom(img, top_ratio=0.40):\n",
    "    h, w = img.shape[:2]\n",
    "    return img[int(h * top_ratio):, :]\n",
    "\n",
    "\n",
    "def split_digits_letters(bottom):\n",
    "    h, w = bottom.shape[:2]\n",
    "    mid = w // 2\n",
    "    return bottom[:, :mid], bottom[:, mid:]\n",
    "\n",
    "\n",
    "def get_mask(region):\n",
    "    gray = rgb2gray(region)\n",
    "\n",
    "    T = threshold_otsu(gray)\n",
    "    mask = gray < T\n",
    "\n",
    "    mask = remove_small_objects(mask, 25)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def touches_border(r0, c0, r1, c1, H, W, margin_ratio=0.005):\n",
    "    mr = int(margin_ratio * H)\n",
    "    mc = int(margin_ratio * W)\n",
    "\n",
    "    if r0 <= mr: return True        # top\n",
    "    if c0 <= mc: return True        # left\n",
    "    if r1 >= H - mr: return True    # bottom\n",
    "    if c1 >= W - mc: return True    # right\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "def extract_digits(digits_region, max_chars=4, debug=False):\n",
    "    H0, W0 = digits_region.shape[:2]\n",
    "    border_ratio = 0.04\n",
    "    by = int(border_ratio * H0)\n",
    "    bx = int(border_ratio * W0)\n",
    "    sub = digits_region[by:H0 - by, bx:W0 - bx]\n",
    "    \n",
    "    mask = get_mask(sub)\n",
    "    H, W = mask.shape\n",
    "    \n",
    "    def remove_frame_components(mask):\n",
    "        H, W = mask.shape\n",
    "        lbl = label(mask)\n",
    "\n",
    "        for p in regionprops(lbl):\n",
    "            r0, c0, r1, c1 = p.bbox\n",
    "            h = r1 - r0\n",
    "            w = c1 - c0\n",
    "\n",
    "            wr = w / (W + 1e-6)\n",
    "            hr = h / (H + 1e-6)\n",
    "\n",
    "            near_edge = (r0 < 0.20 * H) or (r1 > 0.80 * H) #very wide, thin, near top or bottom\n",
    "\n",
    "            if near_edge and wr > 0.75 and hr < 0.12:\n",
    "                mask[lbl == p.label] = 0\n",
    "\n",
    "        return mask\n",
    "\n",
    "    mask = remove_frame_components(mask)\n",
    "    \n",
    "    def touches_top_or_bottom(r0, r1, H, margin=2):\n",
    "        return r0 <= margin or r1 >= H - margin\n",
    "\n",
    "    def is_horizontal_frame(h, w, H, W, r0, r1):\n",
    "        very_wide = w > 0.65 * W\n",
    "        very_thin = h < 0.12 * H\n",
    "        near_edge = r0 < 0.15 * H or r1 > 0.85 * H\n",
    "        return very_wide and very_thin and near_edge\n",
    "\n",
    "\n",
    "\n",
    "    lbl = label(mask)\n",
    "\n",
    "    candidates = []\n",
    "    for p in regionprops(lbl):\n",
    "        r0, c0, r1, c1 = p.bbox\n",
    "\n",
    "        if touches_top_or_bottom(r0, r1, H):\n",
    "            continue\n",
    "\n",
    "        h = r1 - r0\n",
    "        w = c1 - c0\n",
    "        area = p.area\n",
    "        wr = w / W\n",
    "        ar = area / (H * W)\n",
    "\n",
    "        if is_horizontal_frame(h, w, H, W, r0, r1):\n",
    "            continue\n",
    "\n",
    "        if wr < 0.035 or wr > 0.75:\n",
    "            continue\n",
    "\n",
    "        if ar < 0.001:\n",
    "            continue\n",
    "\n",
    "        candidates.append({\"bbox\": [r0, c0, r1, c1], \"area\": area})\n",
    "\n",
    "    candidates.sort(key=lambda c: c[\"bbox\"][1])\n",
    "\n",
    "\n",
    "    merged = []\n",
    "    for c in candidates:\n",
    "        if not merged:\n",
    "            merged.append(c)\n",
    "            continue\n",
    "\n",
    "        r0, c0, r1, c1 = c[\"bbox\"]\n",
    "        r0m, c0m, r1m, c1m = merged[-1][\"bbox\"]\n",
    "\n",
    "        overlap_x = min(c1, c1m) - max(c0, c0m)\n",
    "        overlap_y = min(r1, r1m) - max(r0, r0m)\n",
    "\n",
    "        #only merge if they overlap in X and Y or very close vertically\n",
    "        vertical_gap = max(r0, r0m) - min(r1, r1m) #negative means it overlaps\n",
    "\n",
    "        if overlap_x > 0 and (overlap_y > 0 or vertical_gap < 0.08 * H):\n",
    "            merged[-1][\"bbox\"] = [\n",
    "                min(r0, r0m), min(c0, c0m),\n",
    "                max(r1, r1m), max(c1, c1m)\n",
    "            ]\n",
    "        else:\n",
    "            merged.append(c)\n",
    "\n",
    "    boxed_mask = gray2rgb(mask.astype(np.uint8) * 255)\n",
    "\n",
    "    chars = []\n",
    "    for m in merged:\n",
    "        r0, c0, r1, c1 = m[\"bbox\"]\n",
    "        if (r1 - r0) < 0.22 * H:\n",
    "            continue\n",
    "\n",
    "        boxed_mask[r0:r1, [c0, c1-1]] = [255, 0, 0]\n",
    "        boxed_mask[[r0, r1-1], c0:c1] = [255, 0, 0]\n",
    "\n",
    "        crop = resize(mask[r0:r1, c0:c1].astype(float), (40, 40))\n",
    "        chars.append((c0 + bx, crop))\n",
    "\n",
    "    chars.sort(key=lambda x: x[0])\n",
    "\n",
    "    if debug:\n",
    "        return [c for _, c in chars][:max_chars], mask, boxed_mask\n",
    "    else:\n",
    "        return [c for _, c in chars][:max_chars]\n",
    "\n",
    "\n",
    "\n",
    "def extract_letters(letters_region, max_chars=3, debug=False):\n",
    "    H0, W0 = letters_region.shape[:2]\n",
    "    by = int(0.04 * H0)\n",
    "    bx = int(0.04 * W0)\n",
    "    sub = letters_region[by:H0 - by, bx:W0 - bx]\n",
    "\n",
    "    mask = get_mask(sub)\n",
    "    H, W = mask.shape\n",
    "    lbl = label(mask)\n",
    "\n",
    "    boxed_mask = gray2rgb(mask.astype(np.uint8) * 255)\n",
    "\n",
    "    big_blobs = []   #letter body\n",
    "    small_blobs = [] #dots\n",
    "\n",
    "\n",
    "    for p in regionprops(lbl):\n",
    "        r0, c0, r1, c1 = p.bbox\n",
    "\n",
    "        if touches_border(r0, c0, r1, c1, H, W, margin_ratio=0.02):\n",
    "            continue\n",
    "    \n",
    "        h = r1 - r0\n",
    "        w = c1 - c0\n",
    "        area = p.area\n",
    "        cy = p.centroid[0] / H\n",
    "        wr = w / W\n",
    "        ar = area / (H * W)\n",
    "\n",
    "        #dot (area < 0.015)\n",
    "        if ar < 0.015:\n",
    "            small_blobs.append((r0, c0, r1, c1))\n",
    "            continue\n",
    "\n",
    "        #main letter filtering\n",
    "        if wr < 0.08 or wr > 0.75:\n",
    "            continue\n",
    "        if ar > 0.22:\n",
    "            continue\n",
    "        if cy > 0.75:\n",
    "            continue\n",
    "\n",
    "        big_blobs.append([r0, c0, r1, c1])\n",
    "\n",
    "\n",
    "    for dr0, dc0, dr1, dc1 in small_blobs:\n",
    "        dc = (dc0 + dc1) / 2\n",
    "        dr = (dr0 + dr1) / 2\n",
    "\n",
    "        best_i = -1\n",
    "        best_dx = 1e9\n",
    "\n",
    "        for i, box in enumerate(big_blobs):\n",
    "            r0, c0, r1, c1 = box\n",
    "            bc = (c0 + c1) / 2\n",
    "            br = (r0 + r1) / 2\n",
    "\n",
    "            dx = abs(dc - bc)\n",
    "            dy = abs(dr - br)\n",
    "\n",
    "            #vertically and horizontally closest\n",
    "            if dx < best_dx and dy < 120:\n",
    "                best_dx = dx\n",
    "                best_i = i\n",
    "\n",
    "        #attach dot to nearest valid letter ONLY\n",
    "        if best_i != -1:\n",
    "            box = big_blobs[best_i]\n",
    "            box[0] = min(box[0], dr0)\n",
    "            box[1] = min(box[1], dc0)\n",
    "            box[2] = max(box[2], dr1)\n",
    "            box[3] = max(box[3], dc1)\n",
    "\n",
    "\n",
    "    big_blobs.sort(key=lambda b: b[1])\n",
    "\n",
    "\n",
    "    #new\n",
    "    # ---------- MERGE BROKEN LETTER BODIES (e.g. س) ----------\n",
    "    merged = []\n",
    "    for box in sorted(big_blobs, key=lambda b: b[1]):\n",
    "        if not merged:\n",
    "            merged.append(box)\n",
    "            continue\n",
    "\n",
    "        r0, c0, r1, c1 = box\n",
    "        pr0, pc0, pr1, pc1 = merged[-1]\n",
    "\n",
    "        # horizontal gap\n",
    "        gap = c0 - pc1\n",
    "\n",
    "        # vertical overlap\n",
    "        overlap = min(r1, pr1) - max(r0, pr0)\n",
    "\n",
    "        if gap < 0.15 * W and overlap > 0.3 * min(r1 - r0, pr1 - pr0):\n",
    "            # merge\n",
    "            merged[-1] = [\n",
    "                min(r0, pr0),\n",
    "                min(c0, pc0),\n",
    "                max(r1, pr1),\n",
    "                max(c1, pc1)\n",
    "            ]\n",
    "        else:\n",
    "            merged.append(box)\n",
    "\n",
    "    big_blobs = merged\n",
    "\n",
    "    #new\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    chars = []\n",
    "    for r0, c0, r1, c1 in big_blobs:\n",
    "        boxed_mask[r0:r1, [c0, c1-1]] = [255, 0, 0]\n",
    "        boxed_mask[[r0, r1-1], c0:c1] = [255, 0, 0]\n",
    "\n",
    "        crop = resize(mask[r0:r1, c0:c1].astype(float), (40, 40))\n",
    "        chars.append((c0 + bx, crop))\n",
    "\n",
    "    if debug:\n",
    "        return [c for _, c in chars][:max_chars], mask, boxed_mask\n",
    "    else:\n",
    "        return [c for _, c in chars][:max_chars]\n",
    "\n",
    "\n",
    "\n",
    "def process_plate(img):\n",
    "    bottom = crop_bottom(img)\n",
    "    digits_region, letters_region = split_digits_letters(bottom)\n",
    "\n",
    "    digits, d_mask, d_boxes = extract_digits(digits_region, debug=True)\n",
    "    letters, l_mask, l_boxes = extract_letters(letters_region, debug=True)\n",
    "\n",
    "    return digits_region, letters_region, digits, letters, d_mask, d_boxes, l_mask, l_boxes\n",
    "\n",
    "\n",
    "img22 = imread('Q1.jpg')\n",
    "#img22 = imread('Dataset/Buses & government vehicles.png')\n",
    "#img22 = imread('Dataset/Diplomatic vehicles.png')\n",
    "#img22 = imread('Dataset/image.png')\n",
    "#img22 = imread('Dataset/Limousines & tourist buses.png')\n",
    "#img22 = imread('Dataset/Police vehicles.png')\n",
    "# img22 = rgba2rgb(imread('Dataset/Private vehicles & motorcycles.png'))\n",
    "#img22 = rgba2rgb(imread('Dataset/Taxis.png'))\n",
    "#img22 = imread('Dataset/Trucks.png')\n",
    "#img22 = imread('Dataset/Vehicles with unpaid customs.png')\n",
    "\n",
    "#etsh cropped tests########################\n",
    "# img22 = cropped_Plate1\n",
    "# img22 = cropped_Plate2 #blur problem\n",
    "#img22 = rgba2rgb(imread('Q1C.png'))\n",
    "# img22 = cropped_Plate3 #blur problem\n",
    "# img22 = cropped_Plate5 #FIXED frame counting as letter from left\n",
    "# img22 = cropped_Plate11 #FIXED digit border on top detected  \n",
    "# img22 = cropped_Plate12 #FIXED border in digit detected\n",
    "# img22 = cropped_Plate13 #FIXED border detected as letter\n",
    "#img22 = cropped_Plate15 #blur problem\n",
    "#img22 = cropped_Plate111 ##\n",
    "#img22 = cropped_Plate112 #blur problem\n",
    "#img22 = cropped_Plate113 #blur problem\n",
    "#img22 = cropped_Plate115 ##\n",
    "#img22 = cropped_Plate1111 #hard angle\n",
    "#img22 = cropped_Plate1112 #hard angle\n",
    "#img22 = cropped_Plate1113 #blur problem\n",
    "#img22 = cropped_Plate1115 #blur\n",
    "#img22 = cropped_Plate11113 #blur\n",
    "#img22 = cropped_Plate11114 ##\n",
    "#img22 = cropped_Plate11115 ##\n",
    "#img22 = cropped_Plate11116 ##\n",
    "#img22 = cropped_Plate11117 ##\n",
    "\n",
    "#etsh cropped tests########################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "def clear_previous_outputs():\n",
    "    files = [\n",
    "        \"digit_0.png\", \"digit_1.png\", \"digit_2.png\", \"digit_3.png\", \"digit_4.png\", \"letter_0.png\", \"letter_1.png\", \"letter_2.png\"\n",
    "    ]\n",
    "\n",
    "    for f in files:\n",
    "        if os.path.exists(f):\n",
    "            os.remove(f)\n",
    "\n",
    "\n",
    "def save_characters(digits, letters):\n",
    "    #digits\n",
    "    for i, img in enumerate(digits):\n",
    "        out = (img * 255).astype(np.uint8) if img.dtype != np.uint8 else img\n",
    "        cv2.imwrite(f\"digit_{i}.png\", out)\n",
    "\n",
    "    #letters\n",
    "    for i, img in enumerate(letters):\n",
    "        out = (img * 255).astype(np.uint8) if img.dtype != np.uint8 else img\n",
    "        cv2.imwrite(f\"letter_{i}.png\", out)\n",
    "\n",
    "\n",
    "clear_previous_outputs()\n",
    "\n",
    "d_reg, l_reg, digits, letters, d_mask, d_boxes, l_mask, l_boxes = process_plate(img22)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "show_images([d_reg, l_reg], [\"Digits Region\", \"Letters Region\"])\n",
    "\n",
    "show_images([d_mask, l_mask], [\"Digits Mask\", \"Letters Mask\"])\n",
    "\n",
    "show_images([d_boxes, l_boxes], [\"Digits Mask + Boxes\", \"Letters Mask + Boxes\"])\n",
    "\n",
    "digit_titles = [f\"Digit {i}\" for i in range(len(digits))]\n",
    "show_images(digits, digit_titles)\n",
    "\n",
    "letter_titles = [f\"Letter {i}\" for i in range(len(letters))]\n",
    "show_images(letters, letter_titles)\n",
    "\n",
    "\n",
    "save_characters(digits,letters)\n",
    "\n",
    "\n",
    "#RUN LOOP\n",
    "\n",
    "for i in range(1, 40):\n",
    "    img = globals()[f\"cropped_Plate{i}\"]\n",
    "\n",
    "    (\n",
    "        d_reg, l_reg,\n",
    "        digits, letters,\n",
    "        d_mask, d_boxes,\n",
    "        l_mask, l_boxes\n",
    "    ) = process_plate(img)\n",
    "\n",
    "    show_images([d_reg, l_reg], [\"Digits Region\", \"Letters Region\"])\n",
    "    show_images([d_mask, l_mask], [\"Digits Mask\", \"Letters Mask\"])\n",
    "    show_images([d_boxes, l_boxes], [\"Digits Mask + Boxes\", \"Letters Mask + Boxes\"])\n",
    "\n",
    "    digit_titles = [f\"Digit {j}\" for j in range(len(digits))]\n",
    "    show_images(digits, digit_titles)\n",
    "\n",
    "    letter_titles = [f\"Letter {j}\" for j in range(len(letters))]\n",
    "    show_images(letters, letter_titles)\n",
    "\n",
    "\n",
    "#RUN LOOP\n",
    "\n",
    "\n",
    "'''\n",
    "'''\n",
    "MAAW SEGMENTATION\n",
    "'''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf60faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MAAW DIGIT AND LETTER RECOGNITION\n",
    "'''\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import os\n",
    "\n",
    "\n",
    "english_to_arabic = {\n",
    "    1: '١',\n",
    "    2: '٢',\n",
    "    3: '٣',\n",
    "    4: '٤',\n",
    "    5: '٥',\n",
    "    6: '٦',\n",
    "    7: '٧',\n",
    "    8: '٨',\n",
    "    9: '٩'\n",
    "    }\n",
    "\n",
    "\n",
    "def normalize_digit(img):\n",
    "    img = img.copy()\n",
    "\n",
    "    if np.mean(img) > 127:\n",
    "        img = cv2.bitwise_not(img)\n",
    "\n",
    "    ys, xs = np.where(img > 0)\n",
    "    if len(xs) == 0:\n",
    "        return cv2.resize(img, (64, 64))\n",
    "\n",
    "    x0, x1 = xs.min(), xs.max()\n",
    "    y0, y1 = ys.min(), ys.max()\n",
    "    img = img[y0:y1+1, x0:x1+1]\n",
    "\n",
    "    img = cv2.copyMakeBorder(img, 12, 12, 12, 12, cv2.BORDER_CONSTANT, value=0)\n",
    "\n",
    "    img = cv2.resize(img, (64, 64), interpolation=cv2.INTER_NEAREST)\n",
    "    return img.astype(np.uint8)\n",
    "\n",
    "\n",
    "def match_digit(img, refs_folder=\"digits_reference\"):\n",
    "    img = normalize_digit(img)\n",
    "\n",
    "    scores = {}\n",
    "\n",
    "    for d in range(1,10):\n",
    "        digit_folder = os.path.join(refs_folder, str(d))\n",
    "        if not os.path.exists(digit_folder):\n",
    "            continue\n",
    "\n",
    "        best_local = -1\n",
    "\n",
    "        for fname in os.listdir(digit_folder):\n",
    "            ref = cv2.imread(os.path.join(digit_folder, fname), 0)\n",
    "            ref = normalize_digit(ref)\n",
    "\n",
    "            score = ssim(img, ref)\n",
    "            best_local = max(best_local, score)\n",
    "\n",
    "        scores[d] = best_local\n",
    "\n",
    "    best_digit = max(scores, key=scores.get)\n",
    "\n",
    "    return best_digit\n",
    "\n",
    "final_digits_english = []\n",
    "final_digits_arabic  = []\n",
    "\n",
    "for d in digits:\n",
    "    d_img = d.astype(np.uint8) \n",
    "    digit = match_digit(d_img)\n",
    "\n",
    "    final_digits_english.append(str(digit))\n",
    "    final_digits_arabic.append(english_to_arabic[digit])\n",
    "\n",
    "print(\"Plate Digits In English:\", \"\".join(final_digits_english))\n",
    "print(\"Plate Digits In Arabic: \", \"\".join(final_digits_arabic))\n",
    "\n",
    "\n",
    "\n",
    "letter_id_to_arabic = {\n",
    "    1: 'أ',\n",
    "    2: 'ب',\n",
    "    3: 'ج',\n",
    "    4: 'د',\n",
    "    5: 'ر',\n",
    "    6: 'ز',\n",
    "    7: 'س',\n",
    "    8: 'ص',\n",
    "    9: 'ض',\n",
    "    10: 'ط',\n",
    "    11: 'ع',\n",
    "    12: 'ف',\n",
    "    13: 'ق',\n",
    "    14: 'ك',\n",
    "    15: 'ل',\n",
    "    16: 'م',\n",
    "    17: 'ن',\n",
    "    18: 'ه',\n",
    "    19: 'و',\n",
    "    20: 'ي',\n",
    "    21: 'ى'\n",
    "}\n",
    "\n",
    "\n",
    "def normalize_letter(img):\n",
    "    img = img.copy()\n",
    "\n",
    "    if np.mean(img) > 127:\n",
    "        img = cv2.bitwise_not(img)\n",
    "\n",
    "    ys, xs = np.where(img > 0)\n",
    "    if len(xs) == 0:\n",
    "        return cv2.resize(img, (64, 64))\n",
    "\n",
    "    x0, x1 = xs.min(), xs.max()\n",
    "    y0, y1 = ys.min(), ys.max()\n",
    "    img = img[y0:y1+1, x0:x1+1]\n",
    "\n",
    "    img = cv2.copyMakeBorder(\n",
    "        img, 12, 12, 12, 12,\n",
    "        cv2.BORDER_CONSTANT, value=0\n",
    "    )\n",
    "\n",
    "    img = cv2.resize(img, (64, 64), interpolation=cv2.INTER_NEAREST)\n",
    "    return img.astype(np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "def match_letter(img, refs_folder=\"letters_reference\"):\n",
    "    img = normalize_letter(img)\n",
    "\n",
    "    scores = {}\n",
    "\n",
    "    for letter_id in range(1, 22):\n",
    "        letter_folder = os.path.join(refs_folder, str(letter_id))\n",
    "        if not os.path.exists(letter_folder):\n",
    "            continue\n",
    "\n",
    "        best_local = -1\n",
    "\n",
    "        for fname in os.listdir(letter_folder):\n",
    "            ref = cv2.imread(os.path.join(letter_folder, fname), 0)\n",
    "            if ref is None:\n",
    "                continue\n",
    "\n",
    "            ref = normalize_letter(ref)\n",
    "            score = ssim(img, ref)\n",
    "            best_local = max(best_local, score)\n",
    "\n",
    "        scores[letter_id] = best_local\n",
    "\n",
    "    best_letter_id = max(scores, key=scores.get)\n",
    "    return best_letter_id\n",
    "\n",
    "\n",
    "final_letters_arabic = []\n",
    "\n",
    "for l in letters:\n",
    "    l_img = l.astype(np.uint8)   \n",
    "    letter_id = match_letter(l_img)\n",
    "\n",
    "\n",
    "    final_letters_arabic.append(letter_id_to_arabic[letter_id])\n",
    "\n",
    "final_plate_letters = \" \".join(final_letters_arabic[::-1])\n",
    "\n",
    "print(\"Plate Letters: \", final_plate_letters)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "MAAW DIGIT AND LETTER RECOGNITION\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4522eea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import easyocr\n",
    "os.environ['TESSDATA_PREFIX'] = os.path.abspath(\"Dataset\")\n",
    "# os.environ.pop('TESSDATA_PREFIX', None)\n",
    "def add_padding(img, pad=10):\n",
    "    return cv2.copyMakeBorder(\n",
    "        img, pad, pad, pad, pad,\n",
    "        borderType=cv2.BORDER_CONSTANT,\n",
    "        value=255\n",
    "    )\n",
    "\n",
    "def add_paddingblack(img, pad=50):\n",
    "    return cv2.copyMakeBorder(\n",
    "        img, pad, pad, pad, pad,\n",
    "        borderType=cv2.BORDER_CONSTANT,\n",
    "        value=0\n",
    "    )\n",
    "\n",
    "\n",
    "def pad_for_easyocr(img):\n",
    "    h, w = img.shape\n",
    "    new_img = np.zeros((h, w*3), dtype=np.uint8)  # black background\n",
    "    new_img[:, w:w*2] = img  # center the character\n",
    "    return new_img\n",
    "\n",
    "\n",
    "def recognize_arabic_digit(image_path, show_preprocessed=False):\n",
    "    \"\"\"\n",
    "    Recognize a single Arabic digit from an image.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to image file.\n",
    "        show_preprocessed (bool): If True, shows the binary preprocessed image.\n",
    "    \n",
    "    Returns:\n",
    "        str: Detected Arabic digit or empty string if not recognized.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Load image\n",
    "    img = io.imread(image_path)\n",
    "    # img=add_paddingblack(img)\n",
    "    # img=pad_for_easyocr(img)\n",
    "    \n",
    "    # img=add_padding(img)\n",
    "    # img=d_mask\n",
    "    if img.dtype == bool:\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "\n",
    "    # # Ensure grayscale, not weird format\n",
    "    # if len(img.shape) == 2:\n",
    "    #     img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    # # 2. Convert to grayscale if needed\n",
    "    # gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img\n",
    "    \n",
    "    # # 3. Resize image up to help OCR\n",
    "    # gray = cv2.resize(gray, None, fx=5, fy=5, interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    # # 4. Smooth image to reduce noise\n",
    "    # blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "    \n",
    "    # # 5. Threshold to get binary image\n",
    "    # _, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # # 6. Invert if background is dark\n",
    "    # if np.mean(thresh) < 127:\n",
    "    #     thresh = cv2.bitwise_not(thresh)\n",
    "    \n",
    "    # # Optional: show preprocessed image\n",
    "    if show_preprocessed:\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    # 7. Configure Tesseract for single character + Arabic digits only\n",
    "    # config = f'--oem 3 --psm 10 -c tessedit_char_whitelist={ARABIC_DIGITS}'\n",
    "    \n",
    "    # 8. Run OCR\n",
    "    # text = pytesseract.image_to_string(thresh, lang='ara')\n",
    "\n",
    "    reader = easyocr.Reader(['ar'])\n",
    "    results = reader.readtext(img)\n",
    "    texts = [text for bbox, text, prob in results]\n",
    "\n",
    "\n",
    "    # 9. Clean result\n",
    "    # text = text.strip()\n",
    "    return texts\n",
    "\n",
    "# Example usage:\n",
    "digit = recognize_arabic_digit(\"letter_0.png\", show_preprocessed=True)\n",
    "print(\"Detected Arabic digit EASYOCR:\", repr(digit))\n",
    "# print(\"Detected Arabic digit:\", repr(digit))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f5b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "reader = easyocr.Reader(['ar'], gpu=False)  # make this global or at module level\n",
    "\n",
    "def prepare_for_easyocr_char(img):\n",
    "    \"\"\"\n",
    "    img: numpy array (grayscale or RGB) containing ONE character.\n",
    "    Returns a padded, upscaled image suitable for EasyOCR.\n",
    "    \"\"\"\n",
    "\n",
    "    # If bool -> uint8\n",
    "    if img.dtype == bool:\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    if img.ndim == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        img = img.astype(np.uint8)\n",
    "\n",
    "    # Normalize range\n",
    "    if img.max() <= 1:\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "\n",
    "    # Binarize a bit to stabilize\n",
    "    _, img = cv2.threshold(img, 0, 255,\n",
    "                           cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Make sure text is dark on light (helps EasyOCR)\n",
    "    if img.mean() < 127:      # mostly dark => likely white on black\n",
    "        img = 255 - img       # invert to black text on white\n",
    "\n",
    "    # ---- FIX #1: add margin so glyph doesn't touch borders ----\n",
    "    border = 20\n",
    "    img = cv2.copyMakeBorder(\n",
    "        img, border, border, border, border,\n",
    "        borderType=cv2.BORDER_CONSTANT,\n",
    "        value=255  # white background\n",
    "    )\n",
    "\n",
    "    # ---- FIX #2: upscale ----\n",
    "    img = cv2.resize(img, None, fx=5, fy=5,\n",
    "                     interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def recognize_single_char_easyocr(image_path, show=False):\n",
    "    # load from file\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    prep = prepare_for_easyocr_char(img)\n",
    "\n",
    "    if show:\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.imshow(prep, cmap='gray')\n",
    "        plt.axis('off'); plt.show()\n",
    "\n",
    "    # detail=0 -> just texts; paragraph=False so it doesn't merge things\n",
    "    texts = reader.readtext(prep, detail=0, paragraph=False)\n",
    "\n",
    "    return texts[0] if texts else \"\"\n",
    "\n",
    "digit0 = recognize_single_char_easyocr(\"clean_digits.png\", show=True)\n",
    "letter0 = recognize_single_char_easyocr(\"clean_letters.png\", show=True)\n",
    "print(\"digit_0:\", repr(digit0))\n",
    "print(\"letter_0:\", repr(letter0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cddadb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MAAW FORTNITE BATTLE ROYALE\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2                         ### <<< you were using cv2 in save_characters\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray, rgba2rgb\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.morphology import (\n",
    "    remove_small_holes,\n",
    "    remove_small_objects,\n",
    "    binary_closing,\n",
    "    square,\n",
    ")\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.transform import resize\n",
    "from skimage.color import gray2rgb\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 1) SIMPLE GEOMETRIC UTILITIES\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def crop_bottom(img, top_ratio=0.40):\n",
    "    \"\"\"\n",
    "    Keep the lower part of the plate (digits + letters).\n",
    "    top_ratio is the fraction of height we cut from the top.\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    return img[int(h * top_ratio):, :]\n",
    "\n",
    "\n",
    "def split_digits_letters(bottom):\n",
    "    \"\"\"\n",
    "    Egyptian plate: digits on the left half, letters on the right half.\n",
    "    \"\"\"\n",
    "    h, w = bottom.shape[:2]\n",
    "    mid = w // 2\n",
    "    return bottom[:, :mid], bottom[:, mid:]\n",
    "\n",
    "\n",
    "def get_mask(region):\n",
    "    gray = rgb2gray(region)\n",
    "    T = threshold_otsu(gray)\n",
    "    mask = gray < T\n",
    "\n",
    "    # ✅ KEEP holes & dots (light cleaning only)\n",
    "    mask = remove_small_objects(mask, 25)\n",
    "    return mask\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Helper: create a crop that is friendly for OCR\n",
    "# ---------------------------------------------------\n",
    "def make_ocr_char_crop(gray_sub, r0, c0, r1, c1,\n",
    "                       pad=3, scale=3):\n",
    "    \"\"\"\n",
    "    gray_sub : grayscale version of sub-image (0–1)\n",
    "    (r0,c0,r1,c1) : bbox in sub coordinates\n",
    "    pad : extra pixels around character\n",
    "    scale : upscaling factor (so text is not tiny)\n",
    "    \"\"\"\n",
    "    H, W = gray_sub.shape\n",
    "\n",
    "    rr0 = max(r0 - pad, 0)\n",
    "    cc0 = max(c0 - pad, 0)\n",
    "    rr1 = min(r1 + pad, H)\n",
    "    cc1 = min(c1 + pad, W)\n",
    "\n",
    "    crop = gray_sub[rr0:rr1, cc0:cc1]        # 0–1 float from rgb2gray\n",
    "\n",
    "    # upscale (don’t DOWNsize to 40×40)\n",
    "    h, w = crop.shape\n",
    "    crop = resize(crop, (int(h * scale), int(w * scale)),\n",
    "                  anti_aliasing=True)\n",
    "\n",
    "    return crop   # still float 0–1\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2) DIGITS EXTRACTION\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def touches_border(r0, c0, r1, c1, H, W, margin_ratio=0.005):\n",
    "    mr = int(margin_ratio * H)\n",
    "    mc = int(margin_ratio * W)\n",
    "\n",
    "    if r0 <= mr: return True        # top\n",
    "    if c0 <= mc: return True        # left\n",
    "    if r1 >= H - mr: return True    # bottom\n",
    "    if c1 >= W - mc: return True    # right\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def extract_digits(digits_region, max_chars=4, debug=False):\n",
    "    H0, W0 = digits_region.shape[:2]\n",
    "    border_ratio = 0.04\n",
    "    by = int(border_ratio * H0)\n",
    "    bx = int(border_ratio * W0)\n",
    "    sub = digits_region[by:H0 - by, bx:W0 - bx]\n",
    "\n",
    "    # segmentation is done on mask\n",
    "    mask = get_mask(sub)\n",
    "    gray_sub = rgb2gray(sub)          ### <<< NEW: grayscale for OCR crops\n",
    "    H, W = mask.shape\n",
    "\n",
    "    lbl = label(mask)\n",
    "\n",
    "    candidates = []\n",
    "    for p in regionprops(lbl):\n",
    "        r0, c0, r1, c1 = p.bbox\n",
    "\n",
    "        touches = touches_border(r0, c0, r1, c1, H, W, margin_ratio=0.01)\n",
    "        if touches:\n",
    "            h = r1 - r0\n",
    "            w = c1 - c0\n",
    "            ar = p.area / (H * W)\n",
    "            # ✅ only reject if it looks like a FRAME, not a digit\n",
    "            if h > 0.9 * H or w < 0.02 * W or ar < 0.002:\n",
    "                continue\n",
    "\n",
    "        h = r1 - r0\n",
    "        w = c1 - c0\n",
    "        area = p.area\n",
    "        wr = w / W\n",
    "        ar = area / (H * W)\n",
    "\n",
    "        if wr < 0.035 or wr > 0.75:\n",
    "            continue\n",
    "        if ar < 0.001:\n",
    "            continue\n",
    "\n",
    "        candidates.append({\"bbox\": [r0, c0, r1, c1], \"area\": area})\n",
    "\n",
    "    # sort left → right\n",
    "    candidates.sort(key=lambda c: c[\"bbox\"][1])\n",
    "\n",
    "    # merge overlapping boxes\n",
    "    merged = []\n",
    "    for c in candidates:\n",
    "        if not merged:\n",
    "            merged.append(c)\n",
    "            continue\n",
    "\n",
    "        r0, c0, r1, c1 = c[\"bbox\"]\n",
    "        r0m, c0m, r1m, c1m = merged[-1][\"bbox\"]\n",
    "        overlap_x = min(c1, c1m) - max(c0, c0m)\n",
    "\n",
    "        if overlap_x > 0:\n",
    "            merged[-1][\"bbox\"] = [\n",
    "                min(r0, r0m), min(c0, c0m),\n",
    "                max(r1, r1m), max(c1, c1m)\n",
    "            ]\n",
    "        else:\n",
    "            merged.append(c)\n",
    "\n",
    "    boxed_mask = gray2rgb(mask.astype(np.uint8) * 255)\n",
    "\n",
    "    chars = []\n",
    "    for m in merged:\n",
    "        r0, c0, r1, c1 = m[\"bbox\"]\n",
    "        if (r1 - r0) < 0.22 * H:\n",
    "            continue\n",
    "\n",
    "        # draw box for debug\n",
    "        boxed_mask[r0:r1, [c0, c1-1]] = [255, 0, 0]\n",
    "        boxed_mask[[r0, r1-1], c0:c1] = [255, 0, 0]\n",
    "\n",
    "        # <<< OLD:\n",
    "        # crop = resize(mask[r0:r1, c0:c1].astype(float), (40, 40))\n",
    "        # chars.append((c0 + bx, crop))\n",
    "\n",
    "        # >>> NEW: OCR-friendly grayscale crop with padding + upscaling\n",
    "        crop = make_ocr_char_crop(gray_sub, r0, c0, r1, c1,\n",
    "                                  pad=3, scale=3)\n",
    "        chars.append((c0 + bx, crop))\n",
    "\n",
    "    chars.sort(key=lambda x: x[0])\n",
    "\n",
    "    if debug:\n",
    "        return [c for _, c in chars][:max_chars], mask, boxed_mask\n",
    "    else:\n",
    "        return [c for _, c in chars][:max_chars]\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 3) LETTERS EXTRACTION\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def extract_letters(letters_region, max_chars=3, debug=False):\n",
    "    H0, W0 = letters_region.shape[:2]\n",
    "    by = int(0.04 * H0)\n",
    "    bx = int(0.04 * W0)\n",
    "    sub = letters_region[by:H0 - by, bx:W0 - bx]\n",
    "\n",
    "    mask = get_mask(sub)\n",
    "    gray_sub = rgb2gray(sub)            ### <<< NEW: grayscale for OCR crops\n",
    "    H, W = mask.shape\n",
    "    lbl = label(mask)\n",
    "\n",
    "    boxed_mask = gray2rgb(mask.astype(np.uint8) * 255)\n",
    "\n",
    "    big_blobs = []   # main letter bodies\n",
    "    small_blobs = [] # dots\n",
    "\n",
    "    # -----------------------------\n",
    "    # 1) SPLIT BIG BLOBS & DOTS\n",
    "    # -----------------------------\n",
    "    for p in regionprops(lbl):\n",
    "        r0, c0, r1, c1 = p.bbox\n",
    "\n",
    "        if touches_border(r0, c0, r1, c1, H, W, margin_ratio=0.02):\n",
    "            continue\n",
    "\n",
    "        h = r1 - r0\n",
    "        w = c1 - c0\n",
    "        area = p.area\n",
    "        cy = p.centroid[0] / H\n",
    "        wr = w / W\n",
    "        ar = area / (H * W)\n",
    "\n",
    "        # 👉 DOT = any small area < 0.015\n",
    "        if ar < 0.015:\n",
    "            small_blobs.append((r0, c0, r1, c1))\n",
    "            continue\n",
    "\n",
    "        # 👉 MAIN LETTER FILTER (no lower area limit now)\n",
    "        if wr < 0.08 or wr > 0.75:\n",
    "            continue\n",
    "        if ar > 0.22:\n",
    "            continue\n",
    "        if cy > 0.75:\n",
    "            continue\n",
    "\n",
    "        big_blobs.append([r0, c0, r1, c1])\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # 2) ATTACH EACH DOT TO NEAREST LETTER BOX\n",
    "    # -----------------------------------------\n",
    "    for dr0, dc0, dr1, dc1 in small_blobs:\n",
    "        dc = (dc0 + dc1) / 2\n",
    "        dr = (dr0 + dr1) / 2\n",
    "\n",
    "        best_i = -1\n",
    "        best_dx = 1e9\n",
    "\n",
    "        for i, box in enumerate(big_blobs):\n",
    "            r0, c0, r1, c1 = box\n",
    "            bc = (c0 + c1) / 2\n",
    "            br = (r0 + r1) / 2\n",
    "\n",
    "            dx = abs(dc - bc)\n",
    "            dy = abs(dr - br)\n",
    "\n",
    "            # ✅ must be vertically close AND horizontally closest\n",
    "            if dx < best_dx and dy < 120:\n",
    "                best_dx = dx\n",
    "                best_i = i\n",
    "\n",
    "        # ✅ attach dot ONLY to the nearest valid letter\n",
    "        if best_i != -1:\n",
    "            box = big_blobs[best_i]\n",
    "            box[0] = min(box[0], dr0)\n",
    "            box[1] = min(box[1], dc0)\n",
    "            box[2] = max(box[2], dr1)\n",
    "            box[3] = max(box[3], dc1)\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # 3) SORT & CROP FINAL LETTERS\n",
    "    # -----------------------------------------\n",
    "    big_blobs.sort(key=lambda b: b[1])\n",
    "\n",
    "    chars = []\n",
    "    for r0, c0, r1, c1 in big_blobs:\n",
    "        boxed_mask[r0:r1, [c0, c1-1]] = [255, 0, 0]\n",
    "        boxed_mask[[r0, r1-1], c0:c1] = [255, 0, 0]\n",
    "\n",
    "        # <<< OLD:\n",
    "        # crop = resize(mask[r0:r1, c0:c1].astype(float), (40, 40))\n",
    "        # chars.append((c0 + bx, crop))\n",
    "\n",
    "        # >>> NEW: grayscale + padding + upscaling\n",
    "        crop = make_ocr_char_crop(gray_sub, r0, c0, r1, c1,\n",
    "                                  pad=3, scale=3)\n",
    "        chars.append((c0 + bx, crop))\n",
    "\n",
    "    if debug:\n",
    "        return [c for _, c in chars][:max_chars], mask, boxed_mask\n",
    "    else:\n",
    "        return [c for _, c in chars][:max_chars]\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4) FULL PIPELINE FOR ONE IMAGE\n",
    "# ---------------------------------------------------\n",
    "def process_plate(img):\n",
    "    bottom = crop_bottom(img)\n",
    "    digits_region, letters_region = split_digits_letters(bottom)\n",
    "\n",
    "    digits, d_mask, d_boxes = extract_digits(digits_region, debug=True)\n",
    "    letters, l_mask, l_boxes = extract_letters(letters_region, debug=True)\n",
    "\n",
    "    return digits_region, letters_region, digits, letters, d_mask, d_boxes, l_mask, l_boxes\n",
    "\n",
    "\n",
    "# Choose your plate image\n",
    "img22 = imread('Dataset/Limousines & tourist buses.png')\n",
    "\n",
    "def save_characters(digits, letters):\n",
    "    # digits / letters are floats 0–1 → uint8 0–255\n",
    "    for i, img in enumerate(digits):\n",
    "        out = (img * 255).astype(np.uint8)\n",
    "        cv2.imwrite(f\"digit_{i}.png\", out)\n",
    "\n",
    "    for i, img in enumerate(letters):\n",
    "        out = (img * 255).astype(np.uint8)\n",
    "        cv2.imwrite(f\"letter_{i}.png\", out)\n",
    "\n",
    "\n",
    "d_reg, l_reg, digits, letters, d_mask, d_boxes, l_mask, l_boxes = process_plate(img22)\n",
    "\n",
    "# (show_images assumed defined elsewhere)\n",
    "show_images([d_reg, l_reg], [\"Digits Region\", \"Letters Region\"])\n",
    "show_images([d_mask, l_mask], [\"Digits Mask\", \"Letters Mask\"])\n",
    "show_images([d_boxes, l_boxes], [\"Digits Mask + Boxes\", \"Letters Mask + Boxes\"])\n",
    "\n",
    "digit_titles = [f\"Digit {i}\" for i in range(len(digits))]\n",
    "show_images(digits, digit_titles)\n",
    "\n",
    "letter_titles = [f\"Letter {i}\" for i in range(len(letters))]\n",
    "show_images(letters, letter_titles)\n",
    "\n",
    "save_characters(digits, letters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a88c53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
