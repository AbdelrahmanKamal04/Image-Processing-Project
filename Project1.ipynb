{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74d243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Student Names + (IDs): \n",
    "\n",
    "Abdelrahman Mohamed Kamal Abdelaziz (1220255)\n",
    "Mazen Ahmed Fouad Abdelwahab (1220269)\n",
    "Mohamed Hesham Ibrahim Hassanain (1220278)\n",
    "Ahmed Walaa Abdlelkhalek Abdelrahman (1220216)\n",
    "\n",
    "'''\n",
    "#Import(s)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "import cv2\n",
    "from skimage.feature import canny\n",
    "from skimage.filters import sobel\n",
    "from skimage.color import rgb2gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c595dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images,titles=None):\n",
    "    n_ims = len(images)\n",
    "    if titles is None: titles = ['(%d)' % i for i in range(1,n_ims + 1)]\n",
    "    fig = plt.figure()\n",
    "    n = 1\n",
    "    for image,title in zip(images,titles):\n",
    "        a = fig.add_subplot(1,n_ims,n)\n",
    "        if image.ndim == 2: \n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "        n += 1\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_ims)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9664472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plate Localization\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Path1 = 'Localization Test/One Step All Angles No Headlights/Straight.jpeg'\n",
    "Path2 = 'Localization Test/Two Step All Angles No Headlights/Straight.jpeg'\n",
    "Path3 = 'Localization Test/Three Step All Angles No Headlights/Straight.jpeg'\n",
    "Path4 = 'Localization Test/One Step All Angles With Headlights/Straight.jpeg'\n",
    "Path5 = 'Localization Test/Two Step All Angles With Headlights/Straight.jpeg'\n",
    "\n",
    "Path11 = 'Localization Test/One Step All Angles No Headlights/Elevated.jpeg'\n",
    "Path12 = 'Localization Test/Two Step All Angles No Headlights/Elevated.jpeg'\n",
    "Path13 = 'Localization Test/Three Step All Angles No Headlights/Elevated.jpeg'\n",
    "Path14 = 'Localization Test/One Step All Angles With Headlights/Elevated.jpeg'\n",
    "Path15 = 'Localization Test/Two Step All Angles With Headlights/Elevated.jpeg'\n",
    "\n",
    "Path111 = 'Localization Test/One Step All Angles No Headlights/Slight Right.jpeg'\n",
    "Path112 = 'Localization Test/Two Step All Angles No Headlights/Slight Right.jpeg'\n",
    "Path113 = 'Localization Test/Three Step All Angles No Headlights/Slight Right.jpeg'\n",
    "Path114 = 'Localization Test/One Step All Angles With Headlights/Right.jpeg'\n",
    "Path115 = 'Localization Test/Two Step All Angles With Headlights/Right.jpeg'\n",
    "\n",
    "Path1111 = 'Localization Test/One Step All Angles No Headlights/Slight Left.jpeg'\n",
    "Path1112 = 'Localization Test/Two Step All Angles No Headlights/Slight Left.jpeg'\n",
    "Path1113 = 'Localization Test/Three Step All Angles No Headlights/Slight Left.jpeg'\n",
    "Path1114 = 'Localization Test/One Step All Angles With Headlights/Left.jpeg'\n",
    "Path1115 = 'Localization Test/Two Step All Angles With Headlights/Left.jpeg'\n",
    "\n",
    "Path11111 = 'Localization Test/One Step All Angles No Headlights/Extreme Left.jpeg'\n",
    "Path11112 = 'Localization Test/One Step All Angles No Headlights/Extreme Right.jpeg'\n",
    "Path11113 = 'Localization Test/Two Step All Angles No Headlights/Extreme Left.jpeg'\n",
    "Path11114 = 'Localization Test/Two Step All Angles No Headlights/Extreme Right.jpeg'\n",
    "Path11115 = 'Localization Test/Three Step All Angles No Headlights/Extreme Left.jpeg'\n",
    "Path11116 = 'Localization Test/Three Step All Angles No Headlights/Extreme Right.jpeg'\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def refine_plate_roi(roi_rgb):\n",
    "    \"\"\"\n",
    "    Refine the rough detected region to a tighter plate crop.\n",
    "    roi_rgb: cropped region from Original_Img (RGB from skimage.io)\n",
    "    \"\"\"\n",
    "    # Convert RGB -> gray\n",
    "    roi_gray = cv2.cvtColor(roi_rgb, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    h, w = roi_gray.shape[:2]\n",
    "    if h < 10 or w < 10:\n",
    "        return roi_rgb  # too small to refine\n",
    "\n",
    "    # Enhance and find edges\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    roi_clahe = clahe.apply(roi_gray)\n",
    "    roi_blur = cv2.GaussianBlur(roi_clahe, (3, 3), 0)\n",
    "    edges = cv2.Canny(roi_blur, 50, 150)\n",
    "\n",
    "    # Slight dilation to connect fragmented edges\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    edges_dil = cv2.dilate(edges, kernel, iterations=1)\n",
    "\n",
    "    contours, _ = cv2.findContours(edges_dil, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    best_box = None\n",
    "    best_score = -1.0\n",
    "    roi_area = float(h * w)\n",
    "\n",
    "    # ---- 1) Find best inner plate-like box (similar to what you had) ----\n",
    "    for cnt in contours:\n",
    "        x, y, cw, ch = cv2.boundingRect(cnt)\n",
    "        if cw <= 0 or ch <= 0:\n",
    "            continue\n",
    "\n",
    "        aspect = cw / float(ch)\n",
    "        area = cw * ch\n",
    "        area_ratio = area / roi_area\n",
    "\n",
    "        # Heuristics inside ROI:\n",
    "        # - Plate is fairly wide vs tall\n",
    "        # - Not too tiny, not almost whole ROI\n",
    "        if not (1.8 <= aspect <= 3.7):\n",
    "            continue\n",
    "        if not (0.15 <= area_ratio <= 0.9):\n",
    "            continue\n",
    "\n",
    "        # Score by edge density\n",
    "        sub_edges = edges_dil[y:y+ch, x:x+cw]\n",
    "        non_zero = cv2.countNonZero(sub_edges)\n",
    "        density = non_zero / float(area)\n",
    "\n",
    "        if density > best_score:\n",
    "            best_score = density\n",
    "            best_box = (x, y, cw, ch)\n",
    "\n",
    "    # nothing better found -> return original ROI\n",
    "    if best_box is None:\n",
    "        return roi_rgb\n",
    "\n",
    "    x, y, cw, ch = best_box\n",
    "\n",
    "    # ---- 2) Aspect-based vertical trimming using Egyptian plate ratio ----\n",
    "    # Real Egyptian plate: 35cm x 17cm -> aspect ~ 2.06 (w/h)\n",
    "    ideal_aspect = 35.0 / 17.0\n",
    "\n",
    "    # If the box is \"too tall\" (aspect < ~1.7), it likely includes bumper.\n",
    "    current_aspect = cw / float(ch)\n",
    "\n",
    "    # We will trim vertically to get closer to the ideal aspect,\n",
    "    # but we choose the vertical band with the highest edge energy.\n",
    "    if current_aspect < 1.7:\n",
    "        # target height for ideal aspect\n",
    "        target_h = int(cw / ideal_aspect)\n",
    "        target_h = max(10, min(target_h, ch))  # clamp\n",
    "\n",
    "        sub_edges_full = edges_dil[y:y+ch, x:x+cw]\n",
    "        row_sum = sub_edges_full.sum(axis=1)  # edge energy per row\n",
    "\n",
    "        # sliding window over rows to find the band of height target_h\n",
    "        best_row_start = 0\n",
    "        best_row_score = -1\n",
    "\n",
    "        # if target_h == ch we skip trimming; else search\n",
    "        if target_h < ch:\n",
    "            # compute cumulative sum to make sliding window O(n)\n",
    "            cumsum = np.cumsum(row_sum)\n",
    "            # score for rows [i, i+target_h) = cumsum[i+target_h-1] - (cumsum[i-1] if i>0 else 0)\n",
    "            for i in range(0, ch - target_h + 1):\n",
    "                j = i + target_h - 1\n",
    "                window_sum = cumsum[j] - (cumsum[i-1] if i > 0 else 0)\n",
    "                if window_sum > best_row_score:\n",
    "                    best_row_score = window_sum\n",
    "                    best_row_start = i\n",
    "\n",
    "            # now trim the box to that vertical band\n",
    "            new_y = y + best_row_start\n",
    "            new_h = target_h\n",
    "\n",
    "            # final safety clamp\n",
    "            if new_y + new_h > h:\n",
    "                new_h = h - new_y\n",
    "\n",
    "            y = new_y\n",
    "            ch = new_h\n",
    "\n",
    "    # ---- 3) Final crop from original ROI ----\n",
    "    refined = roi_rgb[y:y+ch, x:x+cw]\n",
    "    return refined\n",
    "\n",
    "      \n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def Plate_Detection(image_path):\n",
    "\n",
    "    # Original Image\n",
    "    Original_Img = io.imread(image_path)\n",
    "    Height, Width, _ = Original_Img.shape\n",
    "\n",
    "    # Read Image and convert to grayscale\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply CLAHE to improve local contrast\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    gray_clahe = clahe.apply(gray)\n",
    "\n",
    "    # Apply Gaussian Blur to reduce noise\n",
    "    gray_blur = cv2.GaussianBlur(gray_clahe, (5,5), 0)\n",
    "\n",
    "    # Adaptive Thresholding to handle dark and bright regions\n",
    "    thresh = cv2.adaptiveThreshold(gray_blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 19, 9)\n",
    "\n",
    "    # Morphological closing to connect fragmented regions\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "    morph = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    plate_candidates = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        aspect_ratio = w / h\n",
    "        area_ratio = w * h / (Height * Width)\n",
    "        if (1.8 < aspect_ratio < 3.7) and (0.01 < area_ratio):  # relaxed aspect ratio\n",
    "            plate_candidates.append((x, y, w, h))\n",
    "\n",
    "    if not plate_candidates:\n",
    "        print(\"No plate candidate found.\")\n",
    "        return None\n",
    "\n",
    "    # Choose the largest candidate\n",
    "    plate_candidates = sorted(plate_candidates, key=lambda x: x[2]*x[3], reverse=True)\n",
    "    for cnt in plate_candidates:\n",
    "        x, y, w, h = cnt\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "    # Crop the largest candidate\n",
    "    x, y, w, h = plate_candidates[0]\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    show_images([img], [\"Best Plate Candidate\"])\n",
    "    plate_img = Original_Img[y:y+h, x:x+w] \n",
    "    \n",
    "    return plate_img\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "# Testing the Plate Detection Function on Different Images\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Origignal_Img1 = io.imread(Path1)\n",
    "# Detected_Plate1 = Plate_Detection(Path1)\n",
    "# if Detected_Plate1 is not None:\n",
    "#     # GrayScale = rgb2gray(Detected_Plate1)\n",
    "#     # BinaryScale = GrayScale > 0.4\n",
    "#     show_images([Origignal_Img1, Detected_Plate1], [\"One Step No Headlights\", \"Plate Image\"])\n",
    "\n",
    "# Origignal_Img2 = io.imread(Path2)\n",
    "# Detected_Plate2 = Plate_Detection(Path2)\n",
    "# if Detected_Plate2 is not None:\n",
    "#     # GrayScale = rgb2gray(Detected_Plate2)\n",
    "#     # BinaryScale = GrayScale > 0.4\n",
    "#     show_images([Origignal_Img2, Detected_Plate2], [\"Two Steps No Headlights\", \"Plate Image\"])\n",
    "\n",
    "# Origignal_Img3 = io.imread(Path3)\n",
    "# Detected_Plate3 = Plate_Detection(Path3)\n",
    "# if Detected_Plate3 is not None:\n",
    "#     # GrayScale = rgb2gray(Detected_Plate3)\n",
    "#     # BinaryScale = GrayScale > 0.4\n",
    "#     show_images([Origignal_Img3, Detected_Plate3], [\"Three Steps No Headlights\", \"Plate Image\"])\n",
    "\n",
    "# Origignal_Img4 = io.imread(Path4)\n",
    "# Detected_Plate4 = Plate_Detection(Path4)\n",
    "# if Detected_Plate4 is not None:\n",
    "#     # GrayScale = rgb2gray(Detected_Plate4)\n",
    "#     # BinaryScale = GrayScale > 0.4\n",
    "#     show_images([Origignal_Img4, Detected_Plate4], [\"One Step Headlights\", \"Plate Image\"])\n",
    "\n",
    "# Origignal_Img5 = io.imread(Path5)\n",
    "# Detected_Plate5 = Plate_Detection(Path5)\n",
    "# if Detected_Plate5 is not None:\n",
    "#     # GrayScale = rgb2gray(Detected_Plate5)\n",
    "#     # BinaryScale = GrayScale > 0.4\n",
    "#     show_images([Origignal_Img5, Detected_Plate5], [\"Two Steps Headlights\", \"Plate Image\"])\n",
    "\n",
    "# #-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Origignal_Img11 = io.imread(Path11)\n",
    "Detected_Plate11 = Plate_Detection(Path11)\n",
    "if Detected_Plate11 is not None:\n",
    "    show_images([Origignal_Img11, Detected_Plate11], [\"One Step Elevated No Headlights\", \"Plate Image\"]) \n",
    "\n",
    "Origignal_Img12 = io.imread(Path12)\n",
    "Detected_Plate12 = Plate_Detection(Path12)\n",
    "if Detected_Plate12 is not None:\n",
    "    show_images([Origignal_Img12, Detected_Plate12], [\"Two Step Elevated No Headlights\", \"Plate Image\"])\n",
    "\n",
    "Origignal_Img13 = io.imread(Path13)\n",
    "Detected_Plate13 = Plate_Detection(Path13)\n",
    "if Detected_Plate13 is not None:\n",
    "    show_images([Origignal_Img13, Detected_Plate13], [\"Three Step Elevated No Headlights\", \"Plate Image\"])\n",
    "\n",
    "# Origignal_Img14 = io.imread(Path14)\n",
    "# Detected_Plate14 = Plate_Detection(Path14)\n",
    "# if Detected_Plate14 is not None:\n",
    "#     show_images([Origignal_Img14, Detected_Plate14], [\"One Step Elevated Headlights\", \"Plate Image\"])\n",
    "\n",
    "Origignal_Img15 = io.imread(Path15)\n",
    "Detected_Plate15 = Plate_Detection(Path15)\n",
    "if Detected_Plate15 is not None:\n",
    "    show_images([Origignal_Img15, Detected_Plate15], [\"Two Step Elevated Headlights\", \"Plate Image\"])\n",
    "\n",
    "# #-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Origignal_Img111 = io.imread(Path111)\n",
    "# Detected_Plate111 = Plate_Detection(Path111)\n",
    "# if Detected_Plate111 is not None:\n",
    "#     show_images([Origignal_Img111, Detected_Plate111], [\"One Step Slight Right No Headlights\", \"Plate Image\"])\n",
    "\n",
    "# Origignal_Img112 = io.imread(Path112)\n",
    "# Detected_Plate112 = Plate_Detection(Path112)\n",
    "# if Detected_Plate112 is not None:\n",
    "#     show_images([Origignal_Img112, Detected_Plate112], [\"Two Step Slight Right No Headlights\", \"Plate Image\"])\n",
    "\n",
    "# Origignal_Img113 = io.imread(Path113)\n",
    "# Detected_Plate113 = Plate_Detection(Path113)\n",
    "# if Detected_Plate113 is not None:\n",
    "#     show_images([Origignal_Img113, Detected_Plate113], [\"Three Step Slight Right No Headlights\", \"Plate Image\"])\n",
    "\n",
    "# # Origignal_Img114 = io.imread(Path114)\n",
    "# # Detected_Plate114 = Plate_Detection(Path114)\n",
    "# # if Detected_Plate114 is not None:\n",
    "# #     show_images([Origignal_Img114, Detected_Plate114], [\"One Step Slight Right Headlights\", \"Plate Image\"])\n",
    "\n",
    "# Origignal_Img115 = io.imread(Path115)\n",
    "# Detected_Plate115 = Plate_Detection(Path115)\n",
    "# if Detected_Plate115 is not None:\n",
    "#     show_images([Origignal_Img115, Detected_Plate115], [\"Two Step Slight Right Headlights\", \"Plate Image\"])\n",
    "\n",
    "# #-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Origignal_Img1111 = io.imread(Path1111)\n",
    "# Detected_Plate1111 = Plate_Detection(Path1111)\n",
    "# if Detected_Plate1111 is not None:\n",
    "#     show_images([Origignal_Img1111, Detected_Plate1111], [\"One Step Slight Left No Headlights\", \"Plate Image\"])\n",
    "\n",
    "# Origignal_Img1112 = io.imread(Path1112)\n",
    "# Detected_Plate1112 = Plate_Detection(Path1112)\n",
    "# if Detected_Plate1112 is not None:\n",
    "#     show_images([Origignal_Img1112, Detected_Plate1112], [\"Two Step Slight Left No Headlights\", \"Plate Image\"])\n",
    "\n",
    "# Origignal_Img1113 = io.imread(Path1113)\n",
    "# Detected_Plate1113 = Plate_Detection(Path1113)\n",
    "# if Detected_Plate1113 is not None:\n",
    "#     show_images([Origignal_Img1113, Detected_Plate1113], [\"Three Step Slight Left No Headlights\", \"Plate Image\"])\n",
    "\n",
    "# # Origignal_Img1114 = io.imread(Path1114)\n",
    "# # Detected_Plate1114 = Plate_Detection(Path1114)\n",
    "# # if Detected_Plate1114 is not None:\n",
    "# #     show_images([Origignal_Img1114, Detected_Plate1114], [\"One Step Slight Left Headlights\", \"Plate Image\"])\n",
    "\n",
    "# Origignal_Img1115 = io.imread(Path1115)\n",
    "# Detected_Plate1115 = Plate_Detection(Path1115)\n",
    "# if Detected_Plate1115 is not None:\n",
    "#     show_images([Origignal_Img1115, Detected_Plate1115], [\"Two Step Slight Left Headlights\", \"Plate Image\"])\n",
    "\n",
    "# #-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# # Original_Img11111 = io.imread(Path11111)\n",
    "# # Detected_Plate11111 = Plate_Detection(Path11111)\n",
    "# # if Detected_Plate11111 is not None:\n",
    "# #     show_images([Original_Img11111, Detected_Plate11111], [\"One Step Extreme Left No Headlights\", \"Plate Image\"])\n",
    "\n",
    "# # Original_Img11112 = io.imread(Path11112)\n",
    "# # Detected_Plate11112 = Plate_Detection(Path11112)\n",
    "# # if Detected_Plate11112 is not None:\n",
    "# #     show_images([Original_Img11112, Detected_Plate11112], [\"One Step Extreme Right No Headlights\", \"Plate Image\"])\n",
    "\n",
    "# Original_Img11113 = io.imread(Path11113)\n",
    "# Detected_Plate11113 = Plate_Detection(Path11113)\n",
    "# if Detected_Plate11113 is not None:\n",
    "#     show_images([Original_Img11113, Detected_Plate11113], [\"Two Step Extreme Left No Headlights\", \"Plate Image\"])\n",
    "\n",
    "# Original_Img11114 = io.imread(Path11114)\n",
    "# Detected_Plate11114 = Plate_Detection(Path11114)\n",
    "# if Detected_Plate11114 is not None:\n",
    "#     show_images([Original_Img11114, Detected_Plate11114], [\"Two Step Extreme Right No Headlights\", \"Plate Image\"])\n",
    "\n",
    "# # Original_Img11115 = io.imread(Path11115)\n",
    "# # Detected_Plate11115 = Plate_Detection(Path11115)\n",
    "# # if Detected_Plate11115 is not None:\n",
    "# #     show_images([Original_Img11115, Detected_Plate11115], [\"Three Step Extreme Left No Headlights\", \"Plate Image\"])\n",
    "\n",
    "# # Original_Img11116 = io.imread(Path11116)\n",
    "# # Detected_Plate11116 = Plate_Detection(Path11116)\n",
    "# # if Detected_Plate11116 is not None:\n",
    "# #     show_images([Original_Img11116, Detected_Plate11116], [\"Three Step Extreme Right No Headlights\", \"Plate Image\"])\n",
    "\n",
    "\n",
    "# Original_Img11114 = io.imread(\"image.jpg\")\n",
    "# Detected_Plate11114 = Plate_Detection(\"image.jpg\")\n",
    "# if Detected_Plate11114 is not None:\n",
    "#     show_images([Original_Img11114, Detected_Plate11114], [\"Two Step Extreme Right No Headlights\", \"Plate Image\"])\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ed7363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def adaptive_blue_mask(img_bgr, debug=False):\n",
    "    \"\"\"\n",
    "    Returns: mask (0/255) of 'blue-ish' pixels,\n",
    "             and the chosen lower/upper HSV bounds.\n",
    "    \"\"\"\n",
    "    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
    "    H, S, V = cv2.split(hsv)\n",
    "\n",
    "    # 1) Take only reasonably saturated, bright pixels (colored, not gray)\n",
    "    sat_thresh = 40   # S > 40\n",
    "    val_thresh = 40   # V > 40\n",
    "    colored = (S > sat_thresh) & (V > val_thresh)\n",
    "\n",
    "    # 2) Within colored pixels, take a very WIDE blue-ish hue band\n",
    "    #    OpenCV H ranges from 0..179 (blue roughly around 100-140, but we'll be generous)\n",
    "    H_colored = H[colored]\n",
    "    blue_candidate_mask = (H_colored >= 70) & (H_colored <= 150)\n",
    "    blue_hues = H_colored[blue_candidate_mask]\n",
    "\n",
    "    if blue_hues.size == 0:\n",
    "        # No obvious blue at all\n",
    "        return np.zeros_like(H, dtype=np.uint8), None, None\n",
    "\n",
    "    # 3) Histogram of blue hue values → find peak\n",
    "    hist, bin_edges = np.histogram(blue_hues, bins=36, range=(0, 180))\n",
    "    peak_bin = np.argmax(hist)\n",
    "    # Center of that bin:\n",
    "    h_peak = 0.5 * (bin_edges[peak_bin] + bin_edges[peak_bin + 1])\n",
    "\n",
    "    # 4) Define tighter bounds around the peak (±delta)\n",
    "    delta = 15  # width of hue window around peak\n",
    "    h_low = max(0, int(h_peak - delta))\n",
    "    h_high = min(179, int(h_peak + delta))\n",
    "\n",
    "    lower_blue = np.array([h_low, sat_thresh, val_thresh], dtype=np.uint8)\n",
    "    upper_blue = np.array([h_high, 255, 255], dtype=np.uint8)\n",
    "\n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Adaptive blue H range: [{h_low}, {h_high}] (peak at {h_peak:.1f})\")\n",
    "\n",
    "    return mask, lower_blue, upper_blue\n",
    "\n",
    "def crop_left_right_by_blue_adaptive(img_bgr):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "\n",
    "    mask, lb, ub = adaptive_blue_mask(img_bgr)\n",
    "    if lb is None:\n",
    "        return None, None, None  # no blue\n",
    "\n",
    "    # --- vertical band (rows) based on relative maximum ---\n",
    "    row_counts = mask.sum(axis=1) // 255\n",
    "    max_row = row_counts.max()\n",
    "    if max_row == 0:\n",
    "        return None, None, None\n",
    "\n",
    "    row_thresh = 0.5 * max_row\n",
    "    blue_rows = row_counts > row_thresh\n",
    "\n",
    "    best_start = best_end = None\n",
    "    cur_start = None\n",
    "    for y, is_blue in enumerate(blue_rows):\n",
    "        if is_blue and cur_start is None:\n",
    "            cur_start = y\n",
    "        elif not is_blue and cur_start is not None:\n",
    "            if best_start is None or (y - cur_start) > (best_end - best_start):\n",
    "                best_start, best_end = cur_start, y\n",
    "            cur_start = None\n",
    "    if cur_start is not None:\n",
    "        y = len(blue_rows)\n",
    "        if best_start is None or (y - cur_start) > (best_end - best_start):\n",
    "            best_start, best_end = cur_start, y\n",
    "\n",
    "    if best_start is None:\n",
    "        return None, None, None\n",
    "\n",
    "    y0_band, y1_band = best_start, best_end\n",
    "\n",
    "    # --- horizontal band (cols) inside that blue band ---\n",
    "    submask = mask[y0_band:y1_band, :]\n",
    "    col_counts = submask.sum(axis=0) // 255\n",
    "    max_col = col_counts.max()\n",
    "    if max_col == 0:\n",
    "        return None, None, None\n",
    "\n",
    "    col_thresh = 0.3 * max_col  # relative, not based on H\n",
    "    blue_cols = col_counts > col_thresh\n",
    "\n",
    "    xs = np.where(blue_cols)[0]\n",
    "    if xs.size == 0:\n",
    "        return None, None, None\n",
    "\n",
    "    x0 = xs[0]\n",
    "    x1 = xs[-1]\n",
    "\n",
    "    # add margin\n",
    "    margin = int(0.02 * W)\n",
    "    x0 = max(0, x0 - margin)\n",
    "    x1 = min(W - 1, x1 + margin)\n",
    "\n",
    "    cropped_lr = img_bgr[:, x0:x1]\n",
    "\n",
    "    return cropped_lr, (x0, y0_band, x1, y1_band), mask\n",
    "\n",
    "\n",
    "cropped_lr, band_bbox, mask = crop_left_right_by_blue_adaptive(Detected_Plate15)\n",
    "\n",
    "if cropped_lr is not None:\n",
    "    x0, y0_band, x1, y1_band = band_bbox\n",
    "    print(\"Band bbox:\", band_bbox)\n",
    "    show_images(\n",
    "        [cv2.cvtColor(cropped_lr, cv2.COLOR_BGR2RGB), Detected_Plate15],\n",
    "        [\"Cropped L/R\", \"Blue Mask\"]\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f8499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from skimage import io, color, filters, morphology\n",
    "import numpy as np\n",
    "from skimage import img_as_ubyte\n",
    "\n",
    "\n",
    "def preprocess_plate_with_smoothing(img, debug=True):\n",
    "    \"\"\"\n",
    "    Preprocess the localized license plate image with:\n",
    "    - Pre-threshold smoothing (median blur)\n",
    "    - CLAHE\n",
    "    - Adaptive thresholding\n",
    "    - Post-threshold noise removal (morphological opening)\n",
    "    Returns the final cleaned binary image.\n",
    "    \"\"\"\n",
    "    # ---------------- 1. Convert to grayscale ----------------\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # ---------------- 2. Optional pre-threshold smoothing ----------------\n",
    "    # Reduce scattered grayscale noise before thresholding\n",
    "    gray_smooth = cv2.medianBlur(gray, ksize=3)  # small kernel\n",
    "\n",
    "    # ---------------- 3. CLAHE ----------------\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    enhanced = clahe.apply(gray_smooth)\n",
    "\n",
    "    # ---------------- 4. Adaptive Threshold ----------------\n",
    "    H, W = enhanced.shape\n",
    "    block_size = int(max(15, (H // 7) | 1))  # odd\n",
    "    C = 8\n",
    "    binary = cv2.adaptiveThreshold(\n",
    "        enhanced,\n",
    "        maxValue=255,\n",
    "        adaptiveMethod=cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        thresholdType=cv2.THRESH_BINARY,\n",
    "        blockSize=block_size,\n",
    "        C=C\n",
    "    )\n",
    "\n",
    "    # ---------------- 5. Invert if needed ----------------------------------\n",
    "    white_ratio = np.mean(binary == 255)\n",
    "    if white_ratio > 0.55:\n",
    "        binary = cv2.bitwise_not(binary)\n",
    "\n",
    "    # ---------------- 6. Post-threshold noise removal ----------------\n",
    "    # Remove tiny white speckles\n",
    "    h, w = binary.shape\n",
    "    k_open = max(1, round(h * 0.015))  # kernel proportional to plate height\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (k_open, k_open))\n",
    "    cleaned_binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # ---------------- 7. Debug visualization ----------------\n",
    "    if debug:\n",
    "        plt.figure(figsize=(15,5))\n",
    "        plt.subplot(1,4,1)\n",
    "        plt.imshow(gray, cmap='gray'); plt.title(\"Grayscale\"); plt.axis(\"off\")\n",
    "        plt.subplot(1,4,2)\n",
    "        plt.imshow(gray_smooth, cmap='gray'); plt.title(\"Median Smoothed\"); plt.axis(\"off\")\n",
    "        plt.subplot(1,4,3)\n",
    "        plt.imshow(binary, cmap='gray'); plt.title(\"Adaptive Threshold\"); plt.axis(\"off\")\n",
    "        plt.subplot(1,4,4)\n",
    "        plt.imshow(cleaned_binary, cmap='gray'); plt.title(\"After Morph Open\"); plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "    return cleaned_binary\n",
    "\n",
    "\n",
    "def crop_one_side(img, mask, side, threshold=0.02, max_px=21):\n",
    "    \"\"\"\n",
    "    Crops ONE SIDE ONLY (top, bottom, left, right) by 1px repeatedly.\n",
    "    Stops when that side becomes clean OR when image would become too small.\n",
    "    \"\"\"\n",
    "    for _ in range(max_px):\n",
    "\n",
    "        # HARD SAFETY — never allow cropping if too small\n",
    "        if img.shape[0] < 10 or img.shape[1] < 10:\n",
    "            break\n",
    "\n",
    "        if side == \"top\":\n",
    "            border_val = mask[0, :].mean()\n",
    "            if border_val > threshold:\n",
    "                img  = img[1:, :]\n",
    "                mask = mask[1:, :]\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        elif side == \"bottom\":\n",
    "            border_val = mask[-1, :].mean()\n",
    "            if border_val > threshold:\n",
    "                img  = img[:-1, :]\n",
    "                mask = mask[:-1, :]\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        elif side == \"left\":\n",
    "            border_val = mask[:, 0].mean()\n",
    "            if border_val > threshold:\n",
    "                img  = img[:, 1:]\n",
    "                mask = mask[:, 1:]\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        elif side == \"right\":\n",
    "            border_val = mask[:, -1].mean()\n",
    "            if border_val > threshold:\n",
    "                img  = img[:, :-1]\n",
    "                mask = mask[:, :-1]\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    return img, mask\n",
    "\n",
    "\n",
    "def clean_crop(img, mask):\n",
    "    img, mask = crop_one_side(img, mask, \"top\")\n",
    "    img, mask = crop_one_side(img, mask, \"bottom\")\n",
    "    img, mask = crop_one_side(img, mask, \"left\")\n",
    "    img, mask = crop_one_side(img, mask, \"right\")\n",
    "    return img, mask\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# WHITE BACKGROUND RENDERING\n",
    "# ======================================================================\n",
    "def make_clean(region_img, region_mask):\n",
    "    clean = np.ones_like(region_img)\n",
    "    clean[region_mask] = region_img[region_mask]\n",
    "    return clean\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def remove_plate_header(plate_img, header_ratio=0.2):\n",
    "\n",
    "    \"\"\"\n",
    "    Crops out the top header rectangle (Egypt / مصر) from a license plate.\n",
    "    \n",
    "    Parameters:\n",
    "        plate_img: binary or grayscale plate image\n",
    "        header_ratio: proportion of height to remove from top (0.0–1.0)\n",
    "    \n",
    "    Returns:\n",
    "        cropped_img: the plate without the top header\n",
    "    \"\"\"\n",
    "    h, w = plate_img.shape[:2]\n",
    "    header_height = int(h * header_ratio)\n",
    "    \n",
    "    # Keep only the bottom part\n",
    "    cropped_img = plate_img[header_height:, :]\n",
    "    \n",
    "    return cropped_img\n",
    "\n",
    "\n",
    "\n",
    "def morphological_and_CCL(binary_img,left,right,debug=True):\n",
    "    \"\"\"\n",
    "    Takes the binarized plate image (white foreground, black background)\n",
    "    and performs:\n",
    "      - Small opening\n",
    "      - Small closing\n",
    "      - Connected Components (8-connectivity)\n",
    "      - Character plausibility filtering (relative thresholds)\n",
    "    Returns:\n",
    "      cleaned_binary, boxes, stats_all, labels, num_labels\n",
    "    \"\"\"\n",
    "\n",
    "    # ---------- STEP 2: Morphological Cleaning ----------\n",
    "    h, w = binary_img.shape[:2]\n",
    "\n",
    "    # Kernel sizes scaled to image height\n",
    "    # k1 = max(1, round(h * 0.01))  # opening kernel\n",
    "    # k2 = max(1, round(h * 0.025))   # closing kernel\n",
    "\n",
    "    # kernel1 = cv2.getStructuringElement(cv2.MORPH_RECT, (k1, k1))\n",
    "    # kernel2 = cv2.getStructuringElement(cv2.MORPH_RECT, (k2, k2))\n",
    "\n",
    "    # # Small opening to remove tiny speckles\n",
    "    # opened = cv2.morphologyEx(binary_img, cv2.MORPH_OPEN, kernel1,iterations=1)\n",
    "\n",
    "    # # Small closing to fill small holes in characters\n",
    "    # closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel2,iterations=1)\n",
    "\n",
    "    # cleaned_binary = closed.copy()\n",
    "\n",
    "    # # Force binary exact values (0,255) and uint8\n",
    "    # cleaned_binary = np.where(cleaned_binary > 0, 255, 0).astype(np.uint8)\n",
    "\n",
    "    # if debug:\n",
    "    #     print(\"After morphology: dtype:\", cleaned_binary.dtype, \"unique:\", np.unique(cleaned_binary))\n",
    "    #     print(\"White pixel count:\", int(np.sum(cleaned_binary == 255)))\n",
    "\n",
    "\n",
    "    # cropped_plate = remove_plate_header(cleaned_binary, header_ratio=0.45)\n",
    "    # noborders= remove_white_borders(cleaned_binary)\n",
    "\n",
    "    \n",
    "    \n",
    "    # ---------- STEP 3: Connected Components (8-connectivity) ----------\n",
    "\n",
    "    left = (left > 0).astype(\"uint8\") * 255\n",
    "    right = (right > 0).astype(\"uint8\") * 255\n",
    "\n",
    "    num_labels1, labels1, stats1, centroids1 = cv2.connectedComponentsWithStats(\n",
    "        left,\n",
    "        connectivity=8,\n",
    "        ltype=cv2.CV_32S\n",
    "    )\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(\n",
    "        right,\n",
    "        connectivity=8,\n",
    "        ltype=cv2.CV_32S\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    if debug:\n",
    "        print(\"num_labels (including background):\", num_labels)\n",
    "        # optionally print first few stats\n",
    "        for i in range(min(num_labels, 12)):\n",
    "            x,y,wb,hb,area = stats[i]\n",
    "            print(f\"label {i}: x={x} y={y} w={wb} h={hb} area={area}\")\n",
    "\n",
    "    # ---------- STEP 5: Bounding-Box Filtering (RELATIVE thresholds) ----------\n",
    "    boxesleft = []\n",
    "    stats_allleft = []\n",
    "    boxesright = []\n",
    "    stats_allright = []\n",
    "\n",
    "    plate_area = h * w\n",
    "\n",
    "    # Reasonable starting thresholds (relative)\n",
    "    min_area = plate_area * 0.005   # 0.5% of plate area\n",
    "    max_area = plate_area * 0.25    # 25% of plate area (likely merged)\n",
    "    min_aspect = 0.08               # w/h (allow narrow digits)   0.08 \n",
    "    max_aspect = 1.4                # some letters might be wider than digits\n",
    "\n",
    "    min_height = h * 0.15           # allow small characters (15% of plate height)\n",
    "    max_height = h * 0.4\n",
    "\n",
    "    if debug:\n",
    "        print(f\"plate_area={plate_area}, min_area={min_area}, max_area={max_area}\")\n",
    "        print(f\"min_height_px={min_height}, max_height_px={max_height}\")\n",
    "\n",
    "    for label in range(1, num_labels1):  # skip background label 0\n",
    "        x, y, w_b, h_b, area = stats1[label]\n",
    "        stats_allleft.append((label, x, y, w_b, h_b, area))\n",
    "\n",
    "        # area filtering\n",
    "        if area < min_area:\n",
    "            continue\n",
    "        if area > max_area:\n",
    "            continue  # merged objects (we're skipping splitting per your instruction)\n",
    "\n",
    "        aspect = w_b / float(max(1, h_b))\n",
    "\n",
    "        # aspect ratio filtering\n",
    "        if aspect < min_aspect or aspect > max_aspect:\n",
    "            continue\n",
    "\n",
    "        # height filtering\n",
    "        if h_b < min_height or h_b > max_height:\n",
    "            continue\n",
    "\n",
    "        boxesleft.append((x, y, w_b, h_b))\n",
    "        \n",
    "    for label in range(1, num_labels):  # skip background label 0\n",
    "        x, y, w_b, h_b, area = stats[label]\n",
    "        stats_allright.append((label, x, y, w_b, h_b, area))\n",
    "\n",
    "        # area filtering\n",
    "        if area < min_area:\n",
    "            continue\n",
    "        if area > max_area:\n",
    "            continue  # merged objects (we're skipping splitting per your instruction)\n",
    "\n",
    "        aspect = w_b / float(max(1, h_b))\n",
    "\n",
    "        # aspect ratio filtering\n",
    "        if aspect < min_aspect or aspect > max_aspect:\n",
    "            continue\n",
    "\n",
    "        # height filtering\n",
    "        if h_b < min_height or h_b > max_height:\n",
    "            continue\n",
    "\n",
    "        boxesright.append((x, y, w_b, h_b))\n",
    "\n",
    "    if debug:\n",
    "        print(\"Found candidate boxes:\", len(boxesleft)+len(boxesright))\n",
    "        # show bounding boxes overlay for quick visual check (returns BGR image)\n",
    "        dbg = cv2.cvtColor(left, cv2.COLOR_GRAY2BGR)\n",
    "        for (x, y, wb, hb) in boxesleft:\n",
    "            cv2.rectangle(dbg, (x, y), (x+wb, y+hb), (0,255,0), 2)\n",
    "        dbg2 = cv2.cvtColor(right, cv2.COLOR_GRAY2BGR)\n",
    "        for (x, y, wb, hb) in boxesright:\n",
    "            cv2.rectangle(dbg, (x, y), (x+wb, y+hb), (0,255,0), 2)\n",
    "        # Display inline if desired (plt or cv2.imshow)\n",
    "        # cv2.imshow(\"ccl_debug\", dbg); cv2.waitKey(0)\n",
    "        # For notebooks, convert and display with matplotlib:\n",
    "        try:\n",
    "            from matplotlib import pyplot as plt\n",
    "            # plt.figure(figsize=(8,5)); plt.imshow(cv2.cvtColor(dbg, cv2.COLOR_BGR2RGB)); plt.axis(\"off\"); plt.show()\n",
    "            # plt.figure(figsize=(8,5)); plt.imshow(cv2.cvtColor(dbg2, cv2.COLOR_BGR2RGB)); plt.axis(\"off\"); plt.show()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # ensure expected number (2–7 components)\n",
    "    if len(boxesleft)+len(boxesright) < 2 or len(boxesleft)+len(boxesright) > 7:\n",
    "        print(\"⚠ Warning: suspicious number of character candidates =\", len(boxesleft)+len(boxesright))\n",
    "\n",
    "    return boxesleft,boxesright,left,right\n",
    "\n",
    "\n",
    "def draw_components(imgL,imgR, boxesL,boxesR, pad=3):\n",
    "    \"\"\"Draws padded bounding boxes on the image for visualization.\"\"\"\n",
    "    out = cv2.cvtColor(imgL.copy(), cv2.COLOR_GRAY2BGR)\n",
    "    H, W = imgL.shape[:2]\n",
    "\n",
    "    for (x, y, w, h) in boxesL:\n",
    "        # Expand bounding box\n",
    "        x1 = max(0, x - pad)\n",
    "        y1 = max(0, y - pad)\n",
    "        x2 = min(W - 1, x + w + pad)\n",
    "        y2 = min(H - 1, y + h + pad)\n",
    "\n",
    "        cv2.rectangle(out, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    out2 = cv2.cvtColor(imgR.copy(), cv2.COLOR_GRAY2BGR)\n",
    "    H, W = imgR.shape[:2]\n",
    "\n",
    "    for (x, y, w, h) in boxesR:\n",
    "        # Expand bounding box\n",
    "        x1 = max(0, x - pad)\n",
    "        y1 = max(0, y - pad)\n",
    "        x2 = min(W - 1, x + w + pad)\n",
    "        y2 = min(H - 1, y + h + pad)\n",
    "\n",
    "        cv2.rectangle(out2, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    return out,out2\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def _ensure_binary_uint8(img):\n",
    "    img = np.asarray(img)\n",
    "    if img.dtype != np.uint8:\n",
    "        img = (img > 0).astype(np.uint8) * 255\n",
    "    else:\n",
    "        # ensure exact 0/255\n",
    "        img = np.where(img > 0, 255, 0).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def manual_sort_boxes(boxes):\n",
    "    \"\"\"\n",
    "    Sort boxes by x-coordinate (left-to-right) manually.\n",
    "    boxes: list of (x, y, w, h)\n",
    "    returns: sorted list\n",
    "    \"\"\"\n",
    "    sorted_boxes = []\n",
    "\n",
    "    for box in boxes:\n",
    "        x = box[0]\n",
    "        inserted = False\n",
    "        for i, b in enumerate(sorted_boxes):\n",
    "            if x < b[0]:\n",
    "                sorted_boxes.insert(i, box)\n",
    "                inserted = True\n",
    "                break\n",
    "        if not inserted:\n",
    "            sorted_boxes.append(box)\n",
    "\n",
    "    return sorted_boxes\n",
    "\n",
    "\n",
    "def save_characters(characters_sortedL, characters_sortedR):\n",
    "    \"\"\"\n",
    "    Saves sorted character images from digits (left) and letters (right).\n",
    "    \n",
    "    Parameters:\n",
    "        characters_sortedL: list of (x, y, w, h, img) for digits\n",
    "        characters_sortedR: list of (x, y, w, h, img) for letters\n",
    "    \"\"\"\n",
    "    # Save digits\n",
    "    for i, (_, _, _, _, img) in enumerate(characters_sortedL):\n",
    "        cv2.imwrite(f\"digit_{i}.png\", img)\n",
    "\n",
    "    # Save letters\n",
    "    for i, (_, _, _, _, img) in enumerate(characters_sortedR):\n",
    "        cv2.imwrite(f\"letter_{i}.png\", img)\n",
    "\n",
    "\n",
    "def crop_characters(binary_img, boxes, resize_to=(64, 64), pad_ratio=0.09):\n",
    "    \"\"\"\n",
    "    Returns list of tuples: (x, y, w, h, char_img) with padded cropping.\n",
    "    \"\"\"\n",
    "    H, W = binary_img.shape[:2]\n",
    "    characters = []\n",
    "\n",
    "    for (x, y, w_b, h_b) in boxes:\n",
    "\n",
    "        # Compute proportional padding from box size\n",
    "        pad_x = int(w_b * pad_ratio)\n",
    "        pad_y = int(h_b * pad_ratio)\n",
    "\n",
    "        # Apply padded crop\n",
    "        x1 = max(0, x - pad_x)\n",
    "        y1 = max(0, y - pad_y)\n",
    "        x2 = min(W, x + w_b + pad_x)\n",
    "        y2 = min(H, y + h_b + pad_y)\n",
    "\n",
    "        char_img = binary_img[y1:y2, x1:x2]\n",
    "\n",
    "        # Resize if needed\n",
    "        # if resize_to is not None:\n",
    "        #     char_img = cv2.resize(char_img, resize_to, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        characters.append((x, y, w_b, h_b, char_img))\n",
    "\n",
    "    return characters\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "img = io.imread(\"Dataset/Vehicles with unpaid customs.png\")[:,:,:3]\n",
    "# img=plate_crop3\n",
    "gray = color.rgb2gray(img)\n",
    "\n",
    "# 1) Crop bottom part (Arabic region)\n",
    "h = gray.shape[0]\n",
    "plate = gray[int(h * 0.35):, :]\n",
    "\n",
    "\n",
    "# 2) Threshold + clean\n",
    "th = filters.threshold_otsu(plate)\n",
    "mask = plate < th\n",
    "\n",
    "mask = morphology.remove_small_objects(mask, 0.1)\n",
    "mask = morphology.remove_small_holes(mask, 0.1)\n",
    "\n",
    "# 3) Split halves\n",
    "H, W = mask.shape\n",
    "digits_img  = plate[:, :W // 2]\n",
    "letters_img = plate[:, W // 2:]\n",
    "\n",
    "digits_mask  = mask[:, :W // 2]\n",
    "letters_mask = mask[:, W // 2:]\n",
    "\n",
    "\n",
    "# 4) SAFE crop each half independently\n",
    "digits_img_c,  digits_mask_c  = clean_crop(digits_img, digits_mask)\n",
    "letters_img_c, letters_mask_c = clean_crop(letters_img, letters_mask)\n",
    "\n",
    "# 5) Build final clean images\n",
    "clean_digits  = make_clean(digits_img_c, digits_mask_c)\n",
    "clean_letters = make_clean(letters_img_c, letters_mask_c)\n",
    "\n",
    "# 6) Show results\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(digits_mask_c, cmap=\"gray\")\n",
    "plt.title(\"ARABIC DIGITS — CLEAN, NO BORDERS\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(letters_mask_c, cmap=\"gray\")\n",
    "plt.title(\"ARABIC LETTERS — CLEAN, NO BORDERS\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# 7) Save\n",
    "io.imsave(\"clean_digits.png\", img_as_ubyte(clean_digits))\n",
    "io.imsave(\"clean_letters.png\", img_as_ubyte(clean_letters))\n",
    "print(\"Saved clean_digits.png & clean_letters.png\")\n",
    "\n",
    "# Straight1 = io.imread('Dataset/image.png')\n",
    "# image=plate_crop1\n",
    "# image=Straight1\n",
    "# proccesded=preprocess_plate_with_smoothing(image)\n",
    "boxesL, boxesR,leftT,rightT= morphological_and_CCL(img,digits_mask_c,letters_mask_c,debug=True)\n",
    "# draw_components(leftT,rightT,boxesL,boxesR)\n",
    "\n",
    "out_digits, out_letters = draw_components(leftT, rightT, boxesL, boxesR)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(out_digits)\n",
    "plt.title(\"Digits with Boxes\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(out_letters)\n",
    "plt.title(\"Letters with Boxes\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# Sort boxes by x-coordinate\n",
    "boxes_sortedL = manual_sort_boxes(boxesL)\n",
    "boxes_sortedR = manual_sort_boxes(boxesR)\n",
    "\n",
    "# Crop in that order\n",
    "charimages_sortedL = crop_characters(leftT, boxes_sortedL)\n",
    "charimages_sortedR = crop_characters(rightT, boxes_sortedR)\n",
    "save_characters(charimages_sortedL,charimages_sortedR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82e95d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import easyocr\n",
    "os.environ['TESSDATA_PREFIX'] = os.path.abspath(\"Dataset\")\n",
    "# os.environ.pop('TESSDATA_PREFIX', None)\n",
    "def add_padding(img, pad=10):\n",
    "    return cv2.copyMakeBorder(\n",
    "        img, pad, pad, pad, pad,\n",
    "        borderType=cv2.BORDER_CONSTANT,\n",
    "        value=255\n",
    "    )\n",
    "\n",
    "def add_paddingblack(img, pad=200):\n",
    "    return cv2.copyMakeBorder(\n",
    "        img, pad, pad, pad, pad,\n",
    "        borderType=cv2.BORDER_CONSTANT,\n",
    "        value=0\n",
    "    )\n",
    "\n",
    "def recognize_arabic_digit(image_path, show_preprocessed=False):\n",
    "    \"\"\"\n",
    "    Recognize a single Arabic digit from an image.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to image file.\n",
    "        show_preprocessed (bool): If True, shows the binary preprocessed image.\n",
    "    \n",
    "    Returns:\n",
    "        str: Detected Arabic digit or empty string if not recognized.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Load image\n",
    "    # img = io.imread(image_path)\n",
    "    # img=add_paddingblack(img)\n",
    "    # img=add_padding(img)\n",
    "    img=d_mask\n",
    "    \n",
    "    # # 2. Convert to grayscale if needed\n",
    "    # gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img\n",
    "    \n",
    "    # # 3. Resize image up to help OCR\n",
    "    # gray = cv2.resize(gray, None, fx=5, fy=5, interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    # # 4. Smooth image to reduce noise\n",
    "    # blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "    \n",
    "    # # 5. Threshold to get binary image\n",
    "    # _, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # # 6. Invert if background is dark\n",
    "    # if np.mean(thresh) < 127:\n",
    "    #     thresh = cv2.bitwise_not(thresh)\n",
    "    \n",
    "    # Optional: show preprocessed image\n",
    "    if show_preprocessed:\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    # 7. Configure Tesseract for single character + Arabic digits only\n",
    "    # config = f'--oem 3 --psm 10 -c tessedit_char_whitelist={ARABIC_DIGITS}'\n",
    "    \n",
    "    # 8. Run OCR\n",
    "    # text = pytesseract.image_to_string(thresh, lang='ara')\n",
    "\n",
    "    reader = easyocr.Reader(['ar'])\n",
    "    results = reader.readtext(img)\n",
    "    texts = [text for bbox, text, prob in results]\n",
    "\n",
    "\n",
    "    # 9. Clean result\n",
    "    # text = text.strip()\n",
    "    return texts\n",
    "\n",
    "# Example usage:\n",
    "digit = recognize_arabic_digit(\"letter_0.png\", show_preprocessed=True)\n",
    "print(\"Detected Arabic digit EASYOCR:\", repr(digit))\n",
    "# print(\"Detected Arabic digit:\", repr(digit))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f156149",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MAAW FORTNITE BATTLE ROYALE\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray, rgba2rgb\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.morphology import (\n",
    "    remove_small_holes,\n",
    "    remove_small_objects,\n",
    "    binary_closing,\n",
    "    square,\n",
    ")\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.transform import resize\n",
    "from skimage.color import gray2rgb\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 1) SIMPLE GEOMETRIC UTILITIES\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def crop_bottom(img, top_ratio=0.40):\n",
    "    \"\"\"\n",
    "    Keep the lower part of the plate (digits + letters).\n",
    "    top_ratio is the fraction of height we cut from the top.\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    return img[int(h * top_ratio):, :]\n",
    "\n",
    "\n",
    "def split_digits_letters(bottom):\n",
    "    \"\"\"\n",
    "    Egyptian plate: digits on the left half, letters on the right half.\n",
    "    \"\"\"\n",
    "    h, w = bottom.shape[:2]\n",
    "    mid = w // 2\n",
    "    return bottom[:, :mid], bottom[:, mid:]\n",
    "\n",
    "\n",
    "def get_mask(region):\n",
    "    gray = rgb2gray(region)\n",
    "\n",
    "    T = threshold_otsu(gray)\n",
    "    mask = gray < T\n",
    "\n",
    "    # ✅ KEEP holes & dots (light cleaning only)\n",
    "    mask = remove_small_objects(mask, 25)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2) DIGITS EXTRACTION\n",
    "# ---------------------------------------------------\n",
    "#0.01\n",
    "def touches_border(r0, c0, r1, c1, H, W, margin_ratio=0.005):\n",
    "    mr = int(margin_ratio * H)\n",
    "    mc = int(margin_ratio * W)\n",
    "\n",
    "    if r0 <= mr: return True        # top\n",
    "    if c0 <= mc: return True        # left\n",
    "    if r1 >= H - mr: return True    # bottom\n",
    "    if c1 >= W - mc: return True    # right\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "def extract_digits(digits_region, max_chars=4, debug=False):\n",
    "    H0, W0 = digits_region.shape[:2]\n",
    "    border_ratio = 0.04\n",
    "    by = int(border_ratio * H0)\n",
    "    bx = int(border_ratio * W0)\n",
    "    sub = digits_region[by:H0 - by, bx:W0 - bx]\n",
    "\n",
    "\n",
    "    \n",
    "    mask = get_mask(sub)\n",
    "    H, W = mask.shape\n",
    "\n",
    "    # Kill thin border noise so it doesn’t attach to digits\n",
    "    #mask[:10, :] = 0\n",
    "    #mask[-10:, :] = 0\n",
    "    #mask[:, :5] = 0\n",
    "    #mask[:, -5:] = 0\n",
    "\n",
    "\n",
    "    lbl = label(mask)\n",
    "\n",
    "    candidates = []\n",
    "    for p in regionprops(lbl):\n",
    "        r0, c0, r1, c1 = p.bbox\n",
    "        '''\n",
    "        if touches_border(r0, c0, r1, c1, H, W, margin_ratio=0.02):\n",
    "            continue\n",
    "        '''\n",
    "        touches = touches_border(r0, c0, r1, c1, H, W, margin_ratio=0.01)\n",
    "\n",
    "        if touches:\n",
    "            h = r1 - r0\n",
    "            w = c1 - c0\n",
    "            ar = p.area / (H * W)\n",
    "\n",
    "            # ✅ only reject if it looks like a FRAME, not a digit\n",
    "            if h > 0.9 * H or w < 0.02 * W or ar < 0.002:\n",
    "                continue\n",
    "\n",
    "        h = r1 - r0\n",
    "        w = c1 - c0\n",
    "        area = p.area\n",
    "        wr = w / W\n",
    "        ar = area / (H * W)\n",
    "        '''\n",
    "        if wr < 0.08 or wr > 0.60:\n",
    "            continue\n",
    "        #if ar < 0.01:\n",
    "        if ar < 0.002:\n",
    "            continue\n",
    "        '''\n",
    "        if wr < 0.035 or wr > 0.75:\n",
    "            continue\n",
    "\n",
    "        if ar < 0.001:\n",
    "            continue\n",
    "\n",
    "        candidates.append({\"bbox\": [r0, c0, r1, c1], \"area\": area})\n",
    "\n",
    "    candidates.sort(key=lambda c: c[\"bbox\"][1])\n",
    "\n",
    "    merged = []\n",
    "    for c in candidates:\n",
    "        if not merged:\n",
    "            merged.append(c)\n",
    "            continue\n",
    "\n",
    "        r0, c0, r1, c1 = c[\"bbox\"]\n",
    "        r0m, c0m, r1m, c1m = merged[-1][\"bbox\"]\n",
    "        overlap_x = min(c1, c1m) - max(c0, c0m)\n",
    "\n",
    "        if overlap_x > 0:\n",
    "            merged[-1][\"bbox\"] = [\n",
    "                min(r0, r0m), min(c0, c0m),\n",
    "                max(r1, r1m), max(c1, c1m)\n",
    "            ]\n",
    "        else:\n",
    "            merged.append(c)\n",
    "\n",
    "    boxed_mask = gray2rgb(mask.astype(np.uint8) * 255)\n",
    "\n",
    "    chars = []\n",
    "    for m in merged:\n",
    "        r0, c0, r1, c1 = m[\"bbox\"]\n",
    "        #if (r1 - r0) < 0.40 * H:\n",
    "        if (r1 - r0) < 0.22 * H:\n",
    "            continue\n",
    "\n",
    "        boxed_mask[r0:r1, [c0, c1-1]] = [255, 0, 0]\n",
    "        boxed_mask[[r0, r1-1], c0:c1] = [255, 0, 0]\n",
    "\n",
    "        crop = resize(mask[r0:r1, c0:c1].astype(float), (40, 40))\n",
    "        # crop = mask[r0:r1, c0:c1].astype(float)\n",
    "        chars.append((c0 + bx, crop))\n",
    "\n",
    "    chars.sort(key=lambda x: x[0])\n",
    "\n",
    "    if debug:\n",
    "        return [c for _, c in chars][:max_chars], mask, boxed_mask\n",
    "    else:\n",
    "        return [c for _, c in chars][:max_chars]\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 3) LETTERS EXTRACTION\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def extract_letters(letters_region, max_chars=3, debug=False):\n",
    "    H0, W0 = letters_region.shape[:2]\n",
    "    by = int(0.04 * H0)\n",
    "    bx = int(0.04 * W0)\n",
    "    sub = letters_region[by:H0 - by, bx:W0 - bx]\n",
    "\n",
    "    mask = get_mask(sub)\n",
    "    H, W = mask.shape\n",
    "    lbl = label(mask)\n",
    "\n",
    "    boxed_mask = gray2rgb(mask.astype(np.uint8) * 255)\n",
    "\n",
    "    big_blobs = []   # main letter bodies\n",
    "    small_blobs = [] # dots\n",
    "\n",
    "    # -----------------------------\n",
    "    # 1) SPLIT BIG BLOBS & DOTS\n",
    "    # -----------------------------\n",
    "    for p in regionprops(lbl):\n",
    "        r0, c0, r1, c1 = p.bbox\n",
    "\n",
    "        if touches_border(r0, c0, r1, c1, H, W, margin_ratio=0.02):\n",
    "            continue\n",
    "    \n",
    "\n",
    "\n",
    "        h = r1 - r0\n",
    "        w = c1 - c0\n",
    "        area = p.area\n",
    "        cy = p.centroid[0] / H\n",
    "        wr = w / W\n",
    "        ar = area / (H * W)\n",
    "        '''\n",
    "        # REMOVE VERTICAL BORDER\n",
    "        margin = int(0.02 * H)\n",
    "        if r0 <= margin and r1 >= H - margin:\n",
    "            continue\n",
    "        '''\n",
    "\n",
    "\n",
    "        # 👉 DOT = any small area < 0.015\n",
    "        if ar < 0.015:\n",
    "            small_blobs.append((r0, c0, r1, c1))\n",
    "            continue\n",
    "\n",
    "        # 👉 MAIN LETTER FILTER (no lower area limit now)\n",
    "        if wr < 0.08 or wr > 0.75:\n",
    "            continue\n",
    "        if ar > 0.22:\n",
    "            continue\n",
    "        if cy > 0.75:\n",
    "            continue\n",
    "\n",
    "        big_blobs.append([r0, c0, r1, c1])\n",
    "\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # 2) ATTACH EACH DOT TO NEAREST LETTER BOX\n",
    "    # -----------------------------------------\n",
    "    for dr0, dc0, dr1, dc1 in small_blobs:\n",
    "        dc = (dc0 + dc1) / 2\n",
    "        dr = (dr0 + dr1) / 2\n",
    "\n",
    "        best_i = -1\n",
    "        best_dx = 1e9\n",
    "\n",
    "        for i, box in enumerate(big_blobs):\n",
    "            r0, c0, r1, c1 = box\n",
    "            bc = (c0 + c1) / 2\n",
    "            br = (r0 + r1) / 2\n",
    "\n",
    "            dx = abs(dc - bc)\n",
    "            dy = abs(dr - br)\n",
    "\n",
    "            # ✅ must be vertically close AND horizontally closest\n",
    "            if dx < best_dx and dy < 120:\n",
    "                best_dx = dx\n",
    "                best_i = i\n",
    "\n",
    "        # ✅ attach dot ONLY to the nearest valid letter\n",
    "        if best_i != -1:\n",
    "            box = big_blobs[best_i]\n",
    "            box[0] = min(box[0], dr0)\n",
    "            box[1] = min(box[1], dc0)\n",
    "            box[2] = max(box[2], dr1)\n",
    "            box[3] = max(box[3], dc1)\n",
    "\n",
    "\n",
    "        # if dot wasn't matched, safely ignore it\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # 3) SORT & CROP FINAL LETTERS\n",
    "    # -----------------------------------------\n",
    "    big_blobs.sort(key=lambda b: b[1])\n",
    "\n",
    "    chars = []\n",
    "    for r0, c0, r1, c1 in big_blobs:\n",
    "        boxed_mask[r0:r1, [c0, c1-1]] = [255, 0, 0]\n",
    "        boxed_mask[[r0, r1-1], c0:c1] = [255, 0, 0]\n",
    "\n",
    "        crop = resize(mask[r0:r1, c0:c1].astype(float), (40, 40))\n",
    "        # crop = mask[r0:r1, c0:c1].astype(float)\n",
    "        chars.append((c0 + bx, crop))\n",
    "\n",
    "    if debug:\n",
    "        return [c for _, c in chars][:max_chars], mask, boxed_mask\n",
    "    else:\n",
    "        return [c for _, c in chars][:max_chars]\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4) FULL PIPELINE FOR ONE IMAGE\n",
    "# ---------------------------------------------------\n",
    "def process_plate(img):\n",
    "    bottom = crop_bottom(img)\n",
    "    digits_region, letters_region = split_digits_letters(bottom)\n",
    "\n",
    "    digits, d_mask, d_boxes = extract_digits(digits_region, debug=True)\n",
    "    letters, l_mask, l_boxes = extract_letters(letters_region, debug=True)\n",
    "\n",
    "    return digits_region, letters_region, digits, letters, d_mask, d_boxes, l_mask, l_boxes\n",
    "\n",
    "\n",
    "# img22 = imread('Q1.jpg')\n",
    "# img22 = imread('Dataset/Buses & government vehicles.png')\n",
    "# img22 = imread('Dataset/Diplomatic vehicles.png')\n",
    "#img22 = imread('Dataset/image.png')\n",
    "img22 = imread('Dataset/Limousines & tourist buses.png')\n",
    "#img22 = imread('Dataset/Police vehicles.png')\n",
    "#img22 = rgba2rgb(imread('Dataset/Private vehicles & motorcycles.png'))\n",
    "#img22 = rgba2rgb(imread('Dataset/Taxis.png'))\n",
    "#img22 = imread('Dataset/Trucks.png')\n",
    "#img22 = imread('Dataset/Vehicles with unpaid customs.png')\n",
    "\n",
    "def save_characters(digits, letters):\n",
    "    # Save digits\n",
    "    for i, img in enumerate(digits):\n",
    "        out = (img * 255).astype(np.uint8) if img.dtype != np.uint8 else img\n",
    "        cv2.imwrite(f\"digit_{i}.png\", out)\n",
    "\n",
    "    # Save letters\n",
    "    for i, img in enumerate(letters):\n",
    "        out = (img * 255).astype(np.uint8) if img.dtype != np.uint8 else img\n",
    "        cv2.imwrite(f\"letter_{i}.png\", out)\n",
    "\n",
    "\n",
    "\n",
    "d_reg, l_reg, digits, letters, d_mask, d_boxes, l_mask, l_boxes = process_plate(img22)\n",
    "# d_reg, l_reg, digits, letters, d_mask, d_boxes, l_mask, l_boxes = process_plate(Detected_Plate1)\n",
    "#problem in plate_crop2 and plate_crop3\n",
    "\n",
    "# ---- Regions ----\n",
    "show_images([d_reg, l_reg], [\"Digits Region\", \"Letters Region\"])\n",
    "\n",
    "# ---- Masks ----\n",
    "show_images([d_mask, l_mask], [\"Digits Mask\", \"Letters Mask\"])\n",
    "\n",
    "# ---- Masks with Bounding Boxes ----\n",
    "show_images([d_boxes, l_boxes], [\"Digits Mask + Boxes\", \"Letters Mask + Boxes\"])\n",
    "\n",
    "# ---- Final Cropped Digits ----\n",
    "digit_titles = [f\"Digit {i}\" for i in range(len(digits))]\n",
    "show_images(digits, digit_titles)\n",
    "\n",
    "# ---- Final Cropped Letters ----\n",
    "letter_titles = [f\"Letter {i}\" for i in range(len(letters))]\n",
    "show_images(letters, letter_titles)\n",
    "\n",
    "save_characters(digits,letters)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "MAAW FORTNITE BATTLE ROYALE\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf60faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import os\n",
    "\n",
    "western_to_arabic = {\n",
    "    0: '٠', 1: '١', 2: '٢', 3: '٣', 4: '٤',\n",
    "    5: '٥', 6: '٦', 7: '٧', 8: '٨', 9: '٩'\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# NORMALIZATION\n",
    "# -------------------------------\n",
    "def normalize_digit(img):\n",
    "    img = img.copy()\n",
    "\n",
    "    if np.mean(img) > 127:\n",
    "        img = cv2.bitwise_not(img)\n",
    "\n",
    "    ys, xs = np.where(img > 0)\n",
    "    if len(xs) == 0:\n",
    "        return cv2.resize(img, (64, 64))\n",
    "\n",
    "    x0, x1 = xs.min(), xs.max()\n",
    "    y0, y1 = ys.min(), ys.max()\n",
    "    img = img[y0:y1+1, x0:x1+1]\n",
    "\n",
    "    img = cv2.copyMakeBorder(img, 12, 12, 12, 12,\n",
    "                              cv2.BORDER_CONSTANT, value=0)\n",
    "\n",
    "    img = cv2.resize(img, (64, 64), interpolation=cv2.INTER_NEAREST)\n",
    "    return img.astype(np.uint8)\n",
    "\n",
    "# -------------------------------\n",
    "# MULTI-TEMPLATE VOTING MATCHER\n",
    "# -------------------------------\n",
    "def match_digit(img, refs_folder=\"digits_reference\"):\n",
    "    img = normalize_digit(img)\n",
    "\n",
    "    scores = {}\n",
    "\n",
    "    for d in range(10):\n",
    "        digit_folder = os.path.join(refs_folder, str(d))\n",
    "        if not os.path.exists(digit_folder):\n",
    "            continue\n",
    "\n",
    "        best_local = -1\n",
    "\n",
    "        for fname in os.listdir(digit_folder):\n",
    "            ref = cv2.imread(os.path.join(digit_folder, fname), 0)\n",
    "            ref = normalize_digit(ref)\n",
    "\n",
    "            score = ssim(img, ref)\n",
    "            best_local = max(best_local, score)\n",
    "\n",
    "        scores[d] = best_local\n",
    "\n",
    "    # ✅ pick digit with strongest template match\n",
    "    best_digit = max(scores, key=scores.get)\n",
    "\n",
    "    return best_digit\n",
    "\n",
    "# -------------------------------\n",
    "# CLASSIFICATION\n",
    "# -------------------------------\n",
    "final_digits_western = []\n",
    "final_digits_arabic  = []\n",
    "\n",
    "for d in digits:\n",
    "    d_img = (d * 255).astype(np.uint8)\n",
    "    digit = match_digit(d_img)\n",
    "\n",
    "    final_digits_western.append(str(digit))\n",
    "    final_digits_arabic.append(western_to_arabic[digit])\n",
    "\n",
    "# -------------------------------\n",
    "# FINAL OUTPUT\n",
    "# -------------------------------\n",
    "print(\"\\n✅ FINAL PLATE (ARABIC): \", \"\".join(final_digits_arabic))\n",
    "print(\"✅ FINAL PLATE (WESTERN):\", \"\".join(final_digits_western))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4522eea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import easyocr\n",
    "os.environ['TESSDATA_PREFIX'] = os.path.abspath(\"Dataset\")\n",
    "# os.environ.pop('TESSDATA_PREFIX', None)\n",
    "def add_padding(img, pad=10):\n",
    "    return cv2.copyMakeBorder(\n",
    "        img, pad, pad, pad, pad,\n",
    "        borderType=cv2.BORDER_CONSTANT,\n",
    "        value=255\n",
    "    )\n",
    "\n",
    "def add_paddingblack(img, pad=50):\n",
    "    return cv2.copyMakeBorder(\n",
    "        img, pad, pad, pad, pad,\n",
    "        borderType=cv2.BORDER_CONSTANT,\n",
    "        value=0\n",
    "    )\n",
    "\n",
    "\n",
    "def pad_for_easyocr(img):\n",
    "    h, w = img.shape\n",
    "    new_img = np.zeros((h, w*3), dtype=np.uint8)  # black background\n",
    "    new_img[:, w:w*2] = img  # center the character\n",
    "    return new_img\n",
    "\n",
    "\n",
    "def recognize_arabic_digit(image_path, show_preprocessed=False):\n",
    "    \"\"\"\n",
    "    Recognize a single Arabic digit from an image.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to image file.\n",
    "        show_preprocessed (bool): If True, shows the binary preprocessed image.\n",
    "    \n",
    "    Returns:\n",
    "        str: Detected Arabic digit or empty string if not recognized.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Load image\n",
    "    img = io.imread(image_path)\n",
    "    # img=add_paddingblack(img)\n",
    "    # img=pad_for_easyocr(img)\n",
    "    \n",
    "    # img=add_padding(img)\n",
    "    # img=d_mask\n",
    "    if img.dtype == bool:\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "\n",
    "    # # Ensure grayscale, not weird format\n",
    "    # if len(img.shape) == 2:\n",
    "    #     img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    # # 2. Convert to grayscale if needed\n",
    "    # gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img\n",
    "    \n",
    "    # # 3. Resize image up to help OCR\n",
    "    # gray = cv2.resize(gray, None, fx=5, fy=5, interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    # # 4. Smooth image to reduce noise\n",
    "    # blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "    \n",
    "    # # 5. Threshold to get binary image\n",
    "    # _, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # # 6. Invert if background is dark\n",
    "    # if np.mean(thresh) < 127:\n",
    "    #     thresh = cv2.bitwise_not(thresh)\n",
    "    \n",
    "    # # Optional: show preprocessed image\n",
    "    if show_preprocessed:\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    # 7. Configure Tesseract for single character + Arabic digits only\n",
    "    # config = f'--oem 3 --psm 10 -c tessedit_char_whitelist={ARABIC_DIGITS}'\n",
    "    \n",
    "    # 8. Run OCR\n",
    "    # text = pytesseract.image_to_string(thresh, lang='ara')\n",
    "\n",
    "    reader = easyocr.Reader(['ar'])\n",
    "    results = reader.readtext(img)\n",
    "    texts = [text for bbox, text, prob in results]\n",
    "\n",
    "\n",
    "    # 9. Clean result\n",
    "    # text = text.strip()\n",
    "    return texts\n",
    "\n",
    "# Example usage:\n",
    "digit = recognize_arabic_digit(\"letter_0.png\", show_preprocessed=True)\n",
    "print(\"Detected Arabic digit EASYOCR:\", repr(digit))\n",
    "# print(\"Detected Arabic digit:\", repr(digit))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f5b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "reader = easyocr.Reader(['ar'], gpu=False)  # make this global or at module level\n",
    "\n",
    "def prepare_for_easyocr_char(img):\n",
    "    \"\"\"\n",
    "    img: numpy array (grayscale or RGB) containing ONE character.\n",
    "    Returns a padded, upscaled image suitable for EasyOCR.\n",
    "    \"\"\"\n",
    "\n",
    "    # If bool -> uint8\n",
    "    if img.dtype == bool:\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    if img.ndim == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        img = img.astype(np.uint8)\n",
    "\n",
    "    # Normalize range\n",
    "    if img.max() <= 1:\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "\n",
    "    # Binarize a bit to stabilize\n",
    "    _, img = cv2.threshold(img, 0, 255,\n",
    "                           cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Make sure text is dark on light (helps EasyOCR)\n",
    "    if img.mean() < 127:      # mostly dark => likely white on black\n",
    "        img = 255 - img       # invert to black text on white\n",
    "\n",
    "    # ---- FIX #1: add margin so glyph doesn't touch borders ----\n",
    "    border = 20\n",
    "    img = cv2.copyMakeBorder(\n",
    "        img, border, border, border, border,\n",
    "        borderType=cv2.BORDER_CONSTANT,\n",
    "        value=255  # white background\n",
    "    )\n",
    "\n",
    "    # ---- FIX #2: upscale ----\n",
    "    img = cv2.resize(img, None, fx=5, fy=5,\n",
    "                     interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def recognize_single_char_easyocr(image_path, show=False):\n",
    "    # load from file\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    prep = prepare_for_easyocr_char(img)\n",
    "\n",
    "    if show:\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.imshow(prep, cmap='gray')\n",
    "        plt.axis('off'); plt.show()\n",
    "\n",
    "    # detail=0 -> just texts; paragraph=False so it doesn't merge things\n",
    "    texts = reader.readtext(prep, detail=0, paragraph=False)\n",
    "\n",
    "    return texts[0] if texts else \"\"\n",
    "\n",
    "digit0 = recognize_single_char_easyocr(\"clean_digits.png\", show=True)\n",
    "letter0 = recognize_single_char_easyocr(\"clean_letters.png\", show=True)\n",
    "print(\"digit_0:\", repr(digit0))\n",
    "print(\"letter_0:\", repr(letter0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cddadb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MAAW FORTNITE BATTLE ROYALE\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2                         ### <<< you were using cv2 in save_characters\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray, rgba2rgb\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.morphology import (\n",
    "    remove_small_holes,\n",
    "    remove_small_objects,\n",
    "    binary_closing,\n",
    "    square,\n",
    ")\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.transform import resize\n",
    "from skimage.color import gray2rgb\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 1) SIMPLE GEOMETRIC UTILITIES\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def crop_bottom(img, top_ratio=0.40):\n",
    "    \"\"\"\n",
    "    Keep the lower part of the plate (digits + letters).\n",
    "    top_ratio is the fraction of height we cut from the top.\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    return img[int(h * top_ratio):, :]\n",
    "\n",
    "\n",
    "def split_digits_letters(bottom):\n",
    "    \"\"\"\n",
    "    Egyptian plate: digits on the left half, letters on the right half.\n",
    "    \"\"\"\n",
    "    h, w = bottom.shape[:2]\n",
    "    mid = w // 2\n",
    "    return bottom[:, :mid], bottom[:, mid:]\n",
    "\n",
    "\n",
    "def get_mask(region):\n",
    "    gray = rgb2gray(region)\n",
    "    T = threshold_otsu(gray)\n",
    "    mask = gray < T\n",
    "\n",
    "    # ✅ KEEP holes & dots (light cleaning only)\n",
    "    mask = remove_small_objects(mask, 25)\n",
    "    return mask\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Helper: create a crop that is friendly for OCR\n",
    "# ---------------------------------------------------\n",
    "def make_ocr_char_crop(gray_sub, r0, c0, r1, c1,\n",
    "                       pad=3, scale=3):\n",
    "    \"\"\"\n",
    "    gray_sub : grayscale version of sub-image (0–1)\n",
    "    (r0,c0,r1,c1) : bbox in sub coordinates\n",
    "    pad : extra pixels around character\n",
    "    scale : upscaling factor (so text is not tiny)\n",
    "    \"\"\"\n",
    "    H, W = gray_sub.shape\n",
    "\n",
    "    rr0 = max(r0 - pad, 0)\n",
    "    cc0 = max(c0 - pad, 0)\n",
    "    rr1 = min(r1 + pad, H)\n",
    "    cc1 = min(c1 + pad, W)\n",
    "\n",
    "    crop = gray_sub[rr0:rr1, cc0:cc1]        # 0–1 float from rgb2gray\n",
    "\n",
    "    # upscale (don’t DOWNsize to 40×40)\n",
    "    h, w = crop.shape\n",
    "    crop = resize(crop, (int(h * scale), int(w * scale)),\n",
    "                  anti_aliasing=True)\n",
    "\n",
    "    return crop   # still float 0–1\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2) DIGITS EXTRACTION\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def touches_border(r0, c0, r1, c1, H, W, margin_ratio=0.005):\n",
    "    mr = int(margin_ratio * H)\n",
    "    mc = int(margin_ratio * W)\n",
    "\n",
    "    if r0 <= mr: return True        # top\n",
    "    if c0 <= mc: return True        # left\n",
    "    if r1 >= H - mr: return True    # bottom\n",
    "    if c1 >= W - mc: return True    # right\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def extract_digits(digits_region, max_chars=4, debug=False):\n",
    "    H0, W0 = digits_region.shape[:2]\n",
    "    border_ratio = 0.04\n",
    "    by = int(border_ratio * H0)\n",
    "    bx = int(border_ratio * W0)\n",
    "    sub = digits_region[by:H0 - by, bx:W0 - bx]\n",
    "\n",
    "    # segmentation is done on mask\n",
    "    mask = get_mask(sub)\n",
    "    gray_sub = rgb2gray(sub)          ### <<< NEW: grayscale for OCR crops\n",
    "    H, W = mask.shape\n",
    "\n",
    "    lbl = label(mask)\n",
    "\n",
    "    candidates = []\n",
    "    for p in regionprops(lbl):\n",
    "        r0, c0, r1, c1 = p.bbox\n",
    "\n",
    "        touches = touches_border(r0, c0, r1, c1, H, W, margin_ratio=0.01)\n",
    "        if touches:\n",
    "            h = r1 - r0\n",
    "            w = c1 - c0\n",
    "            ar = p.area / (H * W)\n",
    "            # ✅ only reject if it looks like a FRAME, not a digit\n",
    "            if h > 0.9 * H or w < 0.02 * W or ar < 0.002:\n",
    "                continue\n",
    "\n",
    "        h = r1 - r0\n",
    "        w = c1 - c0\n",
    "        area = p.area\n",
    "        wr = w / W\n",
    "        ar = area / (H * W)\n",
    "\n",
    "        if wr < 0.035 or wr > 0.75:\n",
    "            continue\n",
    "        if ar < 0.001:\n",
    "            continue\n",
    "\n",
    "        candidates.append({\"bbox\": [r0, c0, r1, c1], \"area\": area})\n",
    "\n",
    "    # sort left → right\n",
    "    candidates.sort(key=lambda c: c[\"bbox\"][1])\n",
    "\n",
    "    # merge overlapping boxes\n",
    "    merged = []\n",
    "    for c in candidates:\n",
    "        if not merged:\n",
    "            merged.append(c)\n",
    "            continue\n",
    "\n",
    "        r0, c0, r1, c1 = c[\"bbox\"]\n",
    "        r0m, c0m, r1m, c1m = merged[-1][\"bbox\"]\n",
    "        overlap_x = min(c1, c1m) - max(c0, c0m)\n",
    "\n",
    "        if overlap_x > 0:\n",
    "            merged[-1][\"bbox\"] = [\n",
    "                min(r0, r0m), min(c0, c0m),\n",
    "                max(r1, r1m), max(c1, c1m)\n",
    "            ]\n",
    "        else:\n",
    "            merged.append(c)\n",
    "\n",
    "    boxed_mask = gray2rgb(mask.astype(np.uint8) * 255)\n",
    "\n",
    "    chars = []\n",
    "    for m in merged:\n",
    "        r0, c0, r1, c1 = m[\"bbox\"]\n",
    "        if (r1 - r0) < 0.22 * H:\n",
    "            continue\n",
    "\n",
    "        # draw box for debug\n",
    "        boxed_mask[r0:r1, [c0, c1-1]] = [255, 0, 0]\n",
    "        boxed_mask[[r0, r1-1], c0:c1] = [255, 0, 0]\n",
    "\n",
    "        # <<< OLD:\n",
    "        # crop = resize(mask[r0:r1, c0:c1].astype(float), (40, 40))\n",
    "        # chars.append((c0 + bx, crop))\n",
    "\n",
    "        # >>> NEW: OCR-friendly grayscale crop with padding + upscaling\n",
    "        crop = make_ocr_char_crop(gray_sub, r0, c0, r1, c1,\n",
    "                                  pad=3, scale=3)\n",
    "        chars.append((c0 + bx, crop))\n",
    "\n",
    "    chars.sort(key=lambda x: x[0])\n",
    "\n",
    "    if debug:\n",
    "        return [c for _, c in chars][:max_chars], mask, boxed_mask\n",
    "    else:\n",
    "        return [c for _, c in chars][:max_chars]\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 3) LETTERS EXTRACTION\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def extract_letters(letters_region, max_chars=3, debug=False):\n",
    "    H0, W0 = letters_region.shape[:2]\n",
    "    by = int(0.04 * H0)\n",
    "    bx = int(0.04 * W0)\n",
    "    sub = letters_region[by:H0 - by, bx:W0 - bx]\n",
    "\n",
    "    mask = get_mask(sub)\n",
    "    gray_sub = rgb2gray(sub)            ### <<< NEW: grayscale for OCR crops\n",
    "    H, W = mask.shape\n",
    "    lbl = label(mask)\n",
    "\n",
    "    boxed_mask = gray2rgb(mask.astype(np.uint8) * 255)\n",
    "\n",
    "    big_blobs = []   # main letter bodies\n",
    "    small_blobs = [] # dots\n",
    "\n",
    "    # -----------------------------\n",
    "    # 1) SPLIT BIG BLOBS & DOTS\n",
    "    # -----------------------------\n",
    "    for p in regionprops(lbl):\n",
    "        r0, c0, r1, c1 = p.bbox\n",
    "\n",
    "        if touches_border(r0, c0, r1, c1, H, W, margin_ratio=0.02):\n",
    "            continue\n",
    "\n",
    "        h = r1 - r0\n",
    "        w = c1 - c0\n",
    "        area = p.area\n",
    "        cy = p.centroid[0] / H\n",
    "        wr = w / W\n",
    "        ar = area / (H * W)\n",
    "\n",
    "        # 👉 DOT = any small area < 0.015\n",
    "        if ar < 0.015:\n",
    "            small_blobs.append((r0, c0, r1, c1))\n",
    "            continue\n",
    "\n",
    "        # 👉 MAIN LETTER FILTER (no lower area limit now)\n",
    "        if wr < 0.08 or wr > 0.75:\n",
    "            continue\n",
    "        if ar > 0.22:\n",
    "            continue\n",
    "        if cy > 0.75:\n",
    "            continue\n",
    "\n",
    "        big_blobs.append([r0, c0, r1, c1])\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # 2) ATTACH EACH DOT TO NEAREST LETTER BOX\n",
    "    # -----------------------------------------\n",
    "    for dr0, dc0, dr1, dc1 in small_blobs:\n",
    "        dc = (dc0 + dc1) / 2\n",
    "        dr = (dr0 + dr1) / 2\n",
    "\n",
    "        best_i = -1\n",
    "        best_dx = 1e9\n",
    "\n",
    "        for i, box in enumerate(big_blobs):\n",
    "            r0, c0, r1, c1 = box\n",
    "            bc = (c0 + c1) / 2\n",
    "            br = (r0 + r1) / 2\n",
    "\n",
    "            dx = abs(dc - bc)\n",
    "            dy = abs(dr - br)\n",
    "\n",
    "            # ✅ must be vertically close AND horizontally closest\n",
    "            if dx < best_dx and dy < 120:\n",
    "                best_dx = dx\n",
    "                best_i = i\n",
    "\n",
    "        # ✅ attach dot ONLY to the nearest valid letter\n",
    "        if best_i != -1:\n",
    "            box = big_blobs[best_i]\n",
    "            box[0] = min(box[0], dr0)\n",
    "            box[1] = min(box[1], dc0)\n",
    "            box[2] = max(box[2], dr1)\n",
    "            box[3] = max(box[3], dc1)\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # 3) SORT & CROP FINAL LETTERS\n",
    "    # -----------------------------------------\n",
    "    big_blobs.sort(key=lambda b: b[1])\n",
    "\n",
    "    chars = []\n",
    "    for r0, c0, r1, c1 in big_blobs:\n",
    "        boxed_mask[r0:r1, [c0, c1-1]] = [255, 0, 0]\n",
    "        boxed_mask[[r0, r1-1], c0:c1] = [255, 0, 0]\n",
    "\n",
    "        # <<< OLD:\n",
    "        # crop = resize(mask[r0:r1, c0:c1].astype(float), (40, 40))\n",
    "        # chars.append((c0 + bx, crop))\n",
    "\n",
    "        # >>> NEW: grayscale + padding + upscaling\n",
    "        crop = make_ocr_char_crop(gray_sub, r0, c0, r1, c1,\n",
    "                                  pad=3, scale=3)\n",
    "        chars.append((c0 + bx, crop))\n",
    "\n",
    "    if debug:\n",
    "        return [c for _, c in chars][:max_chars], mask, boxed_mask\n",
    "    else:\n",
    "        return [c for _, c in chars][:max_chars]\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4) FULL PIPELINE FOR ONE IMAGE\n",
    "# ---------------------------------------------------\n",
    "def process_plate(img):\n",
    "    bottom = crop_bottom(img)\n",
    "    digits_region, letters_region = split_digits_letters(bottom)\n",
    "\n",
    "    digits, d_mask, d_boxes = extract_digits(digits_region, debug=True)\n",
    "    letters, l_mask, l_boxes = extract_letters(letters_region, debug=True)\n",
    "\n",
    "    return digits_region, letters_region, digits, letters, d_mask, d_boxes, l_mask, l_boxes\n",
    "\n",
    "\n",
    "# Choose your plate image\n",
    "img22 = imread('Dataset/Limousines & tourist buses.png')\n",
    "\n",
    "def save_characters(digits, letters):\n",
    "    # digits / letters are floats 0–1 → uint8 0–255\n",
    "    for i, img in enumerate(digits):\n",
    "        out = (img * 255).astype(np.uint8)\n",
    "        cv2.imwrite(f\"digit_{i}.png\", out)\n",
    "\n",
    "    for i, img in enumerate(letters):\n",
    "        out = (img * 255).astype(np.uint8)\n",
    "        cv2.imwrite(f\"letter_{i}.png\", out)\n",
    "\n",
    "\n",
    "d_reg, l_reg, digits, letters, d_mask, d_boxes, l_mask, l_boxes = process_plate(img22)\n",
    "\n",
    "# (show_images assumed defined elsewhere)\n",
    "show_images([d_reg, l_reg], [\"Digits Region\", \"Letters Region\"])\n",
    "show_images([d_mask, l_mask], [\"Digits Mask\", \"Letters Mask\"])\n",
    "show_images([d_boxes, l_boxes], [\"Digits Mask + Boxes\", \"Letters Mask + Boxes\"])\n",
    "\n",
    "digit_titles = [f\"Digit {i}\" for i in range(len(digits))]\n",
    "show_images(digits, digit_titles)\n",
    "\n",
    "letter_titles = [f\"Letter {i}\" for i in range(len(letters))]\n",
    "show_images(letters, letter_titles)\n",
    "\n",
    "save_characters(digits, letters)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
