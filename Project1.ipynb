{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74d243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Student Names + (IDs): \n",
    "\n",
    "Abdelrahman Mohamed Kamal Abdelaziz (1220255)\n",
    "Mazen Ahmed Fouad Abdelwahab (1220269)\n",
    "Mohamed Hesham Ibrahim Hassanain (1220278)\n",
    "Ahmed Walaa Abdlelkhalek Abdelrahman (1220216)\n",
    "\n",
    "'''\n",
    "#Import(s)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "import cv2\n",
    "from skimage.feature import canny\n",
    "from skimage.color import rgb2gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c595dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images,titles=None):\n",
    "    n_ims = len(images)\n",
    "    if titles is None: titles = ['(%d)' % i for i in range(1,n_ims + 1)]\n",
    "    fig = plt.figure()\n",
    "    n = 1\n",
    "    for image,title in zip(images,titles):\n",
    "        a = fig.add_subplot(1,n_ims,n)\n",
    "        if image.ndim == 2: \n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "        n += 1\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_ims)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9664472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plate Localization\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Path1 = 'Localization Test/One Step All Angles No Headlights/Straight.jpeg'\n",
    "Path2 = 'Localization Test/Two Step All Angles No Headlights/Straight.jpeg'\n",
    "Path3 = 'Localization Test/Three Step All Angles No Headlights/Straight.jpeg'\n",
    "Path4 = 'Localization Test/One Step All Angles With Headlights/Straight.jpeg'\n",
    "Path5 = 'Localization Test/Two Step All Angles With Headlights/Straight.jpeg'\n",
    "\n",
    "Path11 = 'Localization Test/One Step All Angles No Headlights/Elevated.jpeg'\n",
    "Path12 = 'Localization Test/Two Step All Angles No Headlights/Elevated.jpeg'\n",
    "Path13 = 'Localization Test/Three Step All Angles No Headlights/Elevated.jpeg'\n",
    "Path14 = 'Localization Test/One Step All Angles With Headlights/Elevated.jpeg'\n",
    "Path15 = 'Localization Test/Two Step All Angles With Headlights/Elevated.jpeg'\n",
    "\n",
    "Path111 = 'Localization Test/One Step All Angles No Headlights/Slight Right.jpeg'\n",
    "Path112 = 'Localization Test/Two Step All Angles No Headlights/Slight Right.jpeg'\n",
    "Path113 = 'Localization Test/Three Step All Angles No Headlights/Slight Right.jpeg'\n",
    "Path114 = 'Localization Test/One Step All Angles With Headlights/Right.jpeg'\n",
    "Path115 = 'Localization Test/Two Step All Angles With Headlights/Right.jpeg'\n",
    "\n",
    "Path1111 = 'Localization Test/One Step All Angles No Headlights/Slight Left.jpeg'\n",
    "Path1112 = 'Localization Test/Two Step All Angles No Headlights/Slight Left.jpeg'\n",
    "Path1113 = 'Localization Test/Three Step All Angles No Headlights/Slight Left.jpeg'\n",
    "Path1114 = 'Localization Test/One Step All Angles With Headlights/Left.jpeg'\n",
    "Path1115 = 'Localization Test/Two Step All Angles With Headlights/Left.jpeg'\n",
    "\n",
    "Path11111 = 'Localization Test/One Step All Angles No Headlights/Extreme Left.jpeg'\n",
    "Path11112 = 'Localization Test/One Step All Angles No Headlights/Extreme Right.jpeg'\n",
    "Path11113 = 'Localization Test/Two Step All Angles No Headlights/Extreme Left.jpeg'\n",
    "Path11114 = 'Localization Test/Two Step All Angles No Headlights/Extreme Right.jpeg'\n",
    "Path11115 = 'Localization Test/Three Step All Angles No Headlights/Extreme Left.jpeg'\n",
    "Path11116 = 'Localization Test/Three Step All Angles No Headlights/Extreme Right.jpeg'\n",
    "   \n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def Plate_Detection(image_path):\n",
    "\n",
    "    # Original Image\n",
    "    Original_Img = io.imread(image_path)[:,:,:3]\n",
    "    Height, Width, _ = Original_Img.shape\n",
    "\n",
    "    # Read Image and convert to grayscale\n",
    "    img = cv2.imread(image_path)[:,:,:3]\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply CLAHE to improve local contrast\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    gray_clahe = clahe.apply(gray)\n",
    "\n",
    "    # Apply Gaussian Blur to reduce noise\n",
    "    gray_blur = cv2.GaussianBlur(gray_clahe, (5,5), 0)\n",
    "\n",
    "    # Adaptive Thresholding to handle dark and bright regions\n",
    "    thresh = cv2.adaptiveThreshold(gray_blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 19, 9)\n",
    "\n",
    "    # Morphological closing to connect fragmented regions\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "    morph = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    plate_candidates = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        aspect_ratio = w / h\n",
    "        area_ratio = (w * h) / (Height * Width)\n",
    "        if (1.8 < aspect_ratio < 3.7) and (0.01 < area_ratio < 0.3):\n",
    "            plate_candidates.append((x, y, w, h))\n",
    "\n",
    "    if not plate_candidates:\n",
    "        print(\"No plate candidate found.\")\n",
    "        return None\n",
    "\n",
    "    # Choose the best candidate\n",
    "    Best_Score = -1\n",
    "    Best_Candidate = None\n",
    "\n",
    "    for (x, y, w, h) in plate_candidates:\n",
    "\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "        Current_Image = Original_Img[y:y+h, x:x+w]\n",
    "\n",
    "        # --- Edge Density ---\n",
    "        CannyEdges = canny(rgb2gray(Current_Image), sigma=1.0)\n",
    "        edge_ratio = np.count_nonzero(CannyEdges) / (h * w)\n",
    "\n",
    "        # --- Color / brightness variance ---\n",
    "        # use brightness (mean over channels) as a simple measure\n",
    "        brightness = Current_Image.mean(axis=2)\n",
    "        brightness_var = np.var(brightness)\n",
    "\n",
    "        # show_images([Current_Image], [f\"Candidate Plate Edge Ratio: {edge_ratio:.4f} , Brightness Var: {brightness_var:.4f}\"])\n",
    "\n",
    "        # --- Combined score ---\n",
    "        # Edge density is still the main factor, color helps down-weight bad ones\n",
    "        score = brightness_var\n",
    "\n",
    "        if score > Best_Score:\n",
    "            Best_Score = score\n",
    "            Best_Candidate = (x, y, w, h)\n",
    "\n",
    "\n",
    "    # Crop the best candidate\n",
    "    x, y, w, h = Best_Candidate\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    # show_images([img], [\"Best Plate Candidate\"])\n",
    "    plate_img = Original_Img[y:y+h, x:x+w] \n",
    "    \n",
    "    return plate_img\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "# Testing the Plate Detection Function on Different Images\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Origignal_Img1 = io.imread(Path1)\n",
    "Detected_Plate1 = Plate_Detection(Path1)\n",
    "if Detected_Plate1 is not None:\n",
    "    show_images([Origignal_Img1, Detected_Plate1], [\"One Step No Headlights\", \"Plate Image\"])\n",
    "\n",
    "Origignal_Img2 = io.imread(Path2)\n",
    "Detected_Plate2 = Plate_Detection(Path2)\n",
    "if Detected_Plate2 is not None:\n",
    "    show_images([Origignal_Img2, Detected_Plate2], [\"Two Steps No Headlights\", \"Plate Image\"])\n",
    "\n",
    "Origignal_Img3 = io.imread(Path3)\n",
    "Detected_Plate3 = Plate_Detection(Path3)\n",
    "if Detected_Plate3 is not None:\n",
    "    show_images([Origignal_Img3, Detected_Plate3], [\"Three Steps No Headlights\", \"Plate Image\"])\n",
    "\n",
    "Origignal_Img4 = io.imread(Path4)\n",
    "Detected_Plate4 = Plate_Detection(Path4)\n",
    "if Detected_Plate4 is not None:\n",
    "    show_images([Origignal_Img4, Detected_Plate4], [\"One Step Headlights\", \"Plate Image\"])\n",
    "\n",
    "Origignal_Img5 = io.imread(Path5)\n",
    "Detected_Plate5 = Plate_Detection(Path5)\n",
    "if Detected_Plate5 is not None:\n",
    "    show_images([Origignal_Img5, Detected_Plate5], [\"Two Steps Headlights\", \"Plate Image\"])\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Origignal_Img11 = io.imread(Path11)\n",
    "Detected_Plate11 = Plate_Detection(Path11)\n",
    "if Detected_Plate11 is not None:\n",
    "    show_images([Origignal_Img11, Detected_Plate11], [\"One Step Elevated No Headlights\", \"Plate Image\"]) \n",
    "\n",
    "Origignal_Img12 = io.imread(Path12)\n",
    "Detected_Plate12 = Plate_Detection(Path12)\n",
    "if Detected_Plate12 is not None:\n",
    "    show_images([Origignal_Img12, Detected_Plate12], [\"Two Step Elevated No Headlights\", \"Plate Image\"])\n",
    "\n",
    "Origignal_Img13 = io.imread(Path13)\n",
    "Detected_Plate13 = Plate_Detection(Path13)\n",
    "if Detected_Plate13 is not None:\n",
    "    show_images([Origignal_Img13, Detected_Plate13], [\"Three Step Elevated No Headlights\", \"Plate Image\"])\n",
    "\n",
    "Origignal_Img14 = io.imread(Path14)\n",
    "Detected_Plate14 = Plate_Detection(Path14) \n",
    "if Detected_Plate14 is not None:\n",
    "    show_images([Origignal_Img14, Detected_Plate14], [\"One Step Elevated Headlights\", \"Plate Image\"])\n",
    "\n",
    "Origignal_Img15 = io.imread(Path15)\n",
    "Detected_Plate15 = Plate_Detection(Path15)  \n",
    "if Detected_Plate15 is not None:\n",
    "    show_images([Origignal_Img15, Detected_Plate15], [\"Two Step Elevated Headlights\", \"Plate Image\"])\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Origignal_Img111 = io.imread(Path111)\n",
    "Detected_Plate111 = Plate_Detection(Path111)\n",
    "if Detected_Plate111 is not None:\n",
    "    show_images([Origignal_Img111, Detected_Plate111], [\"One Step Slight Right No Headlights\", \"Plate Image\"])\n",
    "\n",
    "Origignal_Img112 = io.imread(Path112)\n",
    "Detected_Plate112 = Plate_Detection(Path112)\n",
    "if Detected_Plate112 is not None:\n",
    "    show_images([Origignal_Img112, Detected_Plate112], [\"Two Step Slight Right No Headlights\", \"Plate Image\"])\n",
    "\n",
    "Origignal_Img113 = io.imread(Path113)\n",
    "Detected_Plate113 = Plate_Detection(Path113)\n",
    "if Detected_Plate113 is not None:\n",
    "    show_images([Origignal_Img113, Detected_Plate113], [\"Three Step Slight Right No Headlights\", \"Plate Image\"])\n",
    "\n",
    "Origignal_Img114 = io.imread(Path114)\n",
    "Detected_Plate114 = Plate_Detection(Path114)\n",
    "if Detected_Plate114 is not None:\n",
    "    show_images([Origignal_Img114, Detected_Plate114], [\"One Step Slight Right Headlights\", \"Plate Image\"])\n",
    "\n",
    "Origignal_Img115 = io.imread(Path115)\n",
    "Detected_Plate115 = Plate_Detection(Path115)\n",
    "if Detected_Plate115 is not None:\n",
    "    show_images([Origignal_Img115, Detected_Plate115], [\"Two Step Slight Right Headlights\", \"Plate Image\"])\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Origignal_Img1111 = io.imread(Path1111)\n",
    "Detected_Plate1111 = Plate_Detection(Path1111)\n",
    "if Detected_Plate1111 is not None:\n",
    "    show_images([Origignal_Img1111, Detected_Plate1111], [\"One Step Slight Left No Headlights\", \"Plate Image\"])\n",
    "\n",
    "Origignal_Img1112 = io.imread(Path1112)\n",
    "Detected_Plate1112 = Plate_Detection(Path1112)\n",
    "if Detected_Plate1112 is not None:\n",
    "    show_images([Origignal_Img1112, Detected_Plate1112], [\"Two Step Slight Left No Headlights\", \"Plate Image\"])\n",
    "\n",
    "Origignal_Img1113 = io.imread(Path1113)\n",
    "Detected_Plate1113 = Plate_Detection(Path1113)\n",
    "if Detected_Plate1113 is not None:\n",
    "    show_images([Origignal_Img1113, Detected_Plate1113], [\"Three Step Slight Left No Headlights\", \"Plate Image\"])\n",
    "\n",
    "Origignal_Img1114 = io.imread(Path1114)\n",
    "Detected_Plate1114 = Plate_Detection(Path1114)\n",
    "if Detected_Plate1114 is not None:\n",
    "    show_images([Origignal_Img1114, Detected_Plate1114], [\"One Step Slight Left Headlights\", \"Plate Image\"])\n",
    "\n",
    "Origignal_Img1115 = io.imread(Path1115)\n",
    "Detected_Plate1115 = Plate_Detection(Path1115)\n",
    "if Detected_Plate1115 is not None:\n",
    "    show_images([Origignal_Img1115, Detected_Plate1115], [\"Two Step Slight Left Headlights\", \"Plate Image\"])\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Original_Img11111 = io.imread(Path11111)\n",
    "Detected_Plate11111 = Plate_Detection(Path11111)\n",
    "if Detected_Plate11111 is not None:\n",
    "    show_images([Original_Img11111, Detected_Plate11111], [\"One Step Extreme Left No Headlights\", \"Plate Image\"])\n",
    "\n",
    "Original_Img11112 = io.imread(Path11112)\n",
    "Detected_Plate11112 = Plate_Detection(Path11112)\n",
    "if Detected_Plate11112 is not None:\n",
    "    show_images([Original_Img11112, Detected_Plate11112], [\"One Step Extreme Right No Headlights\", \"Plate Image\"])\n",
    "\n",
    "Original_Img11113 = io.imread(Path11113)\n",
    "Detected_Plate11113 = Plate_Detection(Path11113)\n",
    "if Detected_Plate11113 is not None:\n",
    "    show_images([Original_Img11113, Detected_Plate11113], [\"Two Step Extreme Left No Headlights\", \"Plate Image\"])\n",
    "\n",
    "Original_Img11114 = io.imread(Path11114)\n",
    "Detected_Plate11114 = Plate_Detection(Path11114)\n",
    "if Detected_Plate11114 is not None:\n",
    "    show_images([Original_Img11114, Detected_Plate11114], [\"Two Step Extreme Right No Headlights\", \"Plate Image\"])\n",
    "\n",
    "Original_Img11115 = io.imread(Path11115)\n",
    "Detected_Plate11115 = Plate_Detection(Path11115)\n",
    "if Detected_Plate11115 is not None:\n",
    "    show_images([Original_Img11115, Detected_Plate11115], [\"Three Step Extreme Left No Headlights\", \"Plate Image\"])\n",
    "\n",
    "Original_Img11116 = io.imread(Path11116)\n",
    "Detected_Plate11116 = Plate_Detection(Path11116)\n",
    "if Detected_Plate11116 is not None:\n",
    "    show_images([Original_Img11116, Detected_Plate11116], [\"Three Step Extreme Right No Headlights\", \"Plate Image\"])\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Original_Img11117 = io.imread('trella.png')[:,:,:3]\n",
    "Detected_Plate11117 = Plate_Detection('trella.png')\n",
    "if Detected_Plate11117 is not None:\n",
    "    show_images([Original_Img11117, Detected_Plate11117], [\"Trella\", \"Plate Image\"])\n",
    "\n",
    "# import os\n",
    "\n",
    "# BASE_PATH = \"Localization Test/Vehicles\"\n",
    "\n",
    "# START_ID = 1\n",
    "# END_ID   = 2087\n",
    "\n",
    "# for i in range(START_ID, END_ID + 1):\n",
    "#     fname = f\"{i:04d}.jpg\"        # 0001.jpg, 0002.jpg, ...\n",
    "#     fpath = os.path.join(BASE_PATH, fname)\n",
    "\n",
    "#     if not os.path.exists(fpath):\n",
    "#         print(f\"[SKIP] Missing: {fpath}\")\n",
    "#         continue\n",
    "\n",
    "#     try:\n",
    "#         img = io.imread(fpath)    # RGB (as you want)\n",
    "#         title = f\"Vehicle_{fname}\"\n",
    "#         print(f\"[RUN] {title}\")\n",
    "#         Detected_Plate11116=Plate_Detection(fpath)\n",
    "#         if Detected_Plate11116 is not None:\n",
    "#             show_images([img, Detected_Plate11116], [\"img\", \"detect\"])\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"[ERROR] {fname}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb3aebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ================================================================\n",
    "#  DEBUG VIEW\n",
    "# ================================================================\n",
    "def _show_mask_debug(mask, title):\n",
    "    plt.figure(figsize=(4, 2))\n",
    "    plt.imshow(mask, cmap=\"gray\")\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# ======================================================================\n",
    "#  HELPER: draw candidate rectangles on debug image\n",
    "# ======================================================================\n",
    "def draw_candidates_debug(img, candidates, best_idx):\n",
    "    debug_img = img.copy()\n",
    "\n",
    "    for i, c in enumerate(candidates):\n",
    "        color = (0,255,0) if i==best_idx else \\\n",
    "                (random.randint(50,255), random.randint(50,255), random.randint(50,255))\n",
    "\n",
    "        x0, y0, x1, y1 = c[\"x0\"], c[\"y0\"], c[\"x1\"], c[\"y1\"]\n",
    "        cv2.rectangle(debug_img, (x0,y0), (x1,y1), color, 2)\n",
    "        cv2.putText(debug_img, f\"{c['score']:.2f}\", (x0, y0-4),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "\n",
    "    return debug_img\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "#  TIERS\n",
    "# ================================================================\n",
    "BLUE_PARAMS_STRICT = dict(BLUE_SAT_THRESH=140, BLUE_VAL_THRESH=110, BLUE_HUE_MIN=80, BLUE_HUE_MAX=120, BLUE_DELTA=12)\n",
    "BLUE_PARAMS_MID    = dict(BLUE_SAT_THRESH=115, BLUE_VAL_THRESH=95,  BLUE_HUE_MIN=80, BLUE_HUE_MAX=120, BLUE_DELTA=14)\n",
    "BLUE_PARAMS_LENIENT= dict(BLUE_SAT_THRESH=60,  BLUE_VAL_THRESH=80,  BLUE_HUE_MIN=75, BLUE_HUE_MAX=125, BLUE_DELTA=18)\n",
    "BLUE_PARAMS_VERY_LENIENT = dict(BLUE_SAT_THRESH=30, BLUE_VAL_THRESH=60, BLUE_HUE_MIN=70, BLUE_HUE_MAX=135, BLUE_DELTA=22)\n",
    "\n",
    "BLUE_PARAMS_ULTRA_LENIENT = dict(\n",
    "    BLUE_SAT_THRESH=18,\n",
    "    BLUE_VAL_THRESH=45,\n",
    "    BLUE_HUE_MIN=65,\n",
    "    BLUE_HUE_MAX=145,\n",
    "    BLUE_DELTA=26\n",
    ")\n",
    "\n",
    "BLUE_PARAMS_MAX_LENIENT = dict(\n",
    "    BLUE_SAT_THRESH=8,\n",
    "    BLUE_VAL_THRESH=35,\n",
    "    BLUE_HUE_MIN=55,\n",
    "    BLUE_HUE_MAX=160,\n",
    "    BLUE_DELTA=32\n",
    ")\n",
    "\n",
    "BLUE_PARAMS_NUCLEAR = dict(\n",
    "    BLUE_SAT_THRESH = 3,\n",
    "    BLUE_VAL_THRESH = 25,\n",
    "    BLUE_HUE_MIN    = 45,\n",
    "    BLUE_HUE_MAX    = 170,\n",
    "    BLUE_DELTA      = 40\n",
    ")\n",
    "\n",
    "BLUE_PARAM_TIERS = [\n",
    "    (\"STRICT\",       BLUE_PARAMS_STRICT),\n",
    "    (\"MID\",          BLUE_PARAMS_MID),\n",
    "    (\"LENIENT\",      BLUE_PARAMS_LENIENT),\n",
    "    (\"VERY_LENIENT\", BLUE_PARAMS_VERY_LENIENT),\n",
    "    (\"ULTRA_LENIENT\", BLUE_PARAMS_ULTRA_LENIENT),\n",
    "    (\"MAX_LENIENT\",   BLUE_PARAMS_MAX_LENIENT),\n",
    "    (\"NUCLEAR\",       BLUE_PARAMS_NUCLEAR),\n",
    "]\n",
    "\n",
    "TIER_BONUS = {\n",
    "    \"STRICT\": 0.18,\n",
    "    \"MID\": 0.12,\n",
    "    \"LENIENT\": 0.06,\n",
    "    \"VERY_LENIENT\": 0.00,\n",
    "    \"ULTRA_LENIENT\": -0.06,\n",
    "    \"MAX_LENIENT\":   -0.10,\n",
    "    \"NUCLEAR\":       -0.10,\n",
    "}\n",
    "\n",
    "# ================================================================\n",
    "#  SCORING HYPERPARAMS\n",
    "# ================================================================\n",
    "HUE_CENTER = 100\n",
    "HUE_SIGMA  = 18.0\n",
    "\n",
    "WHITE_S_MAX = 90\n",
    "WHITE_V_MIN = 120\n",
    "\n",
    "W_CC_DOM   = 0.22\n",
    "W_ROW_BAND = 0.18\n",
    "W_BLUE     = 0.26\n",
    "W_SAT      = 0.10\n",
    "W_BELOW    = 0.18\n",
    "W_TOP_PRIOR= 0.06\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "def _adaptive_blue_mask_with_params(img_rgb, params, debug=False, tag=\"\"):\n",
    "    hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)\n",
    "    H, S, V = cv2.split(hsv)\n",
    "\n",
    "    sat_thr = params[\"BLUE_SAT_THRESH\"]\n",
    "    val_thr = params[\"BLUE_VAL_THRESH\"]\n",
    "    hue_min = params[\"BLUE_HUE_MIN\"]\n",
    "    hue_max = params[\"BLUE_HUE_MAX\"]\n",
    "    delta   = params[\"BLUE_DELTA\"]\n",
    "\n",
    "    colored = (S > sat_thr) & (V > val_thr)\n",
    "    H_colored = H[colored]\n",
    "\n",
    "    hue_mask = (H_colored >= hue_min) & (H_colored <= hue_max)\n",
    "    blue_hues = H_colored[hue_mask]\n",
    "\n",
    "    if blue_hues.size == 0:\n",
    "        if debug:\n",
    "            print(f\"[{tag}] No blue hues found in candidate window.\")\n",
    "        return np.zeros_like(H, dtype=np.uint8), None, None\n",
    "\n",
    "    hist, bin_edges = np.histogram(blue_hues, bins=36, range=(0, 180))\n",
    "    peak_bin = int(np.argmax(hist))\n",
    "    h_peak = 0.5 * (bin_edges[peak_bin] + bin_edges[peak_bin + 1])\n",
    "\n",
    "    h_low  = max(0,   int(h_peak - delta))\n",
    "    h_high = min(179, int(h_peak + delta))\n",
    "\n",
    "    lower_blue = np.array([h_low,  sat_thr, val_thr], dtype=np.uint8)\n",
    "    upper_blue = np.array([h_high, 255,     255],     dtype=np.uint8)\n",
    "\n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "\n",
    "    if debug:\n",
    "        n = int(mask.sum() // 255)\n",
    "        print(f\"[{tag}] Peak={h_peak:.1f}, H=({h_low},{h_high}), S>{sat_thr}, V>{val_thr}, pixels={n}\")\n",
    "\n",
    "    return mask, lower_blue, upper_blue\n",
    "\n",
    "\n",
    "def _hue_distance_circular(h, center):\n",
    "    d = np.abs(h.astype(np.float32) - float(center))\n",
    "    return np.minimum(d, 180.0 - d)\n",
    "\n",
    "\n",
    "def _score_component(mask, hsv, comp_mask, bbox, tier_name, debug=False):\n",
    "    Himg, Wimg = mask.shape[:2]\n",
    "    x, y, w, h = bbox\n",
    "    area = float(comp_mask.sum())\n",
    "    total = float((mask > 0).sum()) + 1e-6\n",
    "\n",
    "    cc_dom = area / total\n",
    "\n",
    "    y_center = y + 0.5*h\n",
    "    top_prior = 1.0 - np.clip(y_center / (0.65 * Himg + 1e-6), 0.0, 1.0)\n",
    "\n",
    "    sub = mask[y:y+h, x:x+w] > 0\n",
    "    if sub.size == 0:\n",
    "        return -1e9, {}\n",
    "    row_counts = sub.sum(axis=1).astype(np.float32)\n",
    "    if row_counts.max() <= 0:\n",
    "        row_band = 0.0\n",
    "    else:\n",
    "        peak = row_counts.max()\n",
    "        mean = row_counts.mean() + 1e-6\n",
    "        peakiness = float(peak / mean)\n",
    "        thr = 0.6 * peak\n",
    "        strong = row_counts >= thr\n",
    "        longest = 0\n",
    "        cur = 0\n",
    "        for v in strong:\n",
    "            if v:\n",
    "                cur += 1\n",
    "                longest = max(longest, cur)\n",
    "            else:\n",
    "                cur = 0\n",
    "        run_frac = float(longest / (h + 1e-6))\n",
    "        row_band = np.tanh((peakiness - 1.5) / 2.0) * 0.6 + run_frac * 0.4\n",
    "        row_band = float(np.clip(row_band, 0.0, 1.0))\n",
    "\n",
    "    Hc = hsv[...,0][comp_mask]\n",
    "    Sc = hsv[...,1][comp_mask]\n",
    "    if Hc.size == 0:\n",
    "        blue_score = 0.0\n",
    "        sat_score  = 0.0\n",
    "    else:\n",
    "        d = _hue_distance_circular(Hc, HUE_CENTER)\n",
    "        mean_d = float(d.mean())\n",
    "        blue_score = float(np.exp(- (mean_d**2) / (2.0 * (HUE_SIGMA**2))))\n",
    "        sat_score = float(np.clip(Sc.mean() / 255.0, 0.0, 1.0))\n",
    "\n",
    "    y0 = int(y + h)\n",
    "    y1 = int(min(Himg, y + h + 1.5*h))\n",
    "    if y1 <= y0 + 2:\n",
    "        below_white = 0.0\n",
    "    else:\n",
    "        below = hsv[y0:y1, x:x+w]\n",
    "        S_b = below[...,1].astype(np.uint8)\n",
    "        V_b = below[...,2].astype(np.uint8)\n",
    "        white = (S_b < WHITE_S_MAX) & (V_b > WHITE_V_MIN)\n",
    "        below_white = float(white.mean())\n",
    "\n",
    "    tier_bonus = TIER_BONUS.get(tier_name, 0.0)\n",
    "\n",
    "    score = (\n",
    "        W_CC_DOM    * cc_dom +\n",
    "        W_ROW_BAND  * row_band +\n",
    "        W_BLUE      * blue_score +\n",
    "        W_SAT       * sat_score +\n",
    "        W_BELOW     * below_white +\n",
    "        W_TOP_PRIOR * top_prior +\n",
    "        tier_bonus\n",
    "    )\n",
    "\n",
    "    if debug:\n",
    "        print(f\"    [{tier_name}] bbox={x,y,w,h} \"\n",
    "              f\"score={score:.3f} | cc={cc_dom:.2f} row={row_band:.2f} blue={blue_score:.2f} \"\n",
    "              f\"sat={sat_score:.2f} belowW={below_white:.2f} top={top_prior:.2f} +bonus={tier_bonus:.2f}\")\n",
    "\n",
    "    return float(score), dict(bbox=(x,y,w,h))\n",
    "\n",
    "\n",
    "def adaptive_blue_mask(img_rgb, debug=False):\n",
    "    # NOTE: keep everything minimal\n",
    "    Himg, Wimg = img_rgb.shape[:2]\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # NEW: probe STRICT + MID, and if both are \"near empty\", rescue\n",
    "    # ------------------------------------------------------------\n",
    "    RESCUE_WHITE_THR = 200  # you can tune this\n",
    "    did_rescue = False\n",
    "\n",
    "    # quick probe on ORIGINAL img\n",
    "    maskS, _, _ = _adaptive_blue_mask_with_params(img_rgb, BLUE_PARAMS_STRICT, debug=False, tag=\"PROBE_STRICT\")\n",
    "    maskM, _, _ = _adaptive_blue_mask_with_params(img_rgb, BLUE_PARAMS_MID,    debug=False, tag=\"PROBE_MID\")\n",
    "\n",
    "    nS = int(maskS.sum() // 255) if maskS is not None else 0\n",
    "    nM = int(maskM.sum() // 255) if maskM is not None else 0\n",
    "\n",
    "    img_work = img_rgb\n",
    "\n",
    "    if (nS < RESCUE_WHITE_THR) and (nM < RESCUE_WHITE_THR):\n",
    "        did_rescue = True\n",
    "        if debug:\n",
    "            print(f\"[RESCUE TRIGGER] STRICT={nS} MID={nM} < {RESCUE_WHITE_THR} -> calling rescue_blue_strip_rgb_extreme()\")\n",
    "\n",
    "        img_rescued = rescue_blue_strip_rgb_extreme(img_rgb, debug=True)\n",
    "\n",
    "        if debug:\n",
    "            # show before/after so you see what happened\n",
    "            plt.figure(figsize=(10,4))\n",
    "            plt.subplot(1,2,1); plt.imshow(img_rgb);     plt.title(\"Original (before rescue)\"); plt.axis(\"off\")\n",
    "            plt.subplot(1,2,2); plt.imshow(img_rescued); plt.title(\"After rescue_blue_strip_rgb_extreme\"); plt.axis(\"off\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        # reset pipeline on rescued image\n",
    "        img_work = img_rescued\n",
    "\n",
    "    # now proceed normally, BUT using img_work (original or rescued)\n",
    "    hsv = cv2.cvtColor(img_work, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    best = dict(score=-1e9, mask=None, lb=None, ub=None, tier=None, bbox=None, did_rescue=did_rescue)\n",
    "\n",
    "    for tier_name, params in BLUE_PARAM_TIERS:\n",
    "        mask, lb, ub = _adaptive_blue_mask_with_params(img_work, params, debug=debug, tag=tier_name)\n",
    "\n",
    "        # keep your dilation exactly as-is\n",
    "        mask = cv2.dilate(mask, cv2.getStructuringElement(cv2.MORPH_RECT, (9, 3)), iterations=1)\n",
    "\n",
    "        if debug:\n",
    "            _show_mask_debug(mask, f\"{tier_name} mask (raw+dilated)\")\n",
    "\n",
    "        if lb is None or mask.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        bin_mask = (mask > 0).astype(np.uint8)\n",
    "        num, labels, stats, centroids = cv2.connectedComponentsWithStats(bin_mask, connectivity=8)\n",
    "\n",
    "        for comp_id in range(1, num):\n",
    "            x, y, w, h, area = stats[comp_id]\n",
    "            if area < 20:\n",
    "                continue\n",
    "\n",
    "            comp_mask = (labels == comp_id)\n",
    "            score, details = _score_component(mask, hsv, comp_mask, (x,y,w,h), tier_name, debug=debug)\n",
    "\n",
    "            if score > best[\"score\"]:\n",
    "                best.update(score=score, mask=mask, lb=lb, ub=ub, tier=tier_name, bbox=(x,y,w,h))\n",
    "\n",
    "    if best[\"mask\"] is None:\n",
    "        return np.zeros((Himg, Wimg), dtype=np.uint8), None, None, None, None\n",
    "\n",
    "    if debug:\n",
    "        x,y,w,h = best[\"bbox\"]\n",
    "        print(f\"\\n✅ CHOSEN OVERALL: tier={best['tier']} score={best['score']:.3f} bbox={(x,y,w,h)} rescue_used={did_rescue}\\n\")\n",
    "\n",
    "    return best[\"mask\"], best[\"lb\"], best[\"ub\"], best[\"tier\"], best[\"bbox\"]\n",
    "\n",
    "\n",
    "#/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "def crop_left_right_by_blue_adaptive(img_bgr, debug=False):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "\n",
    "    mask, lb, ub, tier, bbox = adaptive_blue_mask(img_bgr, debug)\n",
    "\n",
    "    if debug:\n",
    "        print(\"✅ Tier used:\", tier)\n",
    "\n",
    "    if lb is None:\n",
    "        if debug:\n",
    "            print(\"❌ No blue detected\")\n",
    "        return None, None, mask, None\n",
    "\n",
    "    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    row_counts = mask.sum(axis=1)//255\n",
    "    max_row = row_counts.max()\n",
    "    if max_row == 0:\n",
    "        return None, None, mask, None\n",
    "\n",
    "    row_thresh = 0.30*max_row\n",
    "    blue_rows = row_counts > row_thresh\n",
    "\n",
    "    bands = []\n",
    "    cur_start = None\n",
    "    for y, flag in enumerate(blue_rows):\n",
    "        if flag and cur_start is None:\n",
    "            cur_start = y\n",
    "        elif not flag and cur_start is not None:\n",
    "            bands.append((cur_start, y))\n",
    "            cur_start = None\n",
    "    if cur_start is not None:\n",
    "        bands.append((cur_start, len(blue_rows)))\n",
    "\n",
    "    # =====================================================\n",
    "    # ✅ NEW: two-pass gating thresholds (only used for filtering)\n",
    "    # =====================================================\n",
    "    PASS1_MIN_BAND_H_FRAC = 0.02   # your current value\n",
    "    PASS1_MIN_BAND_W_FRAC = 0.10   # your current value\n",
    "\n",
    "    PASS2_MIN_BAND_H_FRAC = 0.008  # lenient fallback (far plates)\n",
    "    PASS2_MIN_BAND_W_FRAC = 0.05   # lenient fallback (far plates)\n",
    "\n",
    "    # =====================================================\n",
    "    # ✅ NEW: minimal helper to keep your code unchanged\n",
    "    # =====================================================\n",
    "    def _collect_candidates(min_band_h_frac, min_band_w_frac):\n",
    "        candidates = []\n",
    "\n",
    "        for (y0_band, y1_band) in bands:\n",
    "            band_h = y1_band - y0_band\n",
    "            if band_h < min_band_h_frac * H:\n",
    "                continue\n",
    "\n",
    "            submask = mask[y0_band:y1_band, :]\n",
    "\n",
    "            ys2, xs2 = np.where(submask > 0)\n",
    "            if xs2.size == 0:\n",
    "                continue\n",
    "\n",
    "            # take robust span (ignore tiny outliers)\n",
    "            x0_band = int(np.percentile(xs2, 1))\n",
    "            x1_band = int(np.percentile(xs2, 99))\n",
    "            band_w  = x1_band - x0_band\n",
    "\n",
    "            # sanity on width relative to whole image\n",
    "            if band_w < min_band_w_frac * W or band_w > 0.95 * W:\n",
    "                continue\n",
    "\n",
    "            # ---- 1) aspect ratio of blue band (smooth) ----\n",
    "            ar_band = band_w / (band_h + 1e-6)\n",
    "            s_ar_band = np.tanh((ar_band - 2.0) / 2.0)\n",
    "            s_ar_band = float(np.clip(s_ar_band, 0.0, 1.0))\n",
    "\n",
    "            region_hsv = hsv[:, x0_band:x1_band]\n",
    "            _, Sc, Vc = cv2.split(region_hsv)\n",
    "\n",
    "            S_MAX = 130\n",
    "            V_MIN = 80\n",
    "            white_mask = (Sc < S_MAX) & (Vc > V_MIN)\n",
    "            white_ratio = float(white_mask.mean())\n",
    "\n",
    "            s_white = white_ratio\n",
    "\n",
    "            k = 3.0\n",
    "            y0_pl = max(0,   int(y0_band - 0.2*band_h))\n",
    "            y1_pl = min(H-1, int(y0_band + k*band_h))\n",
    "            plate_h = y1_pl - y0_pl\n",
    "            ar_plate = band_w / (plate_h + 1e-6)\n",
    "\n",
    "            expected_ar = 2.0\n",
    "            sigma = 0.8\n",
    "            s_ar_plate = float(np.exp(-((ar_plate - expected_ar)**2) / (2 * sigma**2)))\n",
    "\n",
    "            score = (\n",
    "                0.20*s_ar_band +\n",
    "                0.50*s_white   +\n",
    "                0.30*s_ar_plate\n",
    "            )\n",
    "\n",
    "            candidates.append({\n",
    "                \"x0\": x0_band, \"y0\": y0_band,\n",
    "                \"x1\": x1_band, \"y1\": y1_band,\n",
    "                \"width\": band_w,\n",
    "                \"height\": band_h,\n",
    "                \"score\": float(score),\n",
    "                \"white_ratio\": white_ratio,\n",
    "                \"s_white\": s_white,\n",
    "                \"s_ar_band\": s_ar_band,\n",
    "                \"s_ar_plate\": s_ar_plate\n",
    "            })\n",
    "\n",
    "        return candidates\n",
    "\n",
    "    # =====================================================\n",
    "    # ✅ NEW: Pass 1 (original strict gates)\n",
    "    # =====================================================\n",
    "    candidates = _collect_candidates(PASS1_MIN_BAND_H_FRAC, PASS1_MIN_BAND_W_FRAC)\n",
    "\n",
    "    # =====================================================\n",
    "    # ✅ NEW: Pass 2 ONLY if Pass 1 found nothing\n",
    "    # =====================================================\n",
    "    if not candidates:\n",
    "        candidates = _collect_candidates(PASS2_MIN_BAND_H_FRAC, PASS2_MIN_BAND_W_FRAC)\n",
    "        if debug and candidates:\n",
    "            print(\"[2-PASS] Pass1 empty -> using lenient gates for far/small plate case\")\n",
    "\n",
    "    if not candidates:\n",
    "        return img_bgr, (0,0,W-1,H-1), mask, img_bgr\n",
    "\n",
    "    candidates_sorted = sorted(\n",
    "        candidates,\n",
    "        key=lambda c: (c[\"score\"], c[\"white_ratio\"], c[\"width\"], c[\"height\"]),\n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    best = candidates_sorted[0]\n",
    "    best_idx = candidates.index(best)\n",
    "\n",
    "    margin = int(0.02*W)\n",
    "    x0 = max(0, best[\"x0\"] - margin)\n",
    "    x1 = min(W-1, best[\"x1\"] + margin)\n",
    "\n",
    "    y_strip_top = int(best[\"y0\"])\n",
    "    strip_h     = int(best[\"height\"])\n",
    "\n",
    "    plate_h = int(3.5 * strip_h)\n",
    "\n",
    "    y_top = max(0, y_strip_top)\n",
    "\n",
    "    y_bottom = y_top + plate_h + int(0.10 * strip_h)\n",
    "    y_bottom = min(H - 1, y_bottom)\n",
    "\n",
    "    cropped = img_bgr[y_top:y_bottom+1, x0:x1]\n",
    "\n",
    "    debug_img = draw_candidates_debug(img_bgr, candidates, best_idx)\n",
    "\n",
    "    if debug:\n",
    "        print(\"\\n========= CANDIDATE BREAKDOWN =========\")\n",
    "        for i, c in enumerate(candidates):\n",
    "            print(f\"[{i}] score={c['score']:.3f}, \"\n",
    "                  f\"white_ratio={c['white_ratio']:.3f}, \"\n",
    "                  f\"s_white={c['s_white']:.2f}, \"\n",
    "                  f\"ARband={c['s_ar_band']:.2f}, \"\n",
    "                  f\"ARplate={c['s_ar_plate']:.2f}, \"\n",
    "                  f\"range=({c['x0']},{c['x1']}) \"\n",
    "                  f\"vertical=({c['y0']},{c['y1']})\")\n",
    "        print(\"Chosen:\", best)\n",
    "        print(\"========================================\\n\")\n",
    "\n",
    "    return cropped, (best[\"x0\"], best[\"y0\"], best[\"x1\"], best[\"y1\"]), mask, debug_img\n",
    "\n",
    "\n",
    "\n",
    "def debug_blue_crop(plate_img, title):\n",
    "    if plate_img is None:\n",
    "        print(f\"{title}: plate_img is None, skipping.\")\n",
    "        return None\n",
    "\n",
    "    cropped, bbox, mask, debug_img = crop_left_right_by_blue_adaptive(plate_img, debug=False)\n",
    "\n",
    "    images = [plate_img]\n",
    "    titles = [f\"{title} - Original\"]\n",
    "\n",
    "    if mask is not None:\n",
    "        images.append(mask)\n",
    "        titles.append(\"Blue mask\")\n",
    "\n",
    "    if debug_img is not None:\n",
    "        images.append(debug_img)\n",
    "        titles.append(\"All candidates\")\n",
    "    else:\n",
    "        print(f\"{title}: debug_img is None (likely no candidates / no blue).\")\n",
    "\n",
    "    if cropped is not None:\n",
    "        images.append(cropped)\n",
    "        titles.append(\"Final crop\")\n",
    "    else:\n",
    "        print(f\"{title}: cropped is None (no blue detected).\")\n",
    "\n",
    "    show_images(images, titles)\n",
    "    return cropped\n",
    "\n",
    "def _rotate_keep_all_rgb(img_rgb, angle_deg):\n",
    "    H, W = img_rgb.shape[:2]\n",
    "    center = (W * 0.5, H * 0.5)\n",
    "    M = cv2.getRotationMatrix2D(center, angle_deg, 1.0)\n",
    "\n",
    "    cos = abs(M[0, 0])\n",
    "    sin = abs(M[0, 1])\n",
    "    newW = int(H * sin + W * cos)\n",
    "    newH = int(H * cos + W * sin)\n",
    "\n",
    "    M[0, 2] += (newW / 2) - center[0]\n",
    "    M[1, 2] += (newH / 2) - center[1]\n",
    "\n",
    "    rot = cv2.warpAffine(\n",
    "        img_rgb, M, (newW, newH),\n",
    "        flags=cv2.INTER_LINEAR,\n",
    "        borderMode=cv2.BORDER_REPLICATE\n",
    "    )\n",
    "    return rot\n",
    "\n",
    "\n",
    "def rescue_blue_strip_rgb_extreme(img_rgb, debug=False):\n",
    "\n",
    "    \"\"\"\n",
    "    MUCH harsher rescue:\n",
    "      - normalize + CLAHE + stronger gamma on V\n",
    "      - build a better seed (prefers blue-ish + horizontal band)\n",
    "      - inside seed: PUSH S/V strongly toward target (S~100, V~90+)\n",
    "      - optional stronger hue pull toward blue center\n",
    "    \"\"\"\n",
    "\n",
    "    hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV).astype(np.float32)\n",
    "    H = hsv[..., 0]\n",
    "    S = hsv[..., 1]\n",
    "    V = hsv[..., 2]\n",
    "\n",
    "    # -----------------------------\n",
    "    # (1) Robust normalize V (stronger)\n",
    "    # -----------------------------\n",
    "    v1 = np.percentile(V, 1)\n",
    "    v2 = np.percentile(V, 99)\n",
    "    if v2 > v1 + 1e-3:\n",
    "        Vn = (V - v1) * (255.0 / (v2 - v1))\n",
    "        Vn = np.clip(Vn, 0, 255)\n",
    "    else:\n",
    "        Vn = V.copy()\n",
    "\n",
    "    # -----------------------------\n",
    "    # (2) CLAHE on V (stronger)\n",
    "    # -----------------------------\n",
    "    V8 = Vn.astype(np.uint8)\n",
    "    clahe = cv2.createCLAHE(clipLimit=6.0, tileGridSize=(5, 5))\n",
    "    Vc = clahe.apply(V8).astype(np.float32)\n",
    "\n",
    "    # -----------------------------\n",
    "    # (3) Gamma brighten (more aggressive)\n",
    "    # gamma < 1 brightens shadows a lot\n",
    "    # -----------------------------\n",
    "    gamma = 0.3   # was 0.65, now harsher\n",
    "    Vg = 255.0 * np.power(np.clip(Vc / 255.0, 0, 1), gamma)\n",
    "\n",
    "    # slight extra lift to midtones\n",
    "    Vg = np.clip(Vg + 10.0, 0, 255)\n",
    "\n",
    "    hsv2 = hsv.copy()\n",
    "    hsv2[..., 2] = Vg\n",
    "\n",
    "    # -----------------------------\n",
    "    # (4) Build a better seed:\n",
    "    #     - still lenient hue window\n",
    "    #     - require *some* saturation after V rescue\n",
    "    #     - favor horizontal structures (blue strip is a long band)\n",
    "    # -----------------------------\n",
    "    hsv2_u8 = hsv2.astype(np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "    lower_seed = np.array([70,  0,  0], dtype=np.uint8)\n",
    "    upper_seed = np.array([135, 255, 255], dtype=np.uint8)\n",
    "    seed0 = cv2.inRange(hsv2_u8, lower_seed, upper_seed)\n",
    "\n",
    "\n",
    "\n",
    "    # lower_seed = np.array([45,  0,  10], dtype=np.uint8)\n",
    "    # upper_seed = np.array([170, 255, 255], dtype=np.uint8)\n",
    "    # seed0 = cv2.inRange(hsv2_u8, lower_seed, upper_seed)\n",
    "\n",
    "    # enforce \"not totally gray\" AFTER brightening\n",
    "    # (this rejects lots of glare/white that becomes bright)\n",
    "    S_min_after = 15\n",
    "    seed0 = seed0 & ((hsv2_u8[...,1] >= S_min_after).astype(np.uint8) * 255)\n",
    "\n",
    "    # cleanup\n",
    "    seed0 = cv2.medianBlur(seed0, 5)\n",
    "\n",
    "    # horizontal emphasis: open with long horizontal kernel\n",
    "    seed1 = cv2.morphologyEx(\n",
    "        seed0, cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (15, 3)),\n",
    "        iterations=1\n",
    "    )\n",
    "\n",
    "    # connect horizontally\n",
    "    seed1 = cv2.morphologyEx(\n",
    "        seed1, cv2.MORPH_CLOSE,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (25, 5)),\n",
    "        iterations=1\n",
    "    )\n",
    "\n",
    "    seed01 = (seed1 > 0)\n",
    "\n",
    "    # -----------------------------\n",
    "    # (5) EXTREME push of S/V inside seed\n",
    "    # target-ish: S ~ 95-100, V ~ 80-100\n",
    "    # -----------------------------\n",
    "    S2 = S.copy()\n",
    "    V2 = Vg.copy()\n",
    "\n",
    "    # Push S upward HARD:\n",
    "    #   - If S is tiny, multiplication does nothing, so we also ADD a lot\n",
    "    S2[seed01] = np.clip(S2[seed01] * 2.8 + 80, 0, 255)\n",
    "\n",
    "    # Push V upward HARD (but still capped):\n",
    "    V2[seed01] = np.clip(V2[seed01] * 1.35 + 35, 0, 255)\n",
    "\n",
    "    # Optional: clamp seed area to minimum \"good\" S/V\n",
    "    # (forces your desired style)\n",
    "    S2[seed01] = np.maximum(S2[seed01], 255)   # ~90% of 255\n",
    "    V2[seed01] = np.maximum(V2[seed01], 230)   # ~75% of 255\n",
    "\n",
    "    # -----------------------------\n",
    "    # (6) Stronger hue pull toward blue center\n",
    "    # -----------------------------\n",
    "    H2 = H.copy()\n",
    "    blue_center = 100.0\n",
    "    pull = 0.55   # was 0.25, now harsher\n",
    "\n",
    "    good = seed01  # since we already enforced S_min_after\n",
    "    H2[good] = (1 - pull) * H2[good] + pull * blue_center\n",
    "    H2 = np.clip(H2, 0, 179)\n",
    "\n",
    "    hsv_out = np.stack([H2, S2, V2], axis=-1).astype(np.uint8)\n",
    "    out_rgb = cv2.cvtColor(hsv_out, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "    if debug:\n",
    "        nseed = int(seed01.sum())\n",
    "        print(f\"[RESCUE EXTREME] seed_pixels={nseed} gamma={gamma} clahe=4.0 pull={pull}\")\n",
    "\n",
    "    return out_rgb\n",
    "\n",
    "\n",
    "# def crop_bottom_by_horizontal_edge(plate_rgb, debug=True):\n",
    "#     \"\"\"\n",
    "#     plate_rgb: your already localized plate crop (RGB)\n",
    "#     returns: cropped_rgb, y_cut (row index in original plate_rgb)\n",
    "#     \"\"\"\n",
    "#     gray = cv2.cvtColor(plate_rgb, cv2.COLOR_RGB2GRAY)\n",
    "#     gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "\n",
    "#     # vertical gradient -> strong where horizontal edges exist\n",
    "#     dy = cv2.Sobel(gray, cv2.CV_32F, 0, 1, ksize=3)\n",
    "#     mag = np.abs(dy)\n",
    "\n",
    "#     # edge energy per row\n",
    "#     row_energy = mag.mean(axis=1)\n",
    "\n",
    "#     # smooth to avoid choosing a noisy row\n",
    "#     row_energy_s = cv2.GaussianBlur(row_energy.reshape(-1,1), (1, 31), 0).ravel()\n",
    "\n",
    "#     H = gray.shape[0]\n",
    "#     # search only in bottom half (tune 0.45..0.65)\n",
    "#     y0 = int(0.45 * H)\n",
    "#     y1 = int(0.98 * H)\n",
    "\n",
    "#     y_cut = y0 + int(np.argmax(row_energy_s[y0:y1]))\n",
    "\n",
    "#     # safety: keep at least some bottom margin (don’t cut too high)\n",
    "#     y_cut = int(np.clip(y_cut, int(0.55*H), H-1))\n",
    "\n",
    "#     out = plate_rgb[:y_cut, :, :]\n",
    "\n",
    "#     if debug:\n",
    "#         vis = plate_rgb.copy()\n",
    "#         cv2.line(vis, (0, y_cut), (vis.shape[1]-1, y_cut), (255,0,0), 2)\n",
    "\n",
    "#         plt.figure(figsize=(12,4))\n",
    "#         plt.subplot(1,3,1); plt.imshow(plate_rgb); plt.title(\"Input plate crop\"); plt.axis(\"off\")\n",
    "#         plt.subplot(1,3,2); plt.imshow(vis); plt.title(f\"Chosen bottom cut y={y_cut}\"); plt.axis(\"off\")\n",
    "#         plt.subplot(1,3,3); plt.plot(row_energy_s); plt.axvline(y_cut, linestyle=\"--\"); plt.title(\"Row edge-energy\"); plt.xlim(0,H-1)\n",
    "#         plt.tight_layout(); plt.show()\n",
    "\n",
    "#     return out, y_cut\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "New_Origignal_Img1111 = io.imread(\"Localization Test/NewTestCases/white car harsh right angle.jpg\")\n",
    "New_Origigna2_Img1111 = io.imread(\"Localization Test/NewTestCases/white car harshest angle.jpg\")\n",
    "New_Origigna3_Img1111 = io.imread(\"Localization Test/NewTestCases/white car slight angle .jpg\")\n",
    "New_Origigna4_Img1111 = io.imread(\"Localization Test/NewTestCases/white car straight.jpg\")\n",
    "New_Origigna5_Img1111 = io.imread(\"Localization Test/NewTestCases/white car very elevated angle.jpg\")\n",
    "New_Origigna6_Img1111 = io.imread(\"Localization Test/NewTestCases/white car very harsh left angle with alot of noise.jpg\")\n",
    "\n",
    "New_Origigna7_Img1111 = io.imread(\"Localization Test/NewTestCases/angle no bright.jpeg\")\n",
    "New_Origigna8_Img1111 = io.imread(\"Localization Test/NewTestCases/blury gedan.jpeg\")\n",
    "New_Origigna9_Img1111 = io.imread(\"Localization Test/NewTestCases/bright with angle.jpeg\")\n",
    "# New_Origigna10_Img1111 = io.imread(\"Localization Test/NewTestCases/kind of normal.jpeg\")\n",
    "# New_Origigna11_Img1111 = io.imread(\"Localization Test/NewTestCases/very dark dim.jpeg\")\n",
    "New_Origigna12_Img1111 = io.imread(\"Localization Test/NewTestCases/very dirty and noisy.jpeg\")\n",
    "New_Origigna13_Img1111 = io.imread(\"Localization Test/NewTestCases/very light bright.jpeg\")\n",
    "New_Origigna14_Img1111 = io.imread(\"Localization Test/NewTestCases/veryyyy far.jpeg\")\n",
    "\n",
    "\n",
    "\n",
    "cropped_Plate1=debug_blue_crop(New_Origignal_Img1111,\"Detected_New_Origignal_Img1111\")    \n",
    "cropped_Plate1=debug_blue_crop(cropped_Plate1,\"Detected_New_Origignal_Img1111\") \n",
    "cropped_Plate2=debug_blue_crop(New_Origigna2_Img1111,\"Detected_New_Origigna2_Img1111\")    \n",
    "cropped_Plate2=debug_blue_crop(cropped_Plate2,\"Detected_New_Origigna2_Img1111\")  \n",
    "cropped_Plate3=debug_blue_crop(New_Origigna3_Img1111,\"Detected_New_Origigna3_Img1111\")    \n",
    "cropped_Plate3=debug_blue_crop(cropped_Plate3,\"Detected_New_Origigna3_Img1111\")    \n",
    "cropped_Plate4=debug_blue_crop(New_Origigna4_Img1111,\"Detected_New_Origigna4_Img1111\")    \n",
    "cropped_Plate4=debug_blue_crop(cropped_Plate4,\"Detected_New_Origigna4_Img1111\") \n",
    "cropped_Plate5=debug_blue_crop(New_Origigna5_Img1111,\"Detected_New_Origigna5_Img1111\")    \n",
    "cropped_Plate5=debug_blue_crop(cropped_Plate5,\"Detected_New_Origigna5_Img1111\")     \n",
    "cropped_Plate6=debug_blue_crop(New_Origigna6_Img1111,\"Detected_New_Origigna6_Img1111\")\n",
    "#cropped_Plate6=debug_blue_crop(cropped_Plate6,\"Detected_New_Origigna6_Img1111\")  \n",
    "\n",
    "cropped_Plate7=debug_blue_crop(Origignal_Img1,\"Detected_New_Origignal_Img1111\")    \n",
    "cropped_Plate7=debug_blue_crop(cropped_Plate7,\"Detected_New_Origignal_Img1111\")    \n",
    "cropped_Plate8=debug_blue_crop(Origignal_Img2,\"Detected_New_Origigna2_Img1111\")    \n",
    "cropped_Plate8=debug_blue_crop(cropped_Plate8,\"Detected_New_Origigna2_Img1111\")    \n",
    "cropped_Plate9=debug_blue_crop(Origignal_Img3,\"Detected_New_Origigna3_Img1111\")    \n",
    "cropped_Plate9=debug_blue_crop(cropped_Plate9,\"Detected_New_Origigna3_Img1111\")     \n",
    "cropped_Plate10=debug_blue_crop(Origignal_Img4,\"Detected_New_Origigna4_Img1111\")    \n",
    "cropped_Plate10=debug_blue_crop(cropped_Plate10,\"Detected_New_Origigna4_Img1111\")      \n",
    "cropped_Plate11=debug_blue_crop(Origignal_Img5,\"Detected_New_Origigna5_Img1111\")\n",
    "cropped_Plate11=debug_blue_crop(cropped_Plate11,\"Detected_New_Origigna5_Img1111\")\n",
    "\n",
    "\n",
    "cropped_Plate12=debug_blue_crop(Origignal_Img11,\"Detected_New_Origigna6_Img1111\") \n",
    "cropped_Plate12=debug_blue_crop(cropped_Plate12,\"Detected_New_Origigna6_Img1111\")  \n",
    "cropped_Plate13=debug_blue_crop(Origignal_Img12,\"Detected_New_Origignal_Img1111\")    \n",
    "cropped_Plate13=debug_blue_crop(cropped_Plate13,\"Detected_New_Origignal_Img1111\")    \n",
    "cropped_Plate14=debug_blue_crop(Origignal_Img13,\"Detected_New_Origigna2_Img1111\")    \n",
    "cropped_Plate14=debug_blue_crop(cropped_Plate14,\"Detected_New_Origigna2_Img1111\")      \n",
    "cropped_Plate15=debug_blue_crop(Origignal_Img14,\"Detected_New_Origigna3_Img1111\")    \n",
    "cropped_Plate15=debug_blue_crop(cropped_Plate15,\"Detected_New_Origigna3_Img1111\")    \n",
    "cropped_Plate16=debug_blue_crop(Origignal_Img15,\"Detected_New_Origigna4_Img1111\")\n",
    "cropped_Plate16=debug_blue_crop(cropped_Plate16,\"Detected_New_Origigna4_Img1111\")\n",
    "\n",
    "cropped_Plate17=debug_blue_crop(Origignal_Img111,\"Detected_New_Origigna5_Img1111\")    \n",
    "cropped_Plate17=debug_blue_crop(cropped_Plate17,\"Detected_New_Origigna5_Img1111\")     \n",
    "cropped_Plate18=debug_blue_crop(Origignal_Img112,\"Detected_New_Origigna6_Img1111\") \n",
    "cropped_Plate18=debug_blue_crop(cropped_Plate18,\"Detected_New_Origigna6_Img1111\") \n",
    "cropped_Plate19=debug_blue_crop(Origignal_Img113,\"Detected_New_Origignal_Img1111\")    \n",
    "cropped_Plate19=debug_blue_crop(cropped_Plate19,\"Detected_New_Origignal_Img1111\")    \n",
    "cropped_Plate20=debug_blue_crop(Origignal_Img114,\"Detected_New_Origigna2_Img1111\")    \n",
    "cropped_Plate20=debug_blue_crop(cropped_Plate20,\"Detected_New_Origigna2_Img1111\")     \n",
    "cropped_Plate21=debug_blue_crop(Origignal_Img115,\"Detected_New_Origigna3_Img1111\")\n",
    "cropped_Plate21=debug_blue_crop(cropped_Plate21,\"Detected_New_Origigna3_Img1111\") \n",
    "\n",
    "cropped_Plate22=debug_blue_crop(Origignal_Img1111,\"Detected_New_Origigna4_Img1111\")    \n",
    "cropped_Plate22=debug_blue_crop(cropped_Plate22,\"Detected_New_Origigna4_Img1111\")   \n",
    "cropped_Plate23=debug_blue_crop(Origignal_Img1112,\"Detected_New_Origigna5_Img1111\")    \n",
    "cropped_Plate23=debug_blue_crop(cropped_Plate23,\"Detected_New_Origigna5_Img1111\")    \n",
    "cropped_Plate24=debug_blue_crop(Origignal_Img1113,\"Detected_New_Origigna6_Img1111\") \n",
    "cropped_Plate24=debug_blue_crop(cropped_Plate24,\"Detected_New_Origigna6_Img1111\")   \n",
    "cropped_Plate25=debug_blue_crop(Origignal_Img1114,\"Detected_New_Origignal_Img1111\")    \n",
    "cropped_Plate25=debug_blue_crop(cropped_Plate25,\"Detected_New_Origignal_Img1111\")      \n",
    "cropped_Plate26=debug_blue_crop(Origignal_Img1115,\"Detected_New_Origigna2_Img1111\") \n",
    "cropped_Plate26=debug_blue_crop(cropped_Plate26,\"Detected_New_Origigna2_Img1111\") \n",
    " \n",
    "\n",
    "cropped_Plate27=debug_blue_crop(Original_Img11111,\"Detected_New_Origigna4_Img1111\")    \n",
    "cropped_Plate27=debug_blue_crop(cropped_Plate27,\"Detected_New_Origigna4_Img1111\")    \n",
    "cropped_Plate28=debug_blue_crop(Original_Img11112,\"Detected_New_Origigna5_Img1111\")    \n",
    "cropped_Plate28=debug_blue_crop(cropped_Plate28,\"Detected_New_Origigna5_Img1111\")     \n",
    "cropped_Plate29=debug_blue_crop(Original_Img11113,\"Detected_New_Origigna6_Img1111\") \n",
    "cropped_Plate29=debug_blue_crop(cropped_Plate29,\"Detected_New_Origigna6_Img1111\")  \n",
    "cropped_Plate30=debug_blue_crop(Original_Img11114,\"Detected_New_Origignal_Img1111\")    \n",
    "cropped_Plate30=debug_blue_crop(cropped_Plate30,\"Detected_New_Origignal_Img1111\")    \n",
    "cropped_Plate31=debug_blue_crop(Original_Img11115,\"Detected_New_Origigna2_Img1111\") \n",
    "cropped_Plate31=debug_blue_crop(cropped_Plate31,\"Detected_New_Origigna2_Img1111\")   \n",
    "\n",
    "cropped_Plate32=debug_blue_crop(New_Origigna7_Img1111,\"Detected_New_Origigna4_Img1111\")    \n",
    "cropped_Plate32=debug_blue_crop(cropped_Plate32,\"Detected_New_Origigna4_Img1111\")   \n",
    "cropped_Plate33=debug_blue_crop(New_Origigna8_Img1111,\"Detected_New_Origigna5_Img1111\")    \n",
    "cropped_Plate33=debug_blue_crop(cropped_Plate33,\"Detected_New_Origigna5_Img1111\")      \n",
    "cropped_Plate34=debug_blue_crop(New_Origigna9_Img1111,\"Detected_New_Origigna6_Img1111\") \n",
    "cropped_Plate34=debug_blue_crop(cropped_Plate34,\"Detected_New_Origigna6_Img1111\")   \n",
    "cropped_Plate37=debug_blue_crop(New_Origigna12_Img1111,\"Detected_New_Origigna4_Img1111\")    \n",
    "cropped_Plate37=debug_blue_crop(cropped_Plate37,\"Detected_New_Origigna4_Img1111\")    \n",
    "cropped_Plate38=debug_blue_crop(New_Origigna13_Img1111,\"Detected_New_Origigna5_Img1111\")    \n",
    "cropped_Plate38=debug_blue_crop(cropped_Plate38,\"Detected_New_Origigna5_Img1111\")    \n",
    "cropped_Plate39=debug_blue_crop(New_Origigna14_Img1111,\"Detected_New_Origigna6_Img1111\") \n",
    "cropped_Plate39=debug_blue_crop(cropped_Plate39,\"Detected_New_Origigna6_Img1111\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import os\n",
    "# from skimage import io\n",
    "\n",
    "# BASE_PATH = \"Localization Test/Vehicles\"\n",
    "\n",
    "# START_ID = 2087\n",
    "# END_ID   = 1\n",
    "\n",
    "# for i in range(START_ID, END_ID,-1):\n",
    "#     fname = f\"{i:04d}.jpg\"        # 0001.jpg, 0002.jpg, ...\n",
    "#     fpath = os.path.join(BASE_PATH, fname)\n",
    "\n",
    "#     if not os.path.exists(fpath):\n",
    "#         print(f\"[SKIP] Missing: {fpath}\")\n",
    "#         continue\n",
    "\n",
    "#     try:\n",
    "#         img = io.imread(fpath)    # RGB (as you want)\n",
    "#         title = f\"Vehicle_{fname}\"\n",
    "#         print(f\"[RUN] {title}\")\n",
    "#         img1=debug_blue_crop(img, title)\n",
    "#         img2=debug_blue_crop(img1, title)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"[ERROR] {fname}: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fe0048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# ================================================================\n",
    "#  HYBRID TILT ESTIMATION + ROTATION (RGB IN / RGB OUT)\n",
    "# ================================================================\n",
    "def _robust_fit_line(points_xy, max_iters=3, keep_sigma=2.5):\n",
    "    \"\"\"\n",
    "    Fit y = a + b x robustly by iteratively removing outliers.\n",
    "    Returns: (a,b), inlier_mask (bool array), residuals\n",
    "    \"\"\"\n",
    "    pts = np.array(points_xy, dtype=np.float32)\n",
    "    if pts.shape[0] < 3:\n",
    "        return None, None, None\n",
    "\n",
    "    x = pts[:, 0]\n",
    "    y = pts[:, 1]\n",
    "\n",
    "    mask = np.ones(len(pts), dtype=bool)\n",
    "    for _ in range(max_iters):\n",
    "        xm = x[mask]\n",
    "        ym = y[mask]\n",
    "        if xm.size < 3:\n",
    "            break\n",
    "\n",
    "        # least squares line fit y = a + b x\n",
    "        b, a = np.polyfit(xm, ym, 1)  # returns slope b, intercept a (since deg=1)\n",
    "        y_hat = a + b * x\n",
    "        resid = np.abs(y - y_hat)\n",
    "\n",
    "        # robust scale\n",
    "        med = np.median(resid[mask])\n",
    "        mad = np.median(np.abs(resid[mask] - med)) + 1e-6\n",
    "        sigma = 1.4826 * mad\n",
    "\n",
    "        thr = med + keep_sigma * sigma\n",
    "        new_mask = resid <= thr\n",
    "\n",
    "        if new_mask.sum() == mask.sum():\n",
    "            mask = new_mask\n",
    "            break\n",
    "        mask = new_mask\n",
    "\n",
    "    # final fit on inliers\n",
    "    if mask.sum() < 3:\n",
    "        return None, None, None\n",
    "    b, a = np.polyfit(x[mask], y[mask], 1)\n",
    "    y_hat = a + b * x\n",
    "    resid = np.abs(y - y_hat)\n",
    "    return (a, b), mask, resid\n",
    "\n",
    "\n",
    "def _rotate_keep_all_rgb(img_rgb, angle_deg):\n",
    "    \"\"\"\n",
    "    Rotate around center, keep full content (expanded canvas). RGB in/out.\n",
    "    \"\"\"\n",
    "    H, W = img_rgb.shape[:2]\n",
    "    center = (W * 0.5, H * 0.5)\n",
    "\n",
    "    M = cv2.getRotationMatrix2D(center, angle_deg, 1.0)\n",
    "\n",
    "    # compute new bounds\n",
    "    cos = abs(M[0, 0])\n",
    "    sin = abs(M[0, 1])\n",
    "    newW = int(H * sin + W * cos)\n",
    "    newH = int(H * cos + W * sin)\n",
    "\n",
    "    # shift so image is centered\n",
    "    M[0, 2] += (newW / 2) - center[0]\n",
    "    M[1, 2] += (newH / 2) - center[1]\n",
    "\n",
    "    rot = cv2.warpAffine(\n",
    "        img_rgb, M, (newW, newH),\n",
    "        flags=cv2.INTER_LINEAR,\n",
    "        borderMode=cv2.BORDER_REPLICATE\n",
    "    )\n",
    "    return rot\n",
    "\n",
    "\n",
    "def deskew_plate_hybrid(img_rgb, debug=False):\n",
    "    \"\"\"\n",
    "    HYBRID tilt estimation:\n",
    "      A) CC-based character proxies -> top/bottom points\n",
    "      B) Vertical projection peaks -> top/bottom points\n",
    "      C) Robust fit line(s) -> angle\n",
    "      D) Rotate if |angle| > threshold\n",
    "\n",
    "    Input:  RGB plate crop\n",
    "    Output: dict with rotated image and diagnostics\n",
    "    \"\"\"\n",
    "    H, W = img_rgb.shape[:2]\n",
    "    hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)\n",
    "    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 1) find BLUE STRIP Y-range (so we focus on region below it)\n",
    "    #    Use your own idea: blue-ish mask (lenient)\n",
    "    # ------------------------------------------------------------\n",
    "    lower = np.array([55, 20, 35], dtype=np.uint8)\n",
    "    upper = np.array([160, 255, 255], dtype=np.uint8)\n",
    "    blue_mask = cv2.inRange(hsv, lower, upper)\n",
    "\n",
    "    blue_mask = cv2.morphologyEx(\n",
    "        blue_mask, cv2.MORPH_CLOSE,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (9, 3)), iterations=1\n",
    "    )\n",
    "\n",
    "    row_counts = (blue_mask > 0).sum(axis=1).astype(np.float32)\n",
    "    if row_counts.max() > 0:\n",
    "        thr = 0.30 * row_counts.max()\n",
    "        ys = np.where(row_counts >= thr)[0]\n",
    "        y_strip_top = int(ys.min()) if ys.size else 0\n",
    "        y_strip_bot = int(ys.max()) if ys.size else int(0.25 * H)\n",
    "        strip_h = max(6, y_strip_bot - y_strip_top + 1)\n",
    "    else:\n",
    "        # fallback if blue mask fails inside crop\n",
    "        y_strip_top = 0\n",
    "        y_strip_bot = int(0.25 * H)\n",
    "        strip_h = max(6, y_strip_bot - y_strip_top + 1)\n",
    "\n",
    "    # character zone below strip (be lenient downward)\n",
    "    y_chars0 = int(np.clip(y_strip_bot + 0.05 * strip_h, 0, H-1))\n",
    "    y_chars1 = int(np.clip(y_strip_top + 3.2 * strip_h, 0, H-1))  # ~strip*3 = plate height-ish\n",
    "    if y_chars1 <= y_chars0 + 10:\n",
    "        y_chars0 = int(0.25 * H)\n",
    "        y_chars1 = H - 1\n",
    "\n",
    "    roi_gray = gray[y_chars0:y_chars1+1, :]\n",
    "    roi_h = roi_gray.shape[0]\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 2) binarize for \"dark strokes\" (characters)\n",
    "    # ------------------------------------------------------------\n",
    "    roi_blur = cv2.GaussianBlur(roi_gray, (3, 3), 0)\n",
    "    # adaptive threshold: strokes become white (1)\n",
    "    bin_inv = cv2.adaptiveThreshold(\n",
    "        roi_blur, 255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY_INV,\n",
    "        31, 10\n",
    "    )\n",
    "\n",
    "    # cleanup: remove tiny dots, connect strokes slightly\n",
    "    bin_inv = cv2.morphologyEx(\n",
    "        bin_inv, cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2)),\n",
    "        iterations=1\n",
    "    )\n",
    "    bin_inv = cv2.morphologyEx(\n",
    "        bin_inv, cv2.MORPH_CLOSE,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (3, 2)),\n",
    "        iterations=1\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 3) A) Connected components -> character proxies -> points\n",
    "    # ------------------------------------------------------------\n",
    "    pts_top = []\n",
    "    pts_bot = []\n",
    "\n",
    "    bin01 = (bin_inv > 0).astype(np.uint8)\n",
    "    num, labels, stats, _ = cv2.connectedComponentsWithStats(bin01, connectivity=8)\n",
    "\n",
    "    # size filters relative to ROI\n",
    "    min_area = max(25, int(0.0005 * (W * roi_h)))\n",
    "    max_area = int(0.20 * (W * roi_h))  # avoid giant blobs\n",
    "    min_h = max(10, int(0.12 * roi_h))\n",
    "    max_h = int(0.95 * roi_h)\n",
    "\n",
    "    for cid in range(1, num):\n",
    "        x, y, w, h, area = stats[cid]\n",
    "        if area < min_area or area > max_area:\n",
    "            continue\n",
    "        if h < min_h or h > max_h:\n",
    "            continue\n",
    "        # aspect sanity (character-ish)\n",
    "        ar = w / (h + 1e-6)\n",
    "        if ar < 0.05 or ar > 1.2:\n",
    "            continue\n",
    "\n",
    "        comp = (labels == cid)\n",
    "        ys, xs = np.where(comp)\n",
    "        if xs.size == 0:\n",
    "            continue\n",
    "\n",
    "        # top point: smallest y\n",
    "        y_top = ys.min()\n",
    "        xs_top = xs[ys == y_top]\n",
    "        x_top = int(np.median(xs_top))\n",
    "\n",
    "        # bottom point: largest y\n",
    "        y_bot = ys.max()\n",
    "        xs_bot = xs[ys == y_bot]\n",
    "        x_bot = int(np.median(xs_bot))\n",
    "\n",
    "        # shift back to full image coords\n",
    "        pts_top.append((x_top, y_chars0 + int(y_top)))\n",
    "        pts_bot.append((x_bot, y_chars0 + int(y_bot)))\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 4) B) Vertical projection peaks -> column-based points\n",
    "    # ------------------------------------------------------------\n",
    "    col_proj = (bin_inv > 0).sum(axis=0).astype(np.float32)\n",
    "    if col_proj.max() > 0:\n",
    "        # smooth\n",
    "        k = max(7, (W // 60) | 1)  # odd\n",
    "        col_smooth = cv2.GaussianBlur(col_proj.reshape(1, -1), (k, 1), 0).ravel()\n",
    "\n",
    "        # keep only strong columns\n",
    "        thr = 0.35 * col_smooth.max()\n",
    "        strong = col_smooth >= thr\n",
    "\n",
    "        # segments of strong columns -> peaks\n",
    "        segs = []\n",
    "        s = None\n",
    "        for i, v in enumerate(strong):\n",
    "            if v and s is None:\n",
    "                s = i\n",
    "            elif (not v) and (s is not None):\n",
    "                segs.append((s, i-1))\n",
    "                s = None\n",
    "        if s is not None:\n",
    "            segs.append((s, W-1))\n",
    "\n",
    "        for (x0, x1) in segs:\n",
    "            if (x1 - x0 + 1) < max(6, W // 80):\n",
    "                continue\n",
    "            xc = int(0.5 * (x0 + x1))\n",
    "\n",
    "            col = bin01[:, xc]  # in ROI coords\n",
    "            ys = np.where(col > 0)[0]\n",
    "            if ys.size < 5:\n",
    "                continue\n",
    "\n",
    "            y_top = int(ys.min())\n",
    "            y_bot = int(ys.max())\n",
    "\n",
    "            pts_top.append((xc, y_chars0 + y_top))\n",
    "            pts_bot.append((xc, y_chars0 + y_bot))\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 5) Fit top & bottom lines robustly\n",
    "    # ------------------------------------------------------------\n",
    "    out = {\n",
    "        \"angle_deg\": 0.0,\n",
    "        \"rotated_rgb\": img_rgb,\n",
    "        \"y_strip_top\": y_strip_top,\n",
    "        \"y_strip_bot\": y_strip_bot,\n",
    "        \"y_chars0\": y_chars0,\n",
    "        \"y_chars1\": y_chars1,\n",
    "        \"n_top_pts\": len(pts_top),\n",
    "        \"n_bot_pts\": len(pts_bot),\n",
    "        \"pts_top\": pts_top,\n",
    "        \"pts_bot\": pts_bot,\n",
    "    }\n",
    "\n",
    "    fit_top, mask_top, _ = _robust_fit_line(pts_top) if len(pts_top) >= 3 else (None, None, None)\n",
    "    fit_bot, mask_bot, _ = _robust_fit_line(pts_bot) if len(pts_bot) >= 3 else (None, None, None)\n",
    "\n",
    "    if fit_top is None and fit_bot is None:\n",
    "        if debug:\n",
    "            print(\"[HYBRID] Not enough points to estimate tilt.\")\n",
    "        return out\n",
    "\n",
    "    angles = []\n",
    "    weights = []\n",
    "\n",
    "    if fit_top is not None:\n",
    "        a, b = fit_top\n",
    "        ang = np.degrees(np.arctan(b))\n",
    "        angles.append(ang)\n",
    "        weights.append(float(mask_top.sum()) if mask_top is not None else 1.0)\n",
    "\n",
    "    if fit_bot is not None:\n",
    "        a, b = fit_bot\n",
    "        ang = np.degrees(np.arctan(b))\n",
    "        angles.append(ang)\n",
    "        weights.append(float(mask_bot.sum()) if mask_bot is not None else 1.0)\n",
    "\n",
    "    # if both exist but disagree strongly in sign, trust the one with more inliers\n",
    "    if len(angles) == 2 and (np.sign(angles[0]) != np.sign(angles[1])) and (abs(angles[0] - angles[1]) > 2.0):\n",
    "        idx = int(np.argmax(weights))\n",
    "        angle = float(angles[idx])\n",
    "    else:\n",
    "        wsum = float(np.sum(weights)) + 1e-6\n",
    "        angle = float(np.sum(np.array(angles) * np.array(weights)) / wsum)\n",
    "\n",
    "    out[\"angle_deg\"] = angle\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 6) Rotate only if meaningful\n",
    "    # ------------------------------------------------------------\n",
    "    ROT_THRESH_DEG = 2.0\n",
    "    if abs(angle) >= ROT_THRESH_DEG:\n",
    "        # rotate opposite direction to correct tilt\n",
    "        out[\"rotated_rgb\"] = _rotate_keep_all_rgb(img_rgb, -angle)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"[HYBRID] strip_y=({y_strip_top},{y_strip_bot}) chars_y=({y_chars0},{y_chars1})\")\n",
    "        print(f\"[HYBRID] top_pts={len(pts_top)} bot_pts={len(pts_bot)} -> angle={angle:.2f} deg (threshold={ROT_THRESH_DEG})\")\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_deskew_debug(img_rgb, out, title=\"\"):\n",
    "    \"\"\"\n",
    "    Plot:\n",
    "      1) Original RGB plate\n",
    "      2) Top / bottom points overlaid\n",
    "      3) Rotated (deskewed) result\n",
    "    \"\"\"\n",
    "    pts_top = out[\"pts_top\"]\n",
    "    pts_bot = out[\"pts_bot\"]\n",
    "    rot = out[\"rotated_rgb\"]\n",
    "    angle = out[\"angle_deg\"]\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "    # -------------------------\n",
    "    # Original\n",
    "    # -------------------------\n",
    "    axs[0].imshow(img_rgb)\n",
    "    axs[0].set_title(f\"{title}\\nOriginal\")\n",
    "    axs[0].axis(\"off\")\n",
    "\n",
    "    # -------------------------\n",
    "    # Points overlay\n",
    "    # -------------------------\n",
    "    axs[1].imshow(img_rgb)\n",
    "    if len(pts_top) > 0:\n",
    "        xt, yt = zip(*pts_top)\n",
    "        axs[1].scatter(xt, yt, s=12, c=\"red\", label=\"Top pts\")\n",
    "    if len(pts_bot) > 0:\n",
    "        xb, yb = zip(*pts_bot)\n",
    "        axs[1].scatter(xb, yb, s=12, c=\"blue\", label=\"Bottom pts\")\n",
    "\n",
    "    axs[1].legend(loc=\"lower right\", fontsize=8)\n",
    "    axs[1].set_title(\n",
    "        f\"Fitting points\\nangle = {angle:.2f}°\"\n",
    "    )\n",
    "    axs[1].axis(\"off\")\n",
    "\n",
    "    # -------------------------\n",
    "    # Deskewed\n",
    "    # -------------------------\n",
    "    axs[2].imshow(rot)\n",
    "    axs[2].set_title(\"Deskewed output\")\n",
    "    axs[2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plates = [\n",
    "    cropped_Plate1, cropped_Plate2, cropped_Plate3, cropped_Plate4,\n",
    "    cropped_Plate5, cropped_Plate6, cropped_Plate7, cropped_Plate8,\n",
    "    cropped_Plate9, cropped_Plate10, cropped_Plate11, cropped_Plate12,\n",
    "    cropped_Plate13, cropped_Plate14, cropped_Plate15, cropped_Plate16,\n",
    "    cropped_Plate17, cropped_Plate18, cropped_Plate19, cropped_Plate20,\n",
    "    cropped_Plate21, cropped_Plate22, cropped_Plate23, cropped_Plate24,\n",
    "    cropped_Plate25, cropped_Plate26, cropped_Plate27, cropped_Plate28,\n",
    "    cropped_Plate29, cropped_Plate30, cropped_Plate31\n",
    "]\n",
    "\n",
    "for i, p in enumerate(plates, start=1):\n",
    "    if p is None:\n",
    "        continue\n",
    "    out = deskew_plate_hybrid(p, debug=True)\n",
    "    plot_deskew_debug(p, out, title=f\"cropped_Plate{i}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f8499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from skimage import io, color, filters, morphology\n",
    "import numpy as np\n",
    "from skimage import img_as_ubyte\n",
    "\n",
    "\n",
    "def preprocess_plate_with_smoothing(img, debug=True):\n",
    "    \"\"\"\n",
    "    Preprocess the localized license plate image with:\n",
    "    - Pre-threshold smoothing (median blur)\n",
    "    - CLAHE\n",
    "    - Adaptive thresholding\n",
    "    - Post-threshold noise removal (morphological opening)\n",
    "    Returns the final cleaned binary image.\n",
    "    \"\"\"\n",
    "    # ---------------- 1. Convert to grayscale ----------------\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # ---------------- 2. Optional pre-threshold smoothing ----------------\n",
    "    # Reduce scattered grayscale noise before thresholding\n",
    "    gray_smooth = cv2.medianBlur(gray, ksize=3)  # small kernel\n",
    "\n",
    "    # ---------------- 3. CLAHE ----------------\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    enhanced = clahe.apply(gray_smooth)\n",
    "\n",
    "    # ---------------- 4. Adaptive Threshold ----------------\n",
    "    H, W = enhanced.shape\n",
    "    block_size = int(max(15, (H // 7) | 1))  # odd\n",
    "    C = 8\n",
    "    binary = cv2.adaptiveThreshold(\n",
    "        enhanced,\n",
    "        maxValue=255,\n",
    "        adaptiveMethod=cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        thresholdType=cv2.THRESH_BINARY,\n",
    "        blockSize=block_size,\n",
    "        C=C\n",
    "    )\n",
    "\n",
    "    # ---------------- 5. Invert if needed ----------------------------------\n",
    "    white_ratio = np.mean(binary == 255)\n",
    "    if white_ratio > 0.55:\n",
    "        binary = cv2.bitwise_not(binary)\n",
    "\n",
    "    # ---------------- 6. Post-threshold noise removal ----------------\n",
    "    # Remove tiny white speckles\n",
    "    h, w = binary.shape\n",
    "    k_open = max(1, round(h * 0.015))  # kernel proportional to plate height\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (k_open, k_open))\n",
    "    cleaned_binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # ---------------- 7. Debug visualization ----------------\n",
    "    if debug:\n",
    "        plt.figure(figsize=(15,5))\n",
    "        plt.subplot(1,4,1)\n",
    "        plt.imshow(gray, cmap='gray'); plt.title(\"Grayscale\"); plt.axis(\"off\")\n",
    "        plt.subplot(1,4,2)\n",
    "        plt.imshow(gray_smooth, cmap='gray'); plt.title(\"Median Smoothed\"); plt.axis(\"off\")\n",
    "        plt.subplot(1,4,3)\n",
    "        plt.imshow(binary, cmap='gray'); plt.title(\"Adaptive Threshold\"); plt.axis(\"off\")\n",
    "        plt.subplot(1,4,4)\n",
    "        plt.imshow(cleaned_binary, cmap='gray'); plt.title(\"After Morph Open\"); plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "    return cleaned_binary\n",
    "\n",
    "\n",
    "def crop_one_side(img, mask, side, threshold=0.02, max_px=21):\n",
    "    \"\"\"\n",
    "    Crops ONE SIDE ONLY (top, bottom, left, right) by 1px repeatedly.\n",
    "    Stops when that side becomes clean OR when image would become too small.\n",
    "    \"\"\"\n",
    "    for _ in range(max_px):\n",
    "\n",
    "        # HARD SAFETY — never allow cropping if too small\n",
    "        if img.shape[0] < 10 or img.shape[1] < 10:\n",
    "            break\n",
    "\n",
    "        if side == \"top\":\n",
    "            border_val = mask[0, :].mean()\n",
    "            if border_val > threshold:\n",
    "                img  = img[1:, :]\n",
    "                mask = mask[1:, :]\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        elif side == \"bottom\":\n",
    "            border_val = mask[-1, :].mean()\n",
    "            if border_val > threshold:\n",
    "                img  = img[:-1, :]\n",
    "                mask = mask[:-1, :]\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        elif side == \"left\":\n",
    "            border_val = mask[:, 0].mean()\n",
    "            if border_val > threshold:\n",
    "                img  = img[:, 1:]\n",
    "                mask = mask[:, 1:]\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        elif side == \"right\":\n",
    "            border_val = mask[:, -1].mean()\n",
    "            if border_val > threshold:\n",
    "                img  = img[:, :-1]\n",
    "                mask = mask[:, :-1]\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    return img, mask\n",
    "\n",
    "\n",
    "def clean_crop(img, mask):\n",
    "    img, mask = crop_one_side(img, mask, \"top\")\n",
    "    img, mask = crop_one_side(img, mask, \"bottom\")\n",
    "    img, mask = crop_one_side(img, mask, \"left\")\n",
    "    img, mask = crop_one_side(img, mask, \"right\")\n",
    "    return img, mask\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# WHITE BACKGROUND RENDERING\n",
    "# ======================================================================\n",
    "def make_clean(region_img, region_mask):\n",
    "    clean = np.ones_like(region_img)\n",
    "    clean[region_mask] = region_img[region_mask]\n",
    "    return clean\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def remove_plate_header(plate_img, header_ratio=0.2):\n",
    "\n",
    "    \"\"\"\n",
    "    Crops out the top header rectangle (Egypt / مصر) from a license plate.\n",
    "    \n",
    "    Parameters:\n",
    "        plate_img: binary or grayscale plate image\n",
    "        header_ratio: proportion of height to remove from top (0.0–1.0)\n",
    "    \n",
    "    Returns:\n",
    "        cropped_img: the plate without the top header\n",
    "    \"\"\"\n",
    "    h, w = plate_img.shape[:2]\n",
    "    header_height = int(h * header_ratio)\n",
    "    \n",
    "    # Keep only the bottom part\n",
    "    cropped_img = plate_img[header_height:, :]\n",
    "    \n",
    "    return cropped_img\n",
    "\n",
    "\n",
    "\n",
    "def morphological_and_CCL(binary_img,left,right,debug=True):\n",
    "    \"\"\"\n",
    "    Takes the binarized plate image (white foreground, black background)\n",
    "    and performs:\n",
    "      - Small opening\n",
    "      - Small closing\n",
    "      - Connected Components (8-connectivity)\n",
    "      - Character plausibility filtering (relative thresholds)\n",
    "    Returns:\n",
    "      cleaned_binary, boxes, stats_all, labels, num_labels\n",
    "    \"\"\"\n",
    "\n",
    "    # ---------- STEP 2: Morphological Cleaning ----------\n",
    "    h, w = binary_img.shape[:2]\n",
    "\n",
    "    # Kernel sizes scaled to image height\n",
    "    # k1 = max(1, round(h * 0.01))  # opening kernel\n",
    "    # k2 = max(1, round(h * 0.025))   # closing kernel\n",
    "\n",
    "    # kernel1 = cv2.getStructuringElement(cv2.MORPH_RECT, (k1, k1))\n",
    "    # kernel2 = cv2.getStructuringElement(cv2.MORPH_RECT, (k2, k2))\n",
    "\n",
    "    # # Small opening to remove tiny speckles\n",
    "    # opened = cv2.morphologyEx(binary_img, cv2.MORPH_OPEN, kernel1,iterations=1)\n",
    "\n",
    "    # # Small closing to fill small holes in characters\n",
    "    # closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel2,iterations=1)\n",
    "\n",
    "    # cleaned_binary = closed.copy()\n",
    "\n",
    "    # # Force binary exact values (0,255) and uint8\n",
    "    # cleaned_binary = np.where(cleaned_binary > 0, 255, 0).astype(np.uint8)\n",
    "\n",
    "    # if debug:\n",
    "    #     print(\"After morphology: dtype:\", cleaned_binary.dtype, \"unique:\", np.unique(cleaned_binary))\n",
    "    #     print(\"White pixel count:\", int(np.sum(cleaned_binary == 255)))\n",
    "\n",
    "\n",
    "    # cropped_plate = remove_plate_header(cleaned_binary, header_ratio=0.45)\n",
    "    # noborders= remove_white_borders(cleaned_binary)\n",
    "\n",
    "    \n",
    "    \n",
    "    # ---------- STEP 3: Connected Components (8-connectivity) ----------\n",
    "\n",
    "    left = (left > 0).astype(\"uint8\") * 255\n",
    "    right = (right > 0).astype(\"uint8\") * 255\n",
    "\n",
    "    num_labels1, labels1, stats1, centroids1 = cv2.connectedComponentsWithStats(\n",
    "        left,\n",
    "        connectivity=8,\n",
    "        ltype=cv2.CV_32S\n",
    "    )\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(\n",
    "        right,\n",
    "        connectivity=8,\n",
    "        ltype=cv2.CV_32S\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    if debug:\n",
    "        print(\"num_labels (including background):\", num_labels)\n",
    "        # optionally print first few stats\n",
    "        for i in range(min(num_labels, 12)):\n",
    "            x,y,wb,hb,area = stats[i]\n",
    "            print(f\"label {i}: x={x} y={y} w={wb} h={hb} area={area}\")\n",
    "\n",
    "    # ---------- STEP 5: Bounding-Box Filtering (RELATIVE thresholds) ----------\n",
    "    boxesleft = []\n",
    "    stats_allleft = []\n",
    "    boxesright = []\n",
    "    stats_allright = []\n",
    "\n",
    "    plate_area = h * w\n",
    "\n",
    "    # Reasonable starting thresholds (relative)\n",
    "    min_area = plate_area * 0.005   # 0.5% of plate area\n",
    "    max_area = plate_area * 0.25    # 25% of plate area (likely merged)\n",
    "    min_aspect = 0.08               # w/h (allow narrow digits)   0.08 \n",
    "    max_aspect = 1.4                # some letters might be wider than digits\n",
    "\n",
    "    min_height = h * 0.15           # allow small characters (15% of plate height)\n",
    "    max_height = h * 0.4\n",
    "\n",
    "    if debug:\n",
    "        print(f\"plate_area={plate_area}, min_area={min_area}, max_area={max_area}\")\n",
    "        print(f\"min_height_px={min_height}, max_height_px={max_height}\")\n",
    "\n",
    "    for label in range(1, num_labels1):  # skip background label 0\n",
    "        x, y, w_b, h_b, area = stats1[label]\n",
    "        stats_allleft.append((label, x, y, w_b, h_b, area))\n",
    "\n",
    "        # area filtering\n",
    "        if area < min_area:\n",
    "            continue\n",
    "        if area > max_area:\n",
    "            continue  # merged objects (we're skipping splitting per your instruction)\n",
    "\n",
    "        aspect = w_b / float(max(1, h_b))\n",
    "\n",
    "        # aspect ratio filtering\n",
    "        if aspect < min_aspect or aspect > max_aspect:\n",
    "            continue\n",
    "\n",
    "        # height filtering\n",
    "        if h_b < min_height or h_b > max_height:\n",
    "            continue\n",
    "\n",
    "        boxesleft.append((x, y, w_b, h_b))\n",
    "        \n",
    "    for label in range(1, num_labels):  # skip background label 0\n",
    "        x, y, w_b, h_b, area = stats[label]\n",
    "        stats_allright.append((label, x, y, w_b, h_b, area))\n",
    "\n",
    "        # area filtering\n",
    "        if area < min_area:\n",
    "            continue\n",
    "        if area > max_area:\n",
    "            continue  # merged objects (we're skipping splitting per your instruction)\n",
    "\n",
    "        aspect = w_b / float(max(1, h_b))\n",
    "\n",
    "        # aspect ratio filtering\n",
    "        if aspect < min_aspect or aspect > max_aspect:\n",
    "            continue\n",
    "\n",
    "        # height filtering\n",
    "        if h_b < min_height or h_b > max_height:\n",
    "            continue\n",
    "\n",
    "        boxesright.append((x, y, w_b, h_b))\n",
    "\n",
    "    if debug:\n",
    "        print(\"Found candidate boxes:\", len(boxesleft)+len(boxesright))\n",
    "        # show bounding boxes overlay for quick visual check (returns BGR image)\n",
    "        dbg = cv2.cvtColor(left, cv2.COLOR_GRAY2BGR)\n",
    "        for (x, y, wb, hb) in boxesleft:\n",
    "            cv2.rectangle(dbg, (x, y), (x+wb, y+hb), (0,255,0), 2)\n",
    "        dbg2 = cv2.cvtColor(right, cv2.COLOR_GRAY2BGR)\n",
    "        for (x, y, wb, hb) in boxesright:\n",
    "            cv2.rectangle(dbg, (x, y), (x+wb, y+hb), (0,255,0), 2)\n",
    "        # Display inline if desired (plt or cv2.imshow)\n",
    "        # cv2.imshow(\"ccl_debug\", dbg); cv2.waitKey(0)\n",
    "        # For notebooks, convert and display with matplotlib:\n",
    "        try:\n",
    "            from matplotlib import pyplot as plt\n",
    "            # plt.figure(figsize=(8,5)); plt.imshow(cv2.cvtColor(dbg, cv2.COLOR_BGR2RGB)); plt.axis(\"off\"); plt.show()\n",
    "            # plt.figure(figsize=(8,5)); plt.imshow(cv2.cvtColor(dbg2, cv2.COLOR_BGR2RGB)); plt.axis(\"off\"); plt.show()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # ensure expected number (2–7 components)\n",
    "    if len(boxesleft)+len(boxesright) < 2 or len(boxesleft)+len(boxesright) > 7:\n",
    "        print(\"⚠ Warning: suspicious number of character candidates =\", len(boxesleft)+len(boxesright))\n",
    "\n",
    "    return boxesleft,boxesright,left,right\n",
    "\n",
    "\n",
    "def draw_components(imgL,imgR, boxesL,boxesR, pad=3):\n",
    "    \"\"\"Draws padded bounding boxes on the image for visualization.\"\"\"\n",
    "    out = cv2.cvtColor(imgL.copy(), cv2.COLOR_GRAY2BGR)\n",
    "    H, W = imgL.shape[:2]\n",
    "\n",
    "    for (x, y, w, h) in boxesL:\n",
    "        # Expand bounding box\n",
    "        x1 = max(0, x - pad)\n",
    "        y1 = max(0, y - pad)\n",
    "        x2 = min(W - 1, x + w + pad)\n",
    "        y2 = min(H - 1, y + h + pad)\n",
    "\n",
    "        cv2.rectangle(out, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    out2 = cv2.cvtColor(imgR.copy(), cv2.COLOR_GRAY2BGR)\n",
    "    H, W = imgR.shape[:2]\n",
    "\n",
    "    for (x, y, w, h) in boxesR:\n",
    "        # Expand bounding box\n",
    "        x1 = max(0, x - pad)\n",
    "        y1 = max(0, y - pad)\n",
    "        x2 = min(W - 1, x + w + pad)\n",
    "        y2 = min(H - 1, y + h + pad)\n",
    "\n",
    "        cv2.rectangle(out2, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    return out,out2\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def _ensure_binary_uint8(img):\n",
    "    img = np.asarray(img)\n",
    "    if img.dtype != np.uint8:\n",
    "        img = (img > 0).astype(np.uint8) * 255\n",
    "    else:\n",
    "        # ensure exact 0/255\n",
    "        img = np.where(img > 0, 255, 0).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def manual_sort_boxes(boxes):\n",
    "    \"\"\"\n",
    "    Sort boxes by x-coordinate (left-to-right) manually.\n",
    "    boxes: list of (x, y, w, h)\n",
    "    returns: sorted list\n",
    "    \"\"\"\n",
    "    sorted_boxes = []\n",
    "\n",
    "    for box in boxes:\n",
    "        x = box[0]\n",
    "        inserted = False\n",
    "        for i, b in enumerate(sorted_boxes):\n",
    "            if x < b[0]:\n",
    "                sorted_boxes.insert(i, box)\n",
    "                inserted = True\n",
    "                break\n",
    "        if not inserted:\n",
    "            sorted_boxes.append(box)\n",
    "\n",
    "    return sorted_boxes\n",
    "\n",
    "\n",
    "def save_characters(characters_sortedL, characters_sortedR):\n",
    "    \"\"\"\n",
    "    Saves sorted character images from digits (left) and letters (right).\n",
    "    \n",
    "    Parameters:\n",
    "        characters_sortedL: list of (x, y, w, h, img) for digits\n",
    "        characters_sortedR: list of (x, y, w, h, img) for letters\n",
    "    \"\"\"\n",
    "    # Save digits\n",
    "    for i, (_, _, _, _, img) in enumerate(characters_sortedL):\n",
    "        cv2.imwrite(f\"digit_{i}.png\", img)\n",
    "\n",
    "    # Save letters\n",
    "    for i, (_, _, _, _, img) in enumerate(characters_sortedR):\n",
    "        cv2.imwrite(f\"letter_{i}.png\", img)\n",
    "\n",
    "\n",
    "def crop_characters(binary_img, boxes, resize_to=(64, 64), pad_ratio=0.09):\n",
    "    \"\"\"\n",
    "    Returns list of tuples: (x, y, w, h, char_img) with padded cropping.\n",
    "    \"\"\"\n",
    "    H, W = binary_img.shape[:2]\n",
    "    characters = []\n",
    "\n",
    "    for (x, y, w_b, h_b) in boxes:\n",
    "\n",
    "        # Compute proportional padding from box size\n",
    "        pad_x = int(w_b * pad_ratio)\n",
    "        pad_y = int(h_b * pad_ratio)\n",
    "\n",
    "        # Apply padded crop\n",
    "        x1 = max(0, x - pad_x)\n",
    "        y1 = max(0, y - pad_y)\n",
    "        x2 = min(W, x + w_b + pad_x)\n",
    "        y2 = min(H, y + h_b + pad_y)\n",
    "\n",
    "        char_img = binary_img[y1:y2, x1:x2]\n",
    "\n",
    "        # Resize if needed\n",
    "        # if resize_to is not None:\n",
    "        #     char_img = cv2.resize(char_img, resize_to, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        characters.append((x, y, w_b, h_b, char_img))\n",
    "\n",
    "    return characters\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "img = io.imread(\"Dataset/Vehicles with unpaid customs.png\")[:,:,:3]\n",
    "# img=plate_crop3\n",
    "gray = color.rgb2gray(img)\n",
    "\n",
    "# 1) Crop bottom part (Arabic region)\n",
    "h = gray.shape[0]\n",
    "plate = gray[int(h * 0.35):, :]\n",
    "\n",
    "\n",
    "# 2) Threshold + clean\n",
    "th = filters.threshold_otsu(plate)\n",
    "mask = plate < th\n",
    "\n",
    "mask = morphology.remove_small_objects(mask, 0.1)\n",
    "mask = morphology.remove_small_holes(mask, 0.1)\n",
    "\n",
    "# 3) Split halves\n",
    "H, W = mask.shape\n",
    "digits_img  = plate[:, :W // 2]\n",
    "letters_img = plate[:, W // 2:]\n",
    "\n",
    "digits_mask  = mask[:, :W // 2]\n",
    "letters_mask = mask[:, W // 2:]\n",
    "\n",
    "\n",
    "# 4) SAFE crop each half independently\n",
    "digits_img_c,  digits_mask_c  = clean_crop(digits_img, digits_mask)\n",
    "letters_img_c, letters_mask_c = clean_crop(letters_img, letters_mask)\n",
    "\n",
    "# 5) Build final clean images\n",
    "clean_digits  = make_clean(digits_img_c, digits_mask_c)\n",
    "clean_letters = make_clean(letters_img_c, letters_mask_c)\n",
    "\n",
    "# 6) Show results\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(digits_mask_c, cmap=\"gray\")\n",
    "plt.title(\"ARABIC DIGITS — CLEAN, NO BORDERS\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(letters_mask_c, cmap=\"gray\")\n",
    "plt.title(\"ARABIC LETTERS — CLEAN, NO BORDERS\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# 7) Save\n",
    "io.imsave(\"clean_digits.png\", img_as_ubyte(clean_digits))\n",
    "io.imsave(\"clean_letters.png\", img_as_ubyte(clean_letters))\n",
    "print(\"Saved clean_digits.png & clean_letters.png\")\n",
    "\n",
    "# Straight1 = io.imread('Dataset/image.png')\n",
    "# image=plate_crop1\n",
    "# image=Straight1\n",
    "# proccesded=preprocess_plate_with_smoothing(image)\n",
    "boxesL, boxesR,leftT,rightT= morphological_and_CCL(img,digits_mask_c,letters_mask_c,debug=True)\n",
    "# draw_components(leftT,rightT,boxesL,boxesR)\n",
    "\n",
    "out_digits, out_letters = draw_components(leftT, rightT, boxesL, boxesR)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(out_digits)\n",
    "plt.title(\"Digits with Boxes\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(out_letters)\n",
    "plt.title(\"Letters with Boxes\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# Sort boxes by x-coordinate\n",
    "boxes_sortedL = manual_sort_boxes(boxesL)\n",
    "boxes_sortedR = manual_sort_boxes(boxesR)\n",
    "\n",
    "# Crop in that order\n",
    "charimages_sortedL = crop_characters(leftT, boxes_sortedL)\n",
    "charimages_sortedR = crop_characters(rightT, boxes_sortedR)\n",
    "save_characters(charimages_sortedL,charimages_sortedR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82e95d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import easyocr\n",
    "os.environ['TESSDATA_PREFIX'] = os.path.abspath(\"Dataset\")\n",
    "# os.environ.pop('TESSDATA_PREFIX', None)\n",
    "def add_padding(img, pad=10):\n",
    "    return cv2.copyMakeBorder(\n",
    "        img, pad, pad, pad, pad,\n",
    "        borderType=cv2.BORDER_CONSTANT,\n",
    "        value=255\n",
    "    )\n",
    "\n",
    "def add_paddingblack(img, pad=200):\n",
    "    return cv2.copyMakeBorder(\n",
    "        img, pad, pad, pad, pad,\n",
    "        borderType=cv2.BORDER_CONSTANT,\n",
    "        value=0\n",
    "    )\n",
    "\n",
    "def recognize_arabic_digit(image_path, show_preprocessed=False):\n",
    "    \"\"\"\n",
    "    Recognize a single Arabic digit from an image.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to image file.\n",
    "        show_preprocessed (bool): If True, shows the binary preprocessed image.\n",
    "    \n",
    "    Returns:\n",
    "        str: Detected Arabic digit or empty string if not recognized.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Load image\n",
    "    # img = io.imread(image_path)\n",
    "    # img=add_paddingblack(img)\n",
    "    # img=add_padding(img)\n",
    "    img=d_mask\n",
    "    \n",
    "    # # 2. Convert to grayscale if needed\n",
    "    # gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img\n",
    "    \n",
    "    # # 3. Resize image up to help OCR\n",
    "    # gray = cv2.resize(gray, None, fx=5, fy=5, interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    # # 4. Smooth image to reduce noise\n",
    "    # blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "    \n",
    "    # # 5. Threshold to get binary image\n",
    "    # _, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # # 6. Invert if background is dark\n",
    "    # if np.mean(thresh) < 127:\n",
    "    #     thresh = cv2.bitwise_not(thresh)\n",
    "    \n",
    "    # Optional: show preprocessed image\n",
    "    if show_preprocessed:\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    # 7. Configure Tesseract for single character + Arabic digits only\n",
    "    # config = f'--oem 3 --psm 10 -c tessedit_char_whitelist={ARABIC_DIGITS}'\n",
    "    \n",
    "    # 8. Run OCR\n",
    "    # text = pytesseract.image_to_string(thresh, lang='ara')\n",
    "\n",
    "    reader = easyocr.Reader(['ar'])\n",
    "    results = reader.readtext(img)\n",
    "    texts = [text for bbox, text, prob in results]\n",
    "\n",
    "\n",
    "    # 9. Clean result\n",
    "    # text = text.strip()\n",
    "    return texts\n",
    "\n",
    "# Example usage:\n",
    "digit = recognize_arabic_digit(\"letter_0.png\", show_preprocessed=True)\n",
    "print(\"Detected Arabic digit EASYOCR:\", repr(digit))\n",
    "# print(\"Detected Arabic digit:\", repr(digit))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af599f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MAAW PLATE CROP\n",
    "'''\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def extract_clean_plate(img_bgr):\n",
    "    \"\"\"\n",
    "    Input: BGR image\n",
    "    Output: CLEAN tightly-cropped plate image (BGR)\n",
    "    \"\"\"\n",
    "\n",
    "    # ---------- 1. PREPROCESS ----------\n",
    "    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Reduce noise but keep edges\n",
    "    gray = cv2.bilateralFilter(gray, 11, 17, 17)\n",
    "\n",
    "    # ---------- 2. EDGE DETECTION ----------\n",
    "    edges = cv2.Canny(gray, 80, 200)\n",
    "\n",
    "    # ---------- 3. MORPHOLOGY (JOIN PLATE EDGES) ----------\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9, 5))\n",
    "    closed = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    closed = cv2.dilate(closed, None, iterations=2)\n",
    "    closed = cv2.erode(closed, None, iterations=1)\n",
    "\n",
    "    # ---------- 4. FIND CONTOURS ----------\n",
    "    cnts, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if len(cnts) == 0:\n",
    "        return None\n",
    "\n",
    "    H, W = gray.shape\n",
    "\n",
    "    best_cnt = None\n",
    "    best_score = 0\n",
    "\n",
    "    for c in cnts:\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        area = w * h\n",
    "        aspect = w / float(h)\n",
    "\n",
    "        # Egyptian plate geometry constraints\n",
    "        if area < 0.01 * H * W:\n",
    "            continue\n",
    "        if not (2.0 < aspect < 6.0):\n",
    "            continue\n",
    "\n",
    "        score = area  # prioritize largest valid rectangle\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_cnt = (x, y, w, h)\n",
    "\n",
    "    if best_cnt is None:\n",
    "        return None\n",
    "\n",
    "    x, y, w, h = best_cnt\n",
    "\n",
    "    # ---------- 5. SAFE TIGHT CROP ----------\n",
    "    pad = int(0.03 * max(w, h))\n",
    "    x0 = max(0, x - pad)\n",
    "    y0 = max(0, y - pad)\n",
    "    x1 = min(W, x + w + pad)\n",
    "    y1 = min(H, y + h + pad)\n",
    "\n",
    "    plate = img_bgr[y0:y1, x0:x1]\n",
    "\n",
    "    return plate\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plates = []\n",
    "titles = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "sample_images = [\n",
    "    globals()[f\"cropped_Plate{i}\"]\n",
    "    for i in range(1, 40)\n",
    "    if f\"cropped_Plate{i}\" in globals()\n",
    "]\n",
    "'''\n",
    "\n",
    "imim1 = io.imread('maaw/image1.png')\n",
    "imim2 = io.imread('maaw/image2.png')\n",
    "imim3 = io.imread('maaw/image3.png')\n",
    "imim4 = io.imread('maaw/image4.png')\n",
    "imim5 = io.imread('maaw/image5.png')\n",
    "\n",
    "\n",
    "sample_images = [imim1, imim2, imim3, imim4, imim5]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "for i, img in enumerate(sample_images):  # sample_images = list of your inputs\n",
    "    plate = extract_clean_plate(img)\n",
    "    if plate is not None:\n",
    "        plates.append(plate)\n",
    "        titles.append(f\"Plate {i+1}\")\n",
    "\n",
    "show_images(plates, titles)\n",
    "'''\n",
    "for i, img in enumerate(sample_images):\n",
    "    plate = extract_clean_plate(img)\n",
    "\n",
    "    if plate is None:\n",
    "        continue\n",
    "\n",
    "    show_images(\n",
    "        images=[img, plate],\n",
    "        titles=[f\"Input {i+1}\", f\"Plate {i+1}\"]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "MAAW PLATE CROP\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1242f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "FORTNITE SEGMENT\n",
    "'''\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "FORT SEGMENT (Robust)\n",
    "- Shows BIG boxes (digits / letters) first\n",
    "- Splits into individual characters\n",
    "- Produces tight-cropped characters (no internal frames/bars)\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# VISUALIZATION\n",
    "# ============================================================\n",
    "def show_images(images, titles=None, figsize_scale=4):\n",
    "    n = len(images)\n",
    "    if titles is None:\n",
    "        titles = [f\"({i})\" for i in range(n)]\n",
    "    plt.figure(figsize=(figsize_scale * n, figsize_scale))\n",
    "    for i, (img, t) in enumerate(zip(images, titles)):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        if img.ndim == 2:\n",
    "            plt.imshow(img, cmap=\"gray\")\n",
    "        else:\n",
    "            plt.imshow(img)\n",
    "        plt.title(t)\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1) PLATE ROI EXTRACTION (ROBUST)\n",
    "# ============================================================\n",
    "def extract_plate_roi(img_bgr):\n",
    "    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.bilateralFilter(gray, 9, 60, 60)\n",
    "\n",
    "    edges = cv2.Canny(gray, 80, 200)\n",
    "    edges = cv2.dilate(edges, cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5)))\n",
    "\n",
    "    cnts, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not cnts:\n",
    "        return img_bgr\n",
    "\n",
    "    cnt = max(cnts, key=cv2.contourArea)\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "    pad = int(0.03 * max(w, h))\n",
    "    H, W = img_bgr.shape[:2]\n",
    "\n",
    "    x0 = max(0, x - pad)\n",
    "    y0 = max(0, y - pad)\n",
    "    x1 = min(W, x + w + pad)\n",
    "    y1 = min(H, y + h + pad)\n",
    "\n",
    "    return img_bgr[y0:y1, x0:x1]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2) CHARACTER BAND\n",
    "# ============================================================\n",
    "def crop_character_band(plate):\n",
    "    H = plate.shape[0]\n",
    "    return plate[int(0.35 * H):int(0.93 * H), :]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3) BINARIZATION (ARABIC SAFE) + (optional) light border cleanup\n",
    "# ============================================================\n",
    "def binarize_clean(region):\n",
    "    gray = cv2.cvtColor(region, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    clahe = cv2.createCLAHE(2.5, (8, 8))\n",
    "    gray = clahe.apply(gray)\n",
    "    gray = cv2.medianBlur(gray, 5)\n",
    "\n",
    "    _, bw = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Gentle close: connect strokes but don't destroy holes too much\n",
    "    bw = cv2.morphologyEx(\n",
    "        bw, cv2.MORPH_CLOSE,\n",
    "        cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3)),\n",
    "        iterations=1\n",
    "    )\n",
    "\n",
    "    # Gentle open: remove pepper noise\n",
    "    bw = cv2.morphologyEx(\n",
    "        bw, cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2)),\n",
    "        iterations=1\n",
    "    )\n",
    "\n",
    "    return bw\n",
    "\n",
    "\n",
    "def clean_digit(ch):\n",
    "    bin_ch = (ch > 0).astype(np.uint8)\n",
    "    num, labels, stats, _ = cv2.connectedComponentsWithStats(bin_ch, 8)\n",
    "\n",
    "    if num <= 1:\n",
    "        return ch\n",
    "\n",
    "    # Keep ONLY the largest component\n",
    "    areas = stats[1:, cv2.CC_STAT_AREA]\n",
    "    best = 1 + np.argmax(areas)\n",
    "\n",
    "    out = np.zeros_like(ch)\n",
    "    out[labels == best] = 255\n",
    "\n",
    "    # Optional light cleanup to remove tiny edge noise\n",
    "    out = cv2.morphologyEx(\n",
    "        out,\n",
    "        cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2)),\n",
    "        iterations=1\n",
    "    )\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def clean_letter(ch):\n",
    "    bin_ch = (ch > 0).astype(np.uint8)\n",
    "    num, labels, stats, centroids = cv2.connectedComponentsWithStats(bin_ch, 8)\n",
    "\n",
    "    if num <= 1:\n",
    "        return ch\n",
    "\n",
    "    H, W = ch.shape\n",
    "\n",
    "    comps = []\n",
    "    for i in range(1, num):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        cx, cy = centroids[i]\n",
    "\n",
    "        touches_border = (\n",
    "            x == 0 or y == 0 or\n",
    "            x + w == W or y + h == H\n",
    "        )\n",
    "\n",
    "        comps.append({\n",
    "            \"i\": i,\n",
    "            \"x\": x, \"y\": y, \"w\": w, \"h\": h,\n",
    "            \"cx\": cx, \"cy\": cy,\n",
    "            \"area\": area,\n",
    "            \"touch\": touches_border\n",
    "        })\n",
    "\n",
    "    # === MAIN BODY ===\n",
    "    body = max(\n",
    "        [c for c in comps if not c[\"touch\"]],\n",
    "        key=lambda c: c[\"area\"],\n",
    "        default=max(comps, key=lambda c: c[\"area\"])\n",
    "    )\n",
    "\n",
    "    out = np.zeros_like(ch)\n",
    "    out[labels == body[\"i\"]] = 255\n",
    "\n",
    "    body_bottom = body[\"y\"] + body[\"h\"]\n",
    "\n",
    "    # === ATTACH DOTS + TAILS ===\n",
    "    for c in comps:\n",
    "        if c[\"i\"] == body[\"i\"]:\n",
    "            continue\n",
    "\n",
    "        dx = abs(c[\"cx\"] - body[\"cx\"])\n",
    "        dy = c[\"cy\"] - body_bottom\n",
    "\n",
    "        # ----- DOTS -----\n",
    "        if c[\"area\"] < 0.4 * body[\"area\"]:\n",
    "            if dx < 0.7 * W and abs(c[\"cy\"] - body[\"cy\"]) < 0.9 * H:\n",
    "                out[labels == c[\"i\"]] = 255\n",
    "\n",
    "        # ----- TAIL (ج) -----\n",
    "        # below body, vertically aligned, thin stroke\n",
    "        if (\n",
    "            dy > 0 and\n",
    "            dy < 0.6 * H and\n",
    "            dx < 0.25 * W and\n",
    "            c[\"area\"] > 0.12 * body[\"area\"]\n",
    "        ):\n",
    "            out[labels == c[\"i\"]] = 255\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4) CONNECTED COMPONENTS (for initial rough detection)\n",
    "# ============================================================\n",
    "def get_components(bw, min_area=40):\n",
    "    num, lab, stats, _ = cv2.connectedComponentsWithStats((bw > 0).astype(np.uint8), 8)\n",
    "    comps = []\n",
    "    H, W = bw.shape\n",
    "\n",
    "    for i in range(1, num):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area < min_area:\n",
    "            continue\n",
    "        # avoid taking the whole BW as a component\n",
    "        if w > 0.98 * W or h > 0.98 * H:\n",
    "            continue\n",
    "        comps.append([x, y, x + w, y + h, area])\n",
    "    return comps\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5) MERGE DOTS (ج ، ق ، ف) into nearest body\n",
    "# ============================================================\n",
    "def attach_dots(boxes):\n",
    "    big, dots = [], []\n",
    "    for b in boxes:\n",
    "        x0, y0, x1, y1, a = b\n",
    "        if a < 600 and (x1 - x0) < 45 and (y1 - y0) < 45:\n",
    "            dots.append(b)\n",
    "        else:\n",
    "            big.append(b)\n",
    "\n",
    "    for dx0, dy0, dx1, dy1, _ in dots:\n",
    "        dcx = (dx0 + dx1) / 2\n",
    "        dcy = (dy0 + dy1) / 2\n",
    "\n",
    "        best = None\n",
    "        best_d = 1e18\n",
    "        for i, (x0, y0, x1, y1, a) in enumerate(big):\n",
    "            bx = (x0 + x1) / 2\n",
    "            by = (y0 + y1) / 2\n",
    "            d = (dcx - bx) ** 2 + 0.7 * (dcy - by) ** 2\n",
    "            if d < best_d and abs(dcx - bx) < 50:\n",
    "                best_d = d\n",
    "                best = i\n",
    "\n",
    "        if best is not None:\n",
    "            big[best][0] = min(big[best][0], dx0)\n",
    "            big[best][1] = min(big[best][1], dy0)\n",
    "            big[best][2] = max(big[best][2], dx1)\n",
    "            big[best][3] = max(big[best][3], dy1)\n",
    "\n",
    "    return big\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6) CLASSIFY by POSITION (Egyptian plate: digits left, letters right)\n",
    "#    This is much more stable across your samples.\n",
    "# ============================================================\n",
    "def split_digits_letters_by_position(boxes, bw_width):\n",
    "    mid = bw_width / 2.0\n",
    "    digits, letters = [], []\n",
    "\n",
    "    for x0, y0, x1, y1, a in boxes:\n",
    "        cx = (x0 + x1) / 2.0\n",
    "        if cx < mid:\n",
    "            digits.append((x0, y0, x1, y1))\n",
    "        else:\n",
    "            letters.append((x0, y0, x1, y1))\n",
    "\n",
    "    # sort for display / later\n",
    "    digits = sorted(digits, key=lambda b: b[0])                 # L->R\n",
    "    letters = sorted(letters, key=lambda b: b[0], reverse=True) # R->L\n",
    "    return digits, letters\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 7) UNION BOX helper\n",
    "# ============================================================\n",
    "def union_box(boxes):\n",
    "    if not boxes:\n",
    "        return None\n",
    "    x0 = min(b[0] for b in boxes)\n",
    "    y0 = min(b[1] for b in boxes)\n",
    "    x1 = max(b[2] for b in boxes)\n",
    "    y1 = max(b[3] for b in boxes)\n",
    "    return (x0, y0, x1, y1)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 8) SPLIT a GROUP BOX into characters using vertical projection\n",
    "#    - Works for both digits and letters\n",
    "#    - Includes forced-cut fallback for \"سى\" type merges\n",
    "# ============================================================\n",
    "def split_group_into_chars(bw, group_box, min_width_px=10, valley_ratio=0.18, force_cut=True):\n",
    "    x0, y0, x1, y1 = group_box\n",
    "    crop = bw[y0:y1, x0:x1]\n",
    "    H, W = crop.shape\n",
    "\n",
    "    if W < 25:\n",
    "        return [group_box]\n",
    "\n",
    "    proj = np.sum(crop > 0, axis=0).astype(np.float32)\n",
    "\n",
    "    win = max(5, W // 18)\n",
    "    proj_s = np.convolve(proj, np.ones(win) / win, mode=\"same\")\n",
    "\n",
    "    thresh = valley_ratio * (np.percentile(proj_s, 90))\n",
    "    gaps = proj_s < thresh\n",
    "\n",
    "    segments = []\n",
    "    start = None\n",
    "    for i in range(W):\n",
    "        if not gaps[i] and start is None:\n",
    "            start = i\n",
    "        if gaps[i] and start is not None:\n",
    "            if i - start >= min_width_px:\n",
    "                segments.append((start, i))\n",
    "            start = None\n",
    "    if start is not None and (W - start) >= min_width_px:\n",
    "        segments.append((start, W))\n",
    "\n",
    "\n",
    "    \n",
    "    # Normal case: multiple segments found\n",
    "    if len(segments) >= 2:\n",
    "        return [(x0 + s, y0, x0 + e, y1) for (s, e) in segments]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # Fallback: force a cut for wide merged group (like سى)\n",
    "    if force_cut and (W > 1.25 * H):\n",
    "        L = int(0.35 * W)\n",
    "        R = int(0.65 * W)\n",
    "        cut = L + int(np.argmin(proj_s[L:R]))\n",
    "\n",
    "        if 10 < cut < W - 10:\n",
    "            left = (x0, y0, x0 + cut, y1)\n",
    "            right = (x0 + cut, y0, x1, y1)\n",
    "\n",
    "            lp = np.sum(crop[:, :cut] > 0)\n",
    "            rp = np.sum(crop[:, cut:] > 0)\n",
    "            total = np.sum(crop > 0) + 1e-9\n",
    "\n",
    "            if lp > 0.12 * total and rp > 0.12 * total:\n",
    "                return [left, right]\n",
    "\n",
    "    return [group_box]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 9) CHARACTER CLEANING:\n",
    "#    Keep the largest component that DOES NOT touch the crop border.\n",
    "#    This removes the \"frame bars\" and random border blobs.\n",
    "# ============================================================\n",
    "def best_component_smart(ch):\n",
    "    bin_ch = (ch > 0).astype(np.uint8)\n",
    "    num, labels, stats, _ = cv2.connectedComponentsWithStats(bin_ch, 8)\n",
    "\n",
    "    if num <= 1:\n",
    "        return ch\n",
    "\n",
    "    H, W = ch.shape\n",
    "\n",
    "    components = []\n",
    "    for lab in range(1, num):\n",
    "        x, y, w, h, area = stats[lab]\n",
    "        cx = x + w / 2\n",
    "        cy = y + h / 2\n",
    "\n",
    "        # border-touch check (frame / bars)\n",
    "        touches_border = (\n",
    "            x == 0 or y == 0 or\n",
    "            x + w == W or y + h == H\n",
    "        )\n",
    "\n",
    "        components.append({\n",
    "            \"lab\": lab,\n",
    "            \"area\": area,\n",
    "            \"cx\": cx,\n",
    "            \"cy\": cy,\n",
    "            \"touches_border\": touches_border\n",
    "        })\n",
    "\n",
    "    # 1) find MAIN body (largest non-border component)\n",
    "    bodies = [c for c in components if not c[\"touches_border\"]]\n",
    "    if not bodies:\n",
    "        bodies = components\n",
    "\n",
    "    main = max(bodies, key=lambda c: c[\"area\"])\n",
    "\n",
    "    out = np.zeros_like(ch)\n",
    "    out[labels == main[\"lab\"]] = 255\n",
    "\n",
    "    # 2) attach DOTS near main body\n",
    "    for c in components:\n",
    "        if c[\"lab\"] == main[\"lab\"]:\n",
    "            continue\n",
    "\n",
    "        # dot heuristic\n",
    "        if c[\"area\"] < 0.35 * main[\"area\"]:\n",
    "            dx = abs(c[\"cx\"] - main[\"cx\"])\n",
    "            dy = abs(c[\"cy\"] - main[\"cy\"])\n",
    "\n",
    "            if dx < 0.6 * W and dy < 0.8 * H:\n",
    "                out[labels == c[\"lab\"]] = 255\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def tight_crop(ch):\n",
    "    ys, xs = np.where(ch > 0)\n",
    "    if len(xs) == 0:\n",
    "        return ch\n",
    "    return ch[ys.min():ys.max() + 1, xs.min():xs.max() + 1]\n",
    "\n",
    "\n",
    "def normalize_to_square(ch, out_size=64, pad=4):\n",
    "    ch = tight_crop(ch)\n",
    "    h, w = ch.shape\n",
    "    if h == 0 or w == 0:\n",
    "        return np.zeros((out_size, out_size), dtype=np.uint8)\n",
    "\n",
    "    scale = (out_size - 2 * pad) / max(h, w)\n",
    "    nh, nw = max(1, int(h * scale)), max(1, int(w * scale))\n",
    "    ch_rs = cv2.resize(ch, (nw, nh), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    canvas = np.zeros((out_size, out_size), dtype=np.uint8)\n",
    "    y0 = (out_size - nh) // 2\n",
    "    x0 = (out_size - nw) // 2\n",
    "    canvas[y0:y0 + nh, x0:x0 + nw] = ch_rs\n",
    "    return canvas\n",
    "\n",
    "\n",
    "def extract_chars_tight_and_norm(bw, boxes, kind, pad_box=4, out_size=64):\n",
    "    tight_list = []\n",
    "    norm_list = []\n",
    "    H, W = bw.shape\n",
    "\n",
    "    for (x0, y0, x1, y1) in boxes:\n",
    "        x0p = max(0, x0 - pad_box)\n",
    "        y0p = max(0, y0 - pad_box)\n",
    "        x1p = min(W, x1 + pad_box)\n",
    "        y1p = min(H, y1 + pad_box)\n",
    "\n",
    "        ch = bw[y0p:y1p, x0p:x1p].copy()\n",
    "\n",
    "        if kind == \"digit\":\n",
    "            ch2 = clean_digit(ch)\n",
    "        else:\n",
    "            ch2 = clean_letter(ch)\n",
    "\n",
    "        ch2 = tight_crop(ch2)\n",
    "\n",
    "        tight_list.append(ch2)\n",
    "        norm_list.append(normalize_to_square(ch2, out_size=out_size))\n",
    "\n",
    "    return tight_list, norm_list\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 10) MAIN PIPELINE\n",
    "# ============================================================\n",
    "def split_iteratively(bw, boxes, max_iters=3):\n",
    "    out = boxes[:]\n",
    "    for _ in range(max_iters):\n",
    "        new = []\n",
    "        changed = False\n",
    "        for b in out:\n",
    "            parts = split_group_into_chars(bw, b, force_cut=False)\n",
    "            if len(parts) > 1:\n",
    "                changed = True\n",
    "                new.extend(parts)\n",
    "            else:\n",
    "                new.append(b)\n",
    "        out = new\n",
    "        if not changed:\n",
    "            break\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def segment_egypt_plate_chars(img_bgr, debug=True):\n",
    "    plate = extract_plate_roi(img_bgr)\n",
    "    band = crop_character_band(plate)\n",
    "    bw = binarize_clean(band)\n",
    "\n",
    "    comps = get_components(bw, min_area=40)\n",
    "    #comps = attach_dots(comps)\n",
    "    digits_tmp, letters_tmp = split_digits_letters_by_position(comps, bw.shape[1])\n",
    "\n",
    "    letters_tmp = attach_dots([\n",
    "        [b[0], b[1], b[2], b[3], (b[2]-b[0])*(b[3]-b[1])]\n",
    "        for b in letters_tmp\n",
    "    ])\n",
    "\n",
    "\n",
    "    # rebuild comps\n",
    "    comps = [(x0,y0,x1,y1,(x1-x0)*(y1-y0)) for (x0,y0,x1,y1) in digits_tmp] + letters_tmp\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    digits_raw, letters_raw = split_digits_letters_by_position(comps, bw.shape[1])\n",
    "\n",
    "    # BIG BOXES (what you want to show first)\n",
    "    big_digit_box = union_box(digits_raw)\n",
    "    big_letter_box = union_box(letters_raw)\n",
    "\n",
    "    # If one side is empty due to weird thresholding, fallback to using position-based halves\n",
    "    if big_digit_box is None:\n",
    "        big_digit_box = (0, 0, bw.shape[1] // 2, bw.shape[0])\n",
    "    if big_letter_box is None:\n",
    "        big_letter_box = (bw.shape[1] // 2, 0, bw.shape[1], bw.shape[0])\n",
    "\n",
    "    # Split each BIG box into individual characters\n",
    "    digits_boxes = split_iteratively(bw, [big_digit_box])\n",
    "    letters_boxes = split_group_into_chars(bw, big_letter_box, min_width_px=10, valley_ratio=0.18, force_cut=True)\n",
    "\n",
    "    \n",
    "    # Sort for reading\n",
    "    digits_boxes = sorted(digits_boxes, key=lambda b: b[0])                 # L->R\n",
    "    letters_boxes = sorted(letters_boxes, key=lambda b: b[0], reverse=True) # R->L\n",
    "\n",
    "    # Extract tight + normalized\n",
    "    digits_tight, digits_norm = extract_chars_tight_and_norm(\n",
    "        bw, digits_boxes, kind=\"digit\", pad_box=5\n",
    "    )\n",
    "\n",
    "    letters_tight, letters_norm = extract_chars_tight_and_norm(\n",
    "        bw, letters_boxes, kind=\"letter\", pad_box=5\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    if debug:\n",
    "        # View 1: pipeline overview + BIG boxes\n",
    "        vis_groups = cv2.cvtColor(bw, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "        x0, y0, x1, y1 = big_digit_box\n",
    "        cv2.rectangle(vis_groups, (x0, y0), (x1, y1), (255, 0, 0), 3)\n",
    "\n",
    "        x0, y0, x1, y1 = big_letter_box\n",
    "        cv2.rectangle(vis_groups, (x0, y0), (x1, y1), (0, 255, 0), 3)\n",
    "\n",
    "        show_images(\n",
    "            [\n",
    "                cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB),\n",
    "                cv2.cvtColor(plate, cv2.COLOR_BGR2RGB),\n",
    "                cv2.cvtColor(band, cv2.COLOR_BGR2RGB),\n",
    "                bw,\n",
    "                vis_groups,\n",
    "            ],\n",
    "            [\"Input\", \"Plate ROI\", \"Character Band\", \"BW\", \"BIG Boxes: Digits (Blue) / Letters (Green)\"],\n",
    "            figsize_scale=4,\n",
    "        )\n",
    "\n",
    "        # View 2: individual boxes after split\n",
    "        vis_split = cv2.cvtColor(bw, cv2.COLOR_GRAY2RGB)\n",
    "        for x0, y0, x1, y1 in digits_boxes:\n",
    "            cv2.rectangle(vis_split, (x0, y0), (x1, y1), (255, 0, 0), 2)\n",
    "        for x0, y0, x1, y1 in letters_boxes:\n",
    "            cv2.rectangle(vis_split, (x0, y0), (x1, y1), (0, 255, 0), 2)\n",
    "\n",
    "        '''\n",
    "        show_images([vis_split], [\"AFTER SPLIT: Individual Boxes\"], figsize_scale=6)\n",
    "  \n",
    "        # View 3: tight crops (this is what you want visually)\n",
    "        if digits_tight:\n",
    "            show_images(digits_tight, [f\"Digit {i+1}\" for i in range(len(digits_tight))], figsize_scale=4)\n",
    "        if letters_tight:\n",
    "            show_images(letters_tight, [f\"Letter {i+1}\" for i in range(len(letters_tight))], figsize_scale=4)\n",
    "        '''\n",
    "\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # COMBINED ROW:\n",
    "        # [ AFTER SPLIT | Digits... | Letters... ]\n",
    "        # ------------------------------------------------------------\n",
    "\n",
    "        row2_images = []\n",
    "        row2_titles = []\n",
    "\n",
    "        # 1) AFTER SPLIT visualization\n",
    "        row2_images.append(vis_split)\n",
    "        row2_titles.append(\"AFTER SPLIT\")\n",
    "\n",
    "        # 2) Digits (left → right)\n",
    "        for i, d in enumerate(digits_tight):\n",
    "            row2_images.append(d)\n",
    "            row2_titles.append(f\"Digit {i+1}\")\n",
    "\n",
    "        # 3) Letters (right → left already sorted)\n",
    "        for i, l in enumerate(letters_tight):\n",
    "            row2_images.append(l)\n",
    "            row2_titles.append(f\"Letter {i+1}\")\n",
    "\n",
    "        show_images(\n",
    "            row2_images,\n",
    "            row2_titles,\n",
    "            figsize_scale=3\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    # Return both (tight for viewing, norm for recognition)\n",
    "    return {\n",
    "        \"bw\": bw,\n",
    "        \"digits_boxes\": digits_boxes,\n",
    "        \"letters_boxes\": letters_boxes,\n",
    "        \"digits_tight\": digits_tight,\n",
    "        \"letters_tight\": letters_tight,\n",
    "        \"digits_norm64\": digits_norm,\n",
    "        \"letters_norm64\": letters_norm,\n",
    "    }\n",
    "\n",
    "\n",
    "# =========================\n",
    "# RUN (single sample)\n",
    "# =========================\n",
    "# img_bgr = cropped_Plate4   # example\n",
    "# out = segment_egypt_plate_chars(img_bgr, debug=True)\n",
    "\n",
    "# =========================\n",
    "# RUN (all samples)\n",
    "# =========================\n",
    "# for i in range(1, 40):\n",
    "#     name = f\"cropped_Plate{i}\"\n",
    "#     if name in globals():\n",
    "#         print(\"====\", name, \"====\")\n",
    "#         segment_egypt_plate_chars(globals()[name], debug=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#images = [cropped_Plate4, cropped_Plate7, cropped_Plate8, cropped_Plate10, cropped_Plate12, cropped_Plate5, cropped_Plate9, cropped_Plate11]\n",
    "#images = [cropped_Plate1, cropped_Plate2, cropped_Plate3, cropped_Plate4, cropped_Plate5, cropped_Plate6, cropped_Plate7, cropped_Plate8, cropped_Plate9, cropped_Plate10, cropped_Plate11, cropped_Plate12, cropped_Plate13, cropped_Plate14, cropped_Plate15, cropped_Plate16, cropped_Plate17, cropped_Plate18, cropped_Plate19, cropped_Plate20, cropped_Plate21, cropped_Plate22, cropped_Plate23, cropped_Plate24, cropped_Plate25, cropped_Plate26, cropped_Plate27, cropped_Plate28, cropped_Plate29, cropped_Plate30, cropped_Plate31, cropped_Plate32, cropped_Plate33, cropped_Plate34, cropped_Plate37, cropped_Plate38, cropped_Plate39]\n",
    "\n",
    "\n",
    "images = [\n",
    "    globals()[f\"cropped_Plate{i}\"]\n",
    "    for i in range(1, 40)\n",
    "    if f\"cropped_Plate{i}\" in globals()\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i, img in enumerate(images, start=1):\n",
    "    print(f\"==== PLATE {i} ====\")\n",
    "    segment_egypt_plate_chars(img, debug=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =========================\n",
    "# RUN\n",
    "# =========================\n",
    "####img_bgr = cropped_Plate12   # change\n",
    "\n",
    "#work: 4, 7, 8, 10, 12\n",
    "#dont: 5, 9, 11\n",
    "#digits, letters = segment_egypt_plate_chars(img_bgr, debug=True)\n",
    "####out = segment_egypt_plate_chars(img_bgr, debug=True)\n",
    "\n",
    "# Run all samples if you have cropped_Plate1..cropped_Plate39 in globals()\n",
    "# for i in range(1, 40):\n",
    "#     name = f\"cropped_Plate{i}\"\n",
    "#     if name in globals():\n",
    "#         print(\"====\", name, \"====\")\n",
    "#         segment_egypt_plate_chars(globals()[name], debug=False)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "FORTNITE SEGMENT\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac737b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MAAW NEW SEG\n",
    "'''\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.measure import label, regionprops\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "def extract_plate(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, 80, 200)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7,7))\n",
    "    closed = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    cnts, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnt = max(cnts, key=cv2.contourArea)\n",
    "\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "    return img[y:y+h, x:x+w]\n",
    "\n",
    "\n",
    "def crop_digits_letters_region(plate):\n",
    "    h, w = plate.shape[:2]\n",
    "\n",
    "    # Egyptian plate layout: bottom ~65% contains digits + letters\n",
    "    y0 = int(0.35 * h)\n",
    "    y1 = int(0.95 * h)\n",
    "\n",
    "    return plate[y0:y1, :]\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "def binarize_for_split(region_bgr):\n",
    "    gray = cv2.cvtColor(region_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    _, bw = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    bw = cv2.morphologyEx(bw, cv2.MORPH_OPEN,\n",
    "                          cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3)))\n",
    "    return bw\n",
    "\n",
    "\n",
    "def split_digits_letters(region_bgr):\n",
    "    H, W = region_bgr.shape[:2]\n",
    "    bw = binarize_for_split(region_bgr)\n",
    "\n",
    "    # --- 1) Detect vertical separator line (strongest vertical structure) ---\n",
    "    # Kernel عمودي طويل يلقط الخط الفاصل\n",
    "    kH = max(15, int(0.7 * H))\n",
    "    vert_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, kH))\n",
    "    vert = cv2.morphologyEx(bw, cv2.MORPH_OPEN, vert_kernel)\n",
    "\n",
    "    col_strength = np.sum(vert > 0, axis=0).astype(np.float32)\n",
    "\n",
    "    # نبحث قريب من منتصف اللوحة فقط\n",
    "    left = int(0.30 * W)\n",
    "    right = int(0.80 * W)\n",
    "\n",
    "    x_sep = left + int(np.argmax(col_strength[left:right]))\n",
    "    sep_strength = col_strength[x_sep]\n",
    "\n",
    "    # --- 2) Fallback: valley split (لو مفيش خط فاصل واضح) ---\n",
    "    if sep_strength < 0.20 * H:  # لو الخط ضعيف\n",
    "        col_sum = np.sum(bw > 0, axis=0).astype(np.float32)\n",
    "        # smoothing\n",
    "        win = max(15, W // 30)\n",
    "        col_sum_s = np.convolve(col_sum, np.ones(win)/win, mode=\"same\")\n",
    "\n",
    "        left = int(0.35 * W)\n",
    "        right = int(0.75 * W)\n",
    "        x_sep = left + int(np.argmin(col_sum_s[left:right]))\n",
    "\n",
    "    # قص حوالين الفاصل عشان ما يدخلش مع أي جانب\n",
    "    pad = 4\n",
    "    x_sep = max(10, min(W - 10, x_sep))\n",
    "\n",
    "    digits = region_bgr[:, :max(0, x_sep - pad)]\n",
    "    letters = region_bgr[:, min(W, x_sep + pad):]\n",
    "    return digits, letters\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def touches_border(x0, y0, x1, y1, W, H, margin=2):\n",
    "    return (x0 <= margin) or (y0 <= margin) or (x1 >= W - margin) or (y1 >= H - margin)\n",
    "\n",
    "#11\n",
    "def binarize(region_bgr):\n",
    "    gray = cv2.cvtColor(region_bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Contrast boost WITHOUT exploding noise\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    gray = clahe.apply(gray)\n",
    "\n",
    "    # Median blur kills texture noise but keeps strokes\n",
    "    gray = cv2.medianBlur(gray, 5)\n",
    "\n",
    "    # Global threshold (stable for plates)\n",
    "    _, bw = cv2.threshold(\n",
    "        gray, 0, 255,\n",
    "        cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU\n",
    "    )\n",
    "\n",
    "    # Remove pepper noise only\n",
    "    bw = cv2.morphologyEx(\n",
    "        bw, cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "    )\n",
    "\n",
    "    return bw\n",
    "\n",
    "\n",
    "def binarize_letters(region_bgr):\n",
    "    gray = cv2.cvtColor(region_bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # mild contrast boost (don't overdo it)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    gray = clahe.apply(gray)\n",
    "\n",
    "    # small median (3) keeps dots better than 5\n",
    "    gray = cv2.medianBlur(gray, 3)\n",
    "\n",
    "    # OTSU is more stable than adaptive here\n",
    "    bw = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    return bw\n",
    "\n",
    "\n",
    "def build_group_mask_letters(bw):\n",
    "    # specifically tuned to reconnect ج tail\n",
    "    bw_g = cv2.morphologyEx(\n",
    "        bw, cv2.MORPH_CLOSE,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (5,3))\n",
    "    )\n",
    "    bw_g = cv2.dilate(\n",
    "        bw_g,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (3,5)),\n",
    "        iterations=1\n",
    "    )\n",
    "    return bw_g\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def merge_close_letter_boxes(boxes, H):\n",
    "    \"\"\"\n",
    "    Merge boxes that are likely parts of the same Arabic letter (fixes ج split).\n",
    "    Rule: merge if x-overlap is decent OR x-gap small, and y ranges are close/overlapping.\n",
    "    \"\"\"\n",
    "    if not boxes:\n",
    "        return boxes\n",
    "\n",
    "    boxes = sorted(boxes, key=lambda b: b[0])\n",
    "    merged = [list(boxes[0])]\n",
    "\n",
    "    for x0,y0,x1,y1 in boxes[1:]:\n",
    "        px0,py0,px1,py1 = merged[-1]\n",
    "\n",
    "        # overlaps / gaps\n",
    "        x_overlap = max(0, min(px1, x1) - max(px0, x0))\n",
    "        x_gap = max(0, x0 - px1)\n",
    "\n",
    "        # vertical relation\n",
    "        y_overlap = max(0, min(py1, y1) - max(py0, y0))\n",
    "        y_gap = max(0, max(y0 - py1, py0 - y1))\n",
    "\n",
    "        # thresholds (tuned for plate letters)\n",
    "        close_in_x = (x_overlap > 0) or (x_gap < 0.06 * (px1 - px0 + x1 - x0))\n",
    "        close_in_y = (y_overlap > 0) or (y_gap < 0.18 * H)\n",
    "\n",
    "        if close_in_x and close_in_y:\n",
    "            merged[-1][0] = min(px0, x0)\n",
    "            merged[-1][1] = min(py0, y0)\n",
    "            merged[-1][2] = max(px1, x1)\n",
    "            merged[-1][3] = max(py1, y1)\n",
    "        else:\n",
    "            merged.append([x0,y0,x1,y1])\n",
    "\n",
    "    return [tuple(b) for b in merged]\n",
    "\n",
    "\n",
    "def find_letter_boxes_and_dots(bw, bw_group):\n",
    "    H, W = bw.shape\n",
    "    labeled = label(bw_group)\n",
    "\n",
    "    big_boxes = []\n",
    "    candidate_small = []  # dot candidates\n",
    "\n",
    "    for r in regionprops(labeled):\n",
    "        y0, x0, y1, x1 = r.bbox\n",
    "        h = y1 - y0\n",
    "        w = x1 - x0\n",
    "        area = r.area\n",
    "\n",
    "        if touches_border(x0, y0, x1, y1, W, H, margin=2):\n",
    "            continue\n",
    "\n",
    "        # DOTS: keep them generous (so ف dot doesn't vanish)\n",
    "        if 20 <= area <= 400 and h <= 0.35 * H and w <= 0.35 * W:\n",
    "            # roughly dot-ish (avoid long strokes)\n",
    "            ar = w / max(h, 1)\n",
    "            if 0.4 <= ar <= 2.5:\n",
    "                candidate_small.append((x0, y0, x1, y1))\n",
    "                continue\n",
    "\n",
    "        # LETTER BODY (relaxed so we don't drop ج)\n",
    "        if area < 120:\n",
    "            continue\n",
    "        if h < 0.16 * H:\n",
    "            continue\n",
    "        if w < 0.02 * W:\n",
    "            continue\n",
    "\n",
    "        big_boxes.append((x0, y0, x1, y1))\n",
    "\n",
    "    big_boxes = merge_close_letter_boxes(big_boxes, H)\n",
    "    big_boxes = sorted(big_boxes, key=lambda b: b[0])\n",
    "\n",
    "    return big_boxes, candidate_small\n",
    "\n",
    "def recover_missing_fa(letter_boxes, dot_boxes, H):\n",
    "    \"\"\"\n",
    "    If a dot exists with no nearby letter body,\n",
    "    create a synthetic body box under it (for ف).\n",
    "    \"\"\"\n",
    "    recovered = list(letter_boxes)\n",
    "\n",
    "    for dx0, dy0, dx1, dy1 in dot_boxes:\n",
    "        dcy = 0.5 * (dy0 + dy1)\n",
    "\n",
    "        attached = False\n",
    "        for x0,y0,x1,y1 in letter_boxes:\n",
    "            if x0 - 10 <= (dx0+dx1)/2 <= x1 + 10:\n",
    "                attached = True\n",
    "                break\n",
    "\n",
    "        if not attached:\n",
    "            # Create a virtual body under the dot\n",
    "            body_h = int(0.35 * H)\n",
    "            recovered.append((\n",
    "                dx0 - 10,\n",
    "                int(dcy),\n",
    "                dx1 + 10,\n",
    "                min(H, int(dcy + body_h))\n",
    "            ))\n",
    "\n",
    "    return recovered\n",
    "\n",
    "\n",
    "def attach_dots_to_boxes(letter_boxes, dot_boxes):\n",
    "    merged = [list(b) for b in letter_boxes]\n",
    "\n",
    "    for dx0, dy0, dx1, dy1 in dot_boxes:\n",
    "        dcx = 0.5 * (dx0 + dx1)\n",
    "        dcy = 0.5 * (dy0 + dy1)\n",
    "\n",
    "        best_i = None\n",
    "        best_score = 1e18\n",
    "\n",
    "        for i, (x0,y0,x1,y1) in enumerate(merged):\n",
    "            # dot should be horizontally near the letter\n",
    "            if dcx < x0 - 15 or dcx > x1 + 15:\n",
    "                continue\n",
    "\n",
    "            # prefer dots above upper-half of the letter (ف/ق), but don't hard-reject\n",
    "            # score: distance with extra penalty if dot is too low\n",
    "            bx = 0.5 * (x0 + x1)\n",
    "            by = 0.5 * (y0 + y1)\n",
    "\n",
    "            penalty_low = 0.0\n",
    "            if dcy > by:  # dot below center is unlikely\n",
    "                penalty_low = 2000.0\n",
    "\n",
    "            score = (dcx - bx)**2 + 0.7*(dcy - by)**2 + penalty_low\n",
    "\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_i = i\n",
    "\n",
    "        if best_i is not None:\n",
    "            merged[best_i][0] = min(merged[best_i][0], dx0)\n",
    "            merged[best_i][1] = min(merged[best_i][1], dy0)\n",
    "            merged[best_i][2] = max(merged[best_i][2], dx1)\n",
    "            merged[best_i][3] = max(merged[best_i][3], dy1)\n",
    "\n",
    "    return [tuple(b) for b in merged]\n",
    "\n",
    "\n",
    "def get_components_letters(region_bgr):\n",
    "    bw = binarize_letters(region_bgr)          # extraction mask (keeps holes/dots)\n",
    "    bw_group = build_group_mask_letters(bw)    # grouping mask (connects ج)\n",
    "\n",
    "    big_boxes, dot_boxes = find_letter_boxes_and_dots(bw, bw_group)\n",
    "    \n",
    "    boxes = attach_dots_to_boxes(big_boxes, dot_boxes)\n",
    "    boxes = recover_missing_fa(boxes, dot_boxes, bw.shape[0])\n",
    "\n",
    "    boxes = merge_close_letter_boxes(sorted(boxes, key=lambda b: b[0]), bw.shape[0])\n",
    "    boxes = sorted(boxes, key=lambda b: b[0])\n",
    "\n",
    "    return bw, boxes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_letter_boxes_and_dots(bw):\n",
    "    H, W = bw.shape\n",
    "\n",
    "    # group mask: connect broken pieces a bit, but don’t destroy holes in the ORIGINAL bw\n",
    "    bw_group = cv2.dilate(\n",
    "        bw, cv2.getStructuringElement(cv2.MORPH_RECT, (3, 5)), iterations=1\n",
    "    )\n",
    "    # small close to reconnect weak gaps (helps ج) but still mild\n",
    "    bw_group = cv2.morphologyEx(\n",
    "        bw_group, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    )\n",
    "\n",
    "    labeled = label(bw_group)\n",
    "\n",
    "    big_boxes = []\n",
    "    small_boxes = []  # dots / small fragments\n",
    "\n",
    "    for r in regionprops(labeled):\n",
    "        y0, x0, y1, x1 = r.bbox\n",
    "        h = y1 - y0\n",
    "        w = x1 - x0\n",
    "        area = r.area\n",
    "\n",
    "        if touches_border(x0, y0, x1, y1, W, H, margin=2):\n",
    "            continue\n",
    "\n",
    "        # classify small components (dots)\n",
    "        is_dot = (\n",
    "            40 < area < 180 and           # real dots only\n",
    "            h < 0.22 * H and\n",
    "            w < 0.22 * W and\n",
    "            0.6 < (w / max(h, 1)) < 1.6   # circular-ish\n",
    "        )\n",
    "\n",
    "\n",
    "        if is_dot:\n",
    "            small_boxes.append((x0, y0, x1, y1))\n",
    "            continue\n",
    "\n",
    "\n",
    "        # relaxed constraints for letters (so ج doesn’t get chopped)\n",
    "        if area < 120:\n",
    "            continue\n",
    "        if h < 0.18 * H:\n",
    "            continue\n",
    "        if w < 0.02 * W:\n",
    "            continue\n",
    "\n",
    "        big_boxes.append((x0, y0, x1, y1))\n",
    "\n",
    "    big_boxes = sorted(big_boxes, key=lambda b: b[0])\n",
    "    return big_boxes, small_boxes\n",
    "\n",
    "\n",
    "\n",
    "def attach_dots_to_letter_boxes(big_boxes, small_boxes):\n",
    "    merged = [list(b) for b in big_boxes]\n",
    "\n",
    "    for sx0, sy0, sx1, sy1 in small_boxes:\n",
    "        scx = 0.5 * (sx0 + sx1)\n",
    "        scy = 0.5 * (sy0 + sy1)\n",
    "\n",
    "        for i, (x0, y0, x1, y1) in enumerate(merged):\n",
    "            # Dot must be horizontally inside letter\n",
    "            if not (x0 - 10 <= scx <= x1 + 10):\n",
    "                continue\n",
    "\n",
    "            # Dot must be ABOVE letter body (ف, ق)\n",
    "            if sy1 > y0:\n",
    "                continue\n",
    "\n",
    "            # Attach dot\n",
    "            merged[i][0] = min(merged[i][0], sx0)\n",
    "            merged[i][1] = min(merged[i][1], sy0)\n",
    "            merged[i][2] = max(merged[i][2], sx1)\n",
    "            merged[i][3] = max(merged[i][3], sy1)\n",
    "            break\n",
    "\n",
    "    return [tuple(b) for b in merged]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_components(region_bgr, kind=\"digits\"):\n",
    "    if kind == \"digits\":\n",
    "        # Preserve thin strokes (important for ٦)\n",
    "        gray = cv2.cvtColor(region_bgr, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.medianBlur(gray, 3)   # NOT Gaussian\n",
    "        _, bw = cv2.threshold(\n",
    "            gray, 0, 255,\n",
    "            cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU\n",
    "        )\n",
    "    else:\n",
    "        bw = binarize(region_bgr)\n",
    "\n",
    "    H, W = bw.shape\n",
    "\n",
    "    # --- mask للتجميع فقط ---\n",
    "    if kind == \"letters\":\n",
    "        big_boxes, small_boxes = get_letter_boxes_and_dots(bw)\n",
    "        boxes = attach_dots_to_letter_boxes(big_boxes, small_boxes)\n",
    "        boxes = sorted(boxes, key=lambda b: b[0])\n",
    "        return bw, boxes\n",
    "    else:\n",
    "        # digits: ممكن close صغير جدًا لو فيه انقطاع، أو سيبه bw_group=bw\n",
    "        bw_group = cv2.morphologyEx(\n",
    "            bw, cv2.MORPH_CLOSE,\n",
    "            cv2.getStructuringElement(cv2.MORPH_RECT, (3,5))\n",
    "        )\n",
    "\n",
    "        min_area = 90        # was too aggressive\n",
    "        min_h_ratio = 0.22   # allow shorter digits\n",
    "        min_w_ratio = 0.02\n",
    "        min_aspect = 0.07\n",
    "\n",
    "    labeled = label(bw_group)\n",
    "    boxes = []\n",
    "\n",
    "    for r in regionprops(labeled):\n",
    "        if r.area < min_area:\n",
    "            continue\n",
    "\n",
    "        y0, x0, y1, x1 = r.bbox\n",
    "        h = y1 - y0\n",
    "        w = x1 - x0\n",
    "\n",
    "        # تجاهل أي شيء بيلمس الإطار (زي إطار اللوحة)\n",
    "        if touches_border(x0, y0, x1, y1, W, H, margin=2):\n",
    "            continue\n",
    "\n",
    "        if h < min_h_ratio * H:\n",
    "            continue\n",
    "        if w < min_w_ratio * W:\n",
    "            continue\n",
    "\n",
    "        aspect = w / float(h)\n",
    "        if aspect < min_aspect:\n",
    "            continue\n",
    "\n",
    "        boxes.append((x0, y0, x1, y1))\n",
    "\n",
    "    boxes = sorted(boxes, key=lambda b: b[0])\n",
    "\n",
    "    # رجّع الاتنين: الأصلي + البوكسات\n",
    "    return bw, boxes\n",
    "\n",
    "\n",
    "def extract_chars_from_mask(mask_bw, boxes, reverse=False, pad=2):\n",
    "    # نقص من الـ mask الأصلي (مش bw_group) علشان holes تفضل موجودة\n",
    "    boxes = sorted(boxes, key=lambda b: b[0], reverse=reverse)\n",
    "    chars = []\n",
    "    H, W = mask_bw.shape\n",
    "\n",
    "    for x0,y0,x1,y1 in boxes:\n",
    "        x0 = max(0, x0 - pad); y0 = max(0, y0 - pad)\n",
    "        x1 = min(W, x1 + pad); y1 = min(H, y1 + pad)\n",
    "        chars.append(mask_bw[y0:y1, x0:x1])\n",
    "\n",
    "    return chars\n",
    "\n",
    "#11\n",
    "\n",
    "\n",
    "def draw_boxes(mask, boxes):\n",
    "    out = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n",
    "    for x0,y0,x1,y1 in boxes:\n",
    "        cv2.rectangle(out,(x0,y0),(x1,y1),(255,0,0),2)\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def trim_borders(img, px=6):\n",
    "    h, w = img.shape[:2]\n",
    "    return img[px:h-px, px:w-px]\n",
    "\n",
    "\n",
    "\n",
    "#img_bgr = cropped_Plate1\n",
    "#img_bgr = cropped_Plate2\n",
    "#img_bgr = cropped_Plate3\n",
    "#img_bgr = cropped_Plate4 #DONE\n",
    "#img_bgr = cropped_Plate5\n",
    "#img_bgr = cropped_Plate6\n",
    "#img_bgr = cropped_Plate7\n",
    "#img_bgr = cropped_Plate8\n",
    "#img_bgr = cropped_Plate9\n",
    "#img_bgr = cropped_Plate10\n",
    "#img_bgr = cropped_Plate11\n",
    "#img_bgr = cropped_Plate12\n",
    "#img_bgr = cropped_Plate13\n",
    "#img_bgr = cropped_Plate14\n",
    "#img_bgr = cropped_Plate15\n",
    "#img_bgr = cropped_Plate16\n",
    "#img_bgr = cropped_Plate17\n",
    "#img_bgr = cropped_Plate18\n",
    "#img_bgr = cropped_Plate19\n",
    "#img_bgr = cropped_Plate20\n",
    "#img_bgr = cropped_Plate21\n",
    "#img_bgr = cropped_Plate22\n",
    "#img_bgr = cropped_Plate23\n",
    "#img_bgr = cropped_Plate24\n",
    "#img_bgr = cropped_Plate25\n",
    "#img_bgr = cropped_Plate26\n",
    "#img_bgr = cropped_Plate27\n",
    "#img_bgr = cropped_Plate28\n",
    "#img_bgr = cropped_Plate29\n",
    "#img_bgr = cropped_Plate30\n",
    "#img_bgr = cropped_Plate31\n",
    "#img_bgr = cropped_Plate32\n",
    "#img_bgr = cropped_Plate33\n",
    "#img_bgr = cropped_Plate34\n",
    "#img_bgr = cropped_Plate37\n",
    "#img_bgr = cropped_Plate38\n",
    "#img_bgr = cropped_Plate39\n",
    "\n",
    "##########################################LOOOOOOOOOOP\n",
    "\n",
    "\n",
    "def process_one_plate(img_bgr, plate_name=\"plate\", save=True, show=True):\n",
    "    \"\"\"\n",
    "    Process ONE Egyptian plate image end-to-end\n",
    "    \"\"\"\n",
    "\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    plate = extract_plate(img_bgr)\n",
    "\n",
    "    dl_region = crop_digits_letters_region(plate)\n",
    "    dl_region = trim_borders(dl_region, px=4)\n",
    "\n",
    "    # Split digits / letters\n",
    "    digits_region, letters_region = split_digits_letters(dl_region)\n",
    "\n",
    "    # Extract components\n",
    "    d_mask, d_boxes = get_components(digits_region, kind=\"digits\")\n",
    "    l_mask, l_boxes = get_components_letters(letters_region)\n",
    "\n",
    "    # Keep at most 4 digits\n",
    "    if len(d_boxes) > 4:\n",
    "        d_boxes = sorted(\n",
    "            d_boxes,\n",
    "            key=lambda b: (b[2]-b[0])*(b[3]-b[1]),\n",
    "            reverse=True\n",
    "        )[:4]\n",
    "        d_boxes = sorted(d_boxes, key=lambda b: b[0])\n",
    "\n",
    "    # Keep at most 3 letters\n",
    "    if len(l_boxes) > 3:\n",
    "        l_boxes = sorted(\n",
    "            l_boxes,\n",
    "            key=lambda b: (b[2]-b[0])*(b[3]-b[1]),\n",
    "            reverse=True\n",
    "        )[:3]\n",
    "        l_boxes = sorted(l_boxes, key=lambda b: b[0])\n",
    "\n",
    "    digits  = extract_chars_from_mask(d_mask, d_boxes, reverse=False)\n",
    "    letters = extract_chars_from_mask(l_mask, l_boxes, reverse=True)\n",
    "\n",
    "    # ---------- SAVE ----------\n",
    "    if save:\n",
    "        BASE_OUT_DIR = \"output_chars\"\n",
    "        DIGITS_DIR = os.path.join(BASE_OUT_DIR, \"digits\", plate_name)\n",
    "        LETTERS_DIR = os.path.join(BASE_OUT_DIR, \"letters\", plate_name)\n",
    "\n",
    "        os.makedirs(DIGITS_DIR, exist_ok=True)\n",
    "        os.makedirs(LETTERS_DIR, exist_ok=True)\n",
    "\n",
    "        TARGET_SIZE = (150, 150)\n",
    "\n",
    "        for i, d in enumerate(digits):\n",
    "            d_resized = cv2.resize(d, TARGET_SIZE, interpolation=cv2.INTER_AREA)\n",
    "            cv2.imwrite(os.path.join(DIGITS_DIR, f\"digit_{i}.png\"), d_resized)\n",
    "\n",
    "        for i, l in enumerate(letters):\n",
    "            l_resized = cv2.resize(l, TARGET_SIZE, interpolation=cv2.INTER_AREA)\n",
    "            cv2.imwrite(os.path.join(LETTERS_DIR, f\"letter_{i}.png\"), l_resized)\n",
    "\n",
    "    # ---------- VISUALIZE ----------\n",
    "    if show:\n",
    "        d_boxes_img = draw_boxes(d_mask, d_boxes)\n",
    "        l_boxes_img = draw_boxes(l_mask, l_boxes)\n",
    "\n",
    "        show_images(\n",
    "            [\n",
    "                img_rgb,\n",
    "                cv2.cvtColor(plate, cv2.COLOR_BGR2RGB),\n",
    "                cv2.cvtColor(dl_region, cv2.COLOR_BGR2RGB),\n",
    "                cv2.cvtColor(digits_region, cv2.COLOR_BGR2RGB),\n",
    "                cv2.cvtColor(letters_region, cv2.COLOR_BGR2RGB),\n",
    "            ],\n",
    "            [\"Original\", \"Plate Crop\", \"Digits+Letters\", \"Digits Region\", \"Letters Region\"]\n",
    "        )\n",
    "\n",
    "        show_images([d_mask, l_mask], [\"Digits Mask\", \"Letters Mask\"])\n",
    "        show_images([d_boxes_img, l_boxes_img], [\"Digits Boxes\", \"Letters Boxes\"])\n",
    "\n",
    "        if digits:\n",
    "            show_images(digits, [f\"Digit {i+1}\" for i in range(len(digits))])\n",
    "        if letters:\n",
    "            show_images(letters, [f\"Letter {i+1}\" for i in range(len(letters))])\n",
    "\n",
    "    return {\n",
    "        \"digits\": digits,\n",
    "        \"letters\": letters,\n",
    "        \"d_boxes\": d_boxes,\n",
    "        \"l_boxes\": l_boxes\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "images = [\n",
    "    globals()[f\"cropped_Plate{i}\"]\n",
    "    for i in range(1, 40)\n",
    "    if f\"cropped_Plate{i}\" in globals()\n",
    "]\n",
    "\n",
    "for i, img in enumerate(images, start=1):\n",
    "    print(f\"\\n===== Processing Plate {i} =====\")\n",
    "    process_one_plate(\n",
    "        img,\n",
    "        plate_name=f\"plate_{i}\",\n",
    "        save=True,\n",
    "        show=True\n",
    "    )\n",
    "\n",
    "#############################################LOOOOOOOOOOOOP\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''#REMOVE TO FIX\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plate = extract_plate(img_bgr)\n",
    "\n",
    "dl_region = crop_digits_letters_region(plate)\n",
    "dl_region = trim_borders(dl_region, px=4)\n",
    "\n",
    "# FINAL robust split\n",
    "digits_region, letters_region = split_digits_letters(dl_region)\n",
    "\n",
    "d_mask, d_boxes = get_components(digits_region, kind=\"digits\")\n",
    "l_mask, l_boxes = get_components_letters(letters_region)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Keep at most 4 digits: choose by area (largest blobs)\n",
    "if len(d_boxes) > 4:\n",
    "    d_boxes = sorted(d_boxes, key=lambda b: (b[2]-b[0])*(b[3]-b[1]), reverse=True)[:4]\n",
    "    d_boxes = sorted(d_boxes, key=lambda b: b[0])\n",
    "\n",
    "# Keep at most 3 letters: choose by area (largest blobs)\n",
    "if len(l_boxes) > 3:\n",
    "    l_boxes = sorted(l_boxes, key=lambda b: (b[2]-b[0])*(b[3]-b[1]), reverse=True)[:3]\n",
    "    l_boxes = sorted(l_boxes, key=lambda b: b[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "BASE_OUT_DIR = \"output_chars\"\n",
    "#BASE_OUT_DIR = \"Image-Processing-Project\"\n",
    "DIGITS_DIR = os.path.join(BASE_OUT_DIR, \"digits\")\n",
    "LETTERS_DIR = os.path.join(BASE_OUT_DIR, \"letters\")\n",
    "\n",
    "os.makedirs(DIGITS_DIR, exist_ok=True)\n",
    "os.makedirs(LETTERS_DIR, exist_ok=True)\n",
    "\n",
    "def clear_old_files(folder, pattern):\n",
    "    for f in glob.glob(os.path.join(folder, pattern)):\n",
    "        os.remove(f)\n",
    "\n",
    "# Clear previous results\n",
    "clear_old_files(DIGITS_DIR, \"digit_*.png\")\n",
    "clear_old_files(LETTERS_DIR, \"letter_*.png\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "digits  = extract_chars_from_mask(d_mask, d_boxes, reverse=False)\n",
    "letters = extract_chars_from_mask(l_mask, l_boxes, reverse=True)\n",
    "\n",
    "\n",
    "TARGET_SIZE = (150, 150)\n",
    "\n",
    "# Save digits\n",
    "for i, d in enumerate(digits):\n",
    "    d_resized = cv2.resize(d, TARGET_SIZE, interpolation=cv2.INTER_AREA)\n",
    "    save_path = os.path.join(DIGITS_DIR, f\"digit_{i}.png\")\n",
    "    cv2.imwrite(save_path, d_resized)\n",
    "\n",
    "# Save letters\n",
    "for i, l in enumerate(letters):\n",
    "    l_resized = cv2.resize(l, TARGET_SIZE, interpolation=cv2.INTER_AREA)\n",
    "    save_path = os.path.join(LETTERS_DIR, f\"letter_{i}.png\")\n",
    "    cv2.imwrite(save_path, l_resized)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "d_boxes_img = draw_boxes(d_mask, d_boxes)\n",
    "l_boxes_img = draw_boxes(l_mask, l_boxes)\n",
    "\n",
    "\n",
    "show_images(\n",
    "    [\n",
    "        img_rgb,\n",
    "        cv2.cvtColor(plate, cv2.COLOR_BGR2RGB),\n",
    "        cv2.cvtColor(dl_region, cv2.COLOR_BGR2RGB),\n",
    "        cv2.cvtColor(digits_region, cv2.COLOR_BGR2RGB),\n",
    "        cv2.cvtColor(letters_region, cv2.COLOR_BGR2RGB)\n",
    "    ],\n",
    "    [\"Original\", \"Plate Crop\", \"Digits+Letters\", \"Digits Region\", \"Letters Region\"]\n",
    ")\n",
    "\n",
    "\n",
    "show_images([d_mask, l_mask], [\"Digits Mask\", \"Letters Mask\"])\n",
    "show_images([d_boxes_img, l_boxes_img], [\"Digits Boxes\", \"Letters Boxes\"])\n",
    "\n",
    "show_images(digits, [f\"Digit {i+1}\" for i in range(len(digits))])\n",
    "show_images(letters, [f\"Letter {i+1}\" for i in range(len(letters))])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''#REMOVE TO FIX\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "MAAW NEW SEG\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f156149",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MAAW SEGMENTATION\n",
    "'''\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray, rgba2rgb\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.morphology import (\n",
    "    remove_small_holes,\n",
    "    remove_small_objects,\n",
    "    binary_closing,\n",
    "    square,\n",
    ")\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.transform import resize\n",
    "from skimage.color import gray2rgb\n",
    "\n",
    "\n",
    "def crop_bottom(img, top_ratio=0.40):\n",
    "    h, w = img.shape[:2]\n",
    "    return img[int(h * top_ratio):, :]\n",
    "\n",
    "\n",
    "def split_digits_letters(bottom):\n",
    "    h, w = bottom.shape[:2]\n",
    "    mid = w // 2\n",
    "    return bottom[:, :mid], bottom[:, mid:]\n",
    "\n",
    "\n",
    "def get_mask(region):\n",
    "    gray = rgb2gray(region)\n",
    "\n",
    "    T = threshold_otsu(gray)\n",
    "    mask = gray < T\n",
    "\n",
    "    mask = remove_small_objects(mask, 25)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def touches_border(r0, c0, r1, c1, H, W, margin_ratio=0.005):\n",
    "    mr = int(margin_ratio * H)\n",
    "    mc = int(margin_ratio * W)\n",
    "\n",
    "    if r0 <= mr: return True        # top\n",
    "    if c0 <= mc: return True        # left\n",
    "    if r1 >= H - mr: return True    # bottom\n",
    "    if c1 >= W - mc: return True    # right\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "def extract_digits(digits_region, max_chars=4, debug=False):\n",
    "    H0, W0 = digits_region.shape[:2]\n",
    "    border_ratio = 0.04\n",
    "    by = int(border_ratio * H0)\n",
    "    bx = int(border_ratio * W0)\n",
    "    sub = digits_region[by:H0 - by, bx:W0 - bx]\n",
    "    \n",
    "    mask = get_mask(sub)\n",
    "    H, W = mask.shape\n",
    "    \n",
    "    def remove_frame_components(mask):\n",
    "        H, W = mask.shape\n",
    "        lbl = label(mask)\n",
    "\n",
    "        for p in regionprops(lbl):\n",
    "            r0, c0, r1, c1 = p.bbox\n",
    "            h = r1 - r0\n",
    "            w = c1 - c0\n",
    "\n",
    "            wr = w / (W + 1e-6)\n",
    "            hr = h / (H + 1e-6)\n",
    "\n",
    "            near_edge = (r0 < 0.20 * H) or (r1 > 0.80 * H) #very wide, thin, near top or bottom\n",
    "\n",
    "            if near_edge and wr > 0.75 and hr < 0.12:\n",
    "                mask[lbl == p.label] = 0\n",
    "\n",
    "        return mask\n",
    "\n",
    "    mask = remove_frame_components(mask)\n",
    "    \n",
    "    def touches_top_or_bottom(r0, r1, H, margin=2):\n",
    "        return r0 <= margin or r1 >= H - margin\n",
    "\n",
    "    def is_horizontal_frame(h, w, H, W, r0, r1):\n",
    "        very_wide = w > 0.65 * W\n",
    "        very_thin = h < 0.12 * H\n",
    "        near_edge = r0 < 0.15 * H or r1 > 0.85 * H\n",
    "        return very_wide and very_thin and near_edge\n",
    "\n",
    "\n",
    "\n",
    "    lbl = label(mask)\n",
    "\n",
    "    candidates = []\n",
    "    for p in regionprops(lbl):\n",
    "        r0, c0, r1, c1 = p.bbox\n",
    "\n",
    "        if touches_top_or_bottom(r0, r1, H):\n",
    "            continue\n",
    "\n",
    "        h = r1 - r0\n",
    "        w = c1 - c0\n",
    "        area = p.area\n",
    "        wr = w / W\n",
    "        ar = area / (H * W)\n",
    "\n",
    "        if is_horizontal_frame(h, w, H, W, r0, r1):\n",
    "            continue\n",
    "\n",
    "        if wr < 0.035 or wr > 0.75:\n",
    "            continue\n",
    "\n",
    "        if ar < 0.001:\n",
    "            continue\n",
    "\n",
    "        candidates.append({\"bbox\": [r0, c0, r1, c1], \"area\": area})\n",
    "\n",
    "    candidates.sort(key=lambda c: c[\"bbox\"][1])\n",
    "\n",
    "\n",
    "    merged = []\n",
    "    for c in candidates:\n",
    "        if not merged:\n",
    "            merged.append(c)\n",
    "            continue\n",
    "\n",
    "        r0, c0, r1, c1 = c[\"bbox\"]\n",
    "        r0m, c0m, r1m, c1m = merged[-1][\"bbox\"]\n",
    "\n",
    "        overlap_x = min(c1, c1m) - max(c0, c0m)\n",
    "        overlap_y = min(r1, r1m) - max(r0, r0m)\n",
    "\n",
    "        #only merge if they overlap in X and Y or very close vertically\n",
    "        vertical_gap = max(r0, r0m) - min(r1, r1m) #negative means it overlaps\n",
    "\n",
    "        if overlap_x > 0 and (overlap_y > 0 or vertical_gap < 0.08 * H):\n",
    "            merged[-1][\"bbox\"] = [\n",
    "                min(r0, r0m), min(c0, c0m),\n",
    "                max(r1, r1m), max(c1, c1m)\n",
    "            ]\n",
    "        else:\n",
    "            merged.append(c)\n",
    "\n",
    "    boxed_mask = gray2rgb(mask.astype(np.uint8) * 255)\n",
    "\n",
    "    chars = []\n",
    "    for m in merged:\n",
    "        r0, c0, r1, c1 = m[\"bbox\"]\n",
    "        if (r1 - r0) < 0.22 * H:\n",
    "            continue\n",
    "\n",
    "        boxed_mask[r0:r1, [c0, c1-1]] = [255, 0, 0]\n",
    "        boxed_mask[[r0, r1-1], c0:c1] = [255, 0, 0]\n",
    "\n",
    "        crop = resize(mask[r0:r1, c0:c1].astype(float), (40, 40))\n",
    "        chars.append((c0 + bx, crop))\n",
    "\n",
    "    chars.sort(key=lambda x: x[0])\n",
    "\n",
    "    if debug:\n",
    "        return [c for _, c in chars][:max_chars], mask, boxed_mask\n",
    "    else:\n",
    "        return [c for _, c in chars][:max_chars]\n",
    "\n",
    "\n",
    "\n",
    "def extract_letters(letters_region, max_chars=3, debug=False):\n",
    "    H0, W0 = letters_region.shape[:2]\n",
    "    by = int(0.04 * H0)\n",
    "    bx = int(0.04 * W0)\n",
    "    sub = letters_region[by:H0 - by, bx:W0 - bx]\n",
    "\n",
    "    mask = get_mask(sub)\n",
    "    H, W = mask.shape\n",
    "    lbl = label(mask)\n",
    "\n",
    "    boxed_mask = gray2rgb(mask.astype(np.uint8) * 255)\n",
    "\n",
    "    big_blobs = []   #letter body\n",
    "    small_blobs = [] #dots\n",
    "\n",
    "\n",
    "    for p in regionprops(lbl):\n",
    "        r0, c0, r1, c1 = p.bbox\n",
    "\n",
    "        if touches_border(r0, c0, r1, c1, H, W, margin_ratio=0.02):\n",
    "            continue\n",
    "    \n",
    "        h = r1 - r0\n",
    "        w = c1 - c0\n",
    "        area = p.area\n",
    "        cy = p.centroid[0] / H\n",
    "        wr = w / W\n",
    "        ar = area / (H * W)\n",
    "\n",
    "        #dot (area < 0.015)\n",
    "        if ar < 0.015:\n",
    "            small_blobs.append((r0, c0, r1, c1))\n",
    "            continue\n",
    "\n",
    "        #main letter filtering\n",
    "        if wr < 0.08 or wr > 0.75:\n",
    "            continue\n",
    "        if ar > 0.22:\n",
    "            continue\n",
    "        if cy > 0.75:\n",
    "            continue\n",
    "\n",
    "        big_blobs.append([r0, c0, r1, c1])\n",
    "\n",
    "\n",
    "    for dr0, dc0, dr1, dc1 in small_blobs:\n",
    "        dc = (dc0 + dc1) / 2\n",
    "        dr = (dr0 + dr1) / 2\n",
    "\n",
    "        best_i = -1\n",
    "        best_dx = 1e9\n",
    "\n",
    "        for i, box in enumerate(big_blobs):\n",
    "            r0, c0, r1, c1 = box\n",
    "            bc = (c0 + c1) / 2\n",
    "            br = (r0 + r1) / 2\n",
    "\n",
    "            dx = abs(dc - bc)\n",
    "            dy = abs(dr - br)\n",
    "\n",
    "            #vertically and horizontally closest\n",
    "            if dx < best_dx and dy < 120:\n",
    "                best_dx = dx\n",
    "                best_i = i\n",
    "\n",
    "        #attach dot to nearest valid letter ONLY\n",
    "        if best_i != -1:\n",
    "            box = big_blobs[best_i]\n",
    "            box[0] = min(box[0], dr0)\n",
    "            box[1] = min(box[1], dc0)\n",
    "            box[2] = max(box[2], dr1)\n",
    "            box[3] = max(box[3], dc1)\n",
    "\n",
    "\n",
    "    big_blobs.sort(key=lambda b: b[1])\n",
    "\n",
    "\n",
    "    #new\n",
    "    # ---------- MERGE BROKEN LETTER BODIES (e.g. س) ----------\n",
    "    merged = []\n",
    "    for box in sorted(big_blobs, key=lambda b: b[1]):\n",
    "        if not merged:\n",
    "            merged.append(box)\n",
    "            continue\n",
    "\n",
    "        r0, c0, r1, c1 = box\n",
    "        pr0, pc0, pr1, pc1 = merged[-1]\n",
    "\n",
    "        # horizontal gap\n",
    "        gap = c0 - pc1\n",
    "\n",
    "        # vertical overlap\n",
    "        overlap = min(r1, pr1) - max(r0, pr0)\n",
    "\n",
    "        if gap < 0.15 * W and overlap > 0.3 * min(r1 - r0, pr1 - pr0):\n",
    "            # merge\n",
    "            merged[-1] = [\n",
    "                min(r0, pr0),\n",
    "                min(c0, pc0),\n",
    "                max(r1, pr1),\n",
    "                max(c1, pc1)\n",
    "            ]\n",
    "        else:\n",
    "            merged.append(box)\n",
    "\n",
    "    big_blobs = merged\n",
    "\n",
    "    #new\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    chars = []\n",
    "    for r0, c0, r1, c1 in big_blobs:\n",
    "        boxed_mask[r0:r1, [c0, c1-1]] = [255, 0, 0]\n",
    "        boxed_mask[[r0, r1-1], c0:c1] = [255, 0, 0]\n",
    "\n",
    "        crop = resize(mask[r0:r1, c0:c1].astype(float), (40, 40))\n",
    "        chars.append((c0 + bx, crop))\n",
    "\n",
    "    if debug:\n",
    "        return [c for _, c in chars][:max_chars], mask, boxed_mask\n",
    "    else:\n",
    "        return [c for _, c in chars][:max_chars]\n",
    "\n",
    "\n",
    "\n",
    "def process_plate(img):\n",
    "    bottom = crop_bottom(img)\n",
    "    digits_region, letters_region = split_digits_letters(bottom)\n",
    "\n",
    "    digits, d_mask, d_boxes = extract_digits(digits_region, debug=True)\n",
    "    letters, l_mask, l_boxes = extract_letters(letters_region, debug=True)\n",
    "\n",
    "    return digits_region, letters_region, digits, letters, d_mask, d_boxes, l_mask, l_boxes\n",
    "\n",
    "\n",
    "img22 = imread('Q1.jpg')\n",
    "#img22 = imread('Dataset/Buses & government vehicles.png')\n",
    "#img22 = imread('Dataset/Diplomatic vehicles.png')\n",
    "#img22 = imread('Dataset/image.png')\n",
    "#img22 = imread('Dataset/Limousines & tourist buses.png')\n",
    "#img22 = imread('Dataset/Police vehicles.png')\n",
    "# img22 = rgba2rgb(imread('Dataset/Private vehicles & motorcycles.png'))\n",
    "#img22 = rgba2rgb(imread('Dataset/Taxis.png'))\n",
    "#img22 = imread('Dataset/Trucks.png')\n",
    "#img22 = imread('Dataset/Vehicles with unpaid customs.png')\n",
    "\n",
    "#etsh cropped tests########################\n",
    "# img22 = cropped_Plate1\n",
    "# img22 = cropped_Plate2 #blur problem\n",
    "#img22 = rgba2rgb(imread('Q1C.png'))\n",
    "# img22 = cropped_Plate3 #blur problem\n",
    "# img22 = cropped_Plate5 #FIXED frame counting as letter from left\n",
    "# img22 = cropped_Plate11 #FIXED digit border on top detected  \n",
    "# img22 = cropped_Plate12 #FIXED border in digit detected\n",
    "# img22 = cropped_Plate13 #FIXED border detected as letter\n",
    "#img22 = cropped_Plate15 #blur problem\n",
    "#img22 = cropped_Plate111 ##\n",
    "#img22 = cropped_Plate112 #blur problem\n",
    "#img22 = cropped_Plate113 #blur problem\n",
    "#img22 = cropped_Plate115 ##\n",
    "#img22 = cropped_Plate1111 #hard angle\n",
    "#img22 = cropped_Plate1112 #hard angle\n",
    "#img22 = cropped_Plate1113 #blur problem\n",
    "#img22 = cropped_Plate1115 #blur\n",
    "#img22 = cropped_Plate11113 #blur\n",
    "#img22 = cropped_Plate11114 ##\n",
    "#img22 = cropped_Plate11115 ##\n",
    "#img22 = cropped_Plate11116 ##\n",
    "#img22 = cropped_Plate11117 ##\n",
    "\n",
    "#etsh cropped tests########################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "def clear_previous_outputs():\n",
    "    files = [\n",
    "        \"digit_0.png\", \"digit_1.png\", \"digit_2.png\", \"digit_3.png\", \"digit_4.png\", \"letter_0.png\", \"letter_1.png\", \"letter_2.png\"\n",
    "    ]\n",
    "\n",
    "    for f in files:\n",
    "        if os.path.exists(f):\n",
    "            os.remove(f)\n",
    "\n",
    "\n",
    "def save_characters(digits, letters):\n",
    "    #digits\n",
    "    for i, img in enumerate(digits):\n",
    "        out = (img * 255).astype(np.uint8) if img.dtype != np.uint8 else img\n",
    "        cv2.imwrite(f\"digit_{i}.png\", out)\n",
    "\n",
    "    #letters\n",
    "    for i, img in enumerate(letters):\n",
    "        out = (img * 255).astype(np.uint8) if img.dtype != np.uint8 else img\n",
    "        cv2.imwrite(f\"letter_{i}.png\", out)\n",
    "\n",
    "\n",
    "clear_previous_outputs()\n",
    "\n",
    "d_reg, l_reg, digits, letters, d_mask, d_boxes, l_mask, l_boxes = process_plate(img22)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "show_images([d_reg, l_reg], [\"Digits Region\", \"Letters Region\"])\n",
    "\n",
    "show_images([d_mask, l_mask], [\"Digits Mask\", \"Letters Mask\"])\n",
    "\n",
    "show_images([d_boxes, l_boxes], [\"Digits Mask + Boxes\", \"Letters Mask + Boxes\"])\n",
    "\n",
    "digit_titles = [f\"Digit {i}\" for i in range(len(digits))]\n",
    "show_images(digits, digit_titles)\n",
    "\n",
    "letter_titles = [f\"Letter {i}\" for i in range(len(letters))]\n",
    "show_images(letters, letter_titles)\n",
    "\n",
    "\n",
    "save_characters(digits,letters)\n",
    "\n",
    "\n",
    "#RUN LOOP\n",
    "\n",
    "for i in range(1, 40):\n",
    "    img = globals()[f\"cropped_Plate{i}\"]\n",
    "\n",
    "    (\n",
    "        d_reg, l_reg,\n",
    "        digits, letters,\n",
    "        d_mask, d_boxes,\n",
    "        l_mask, l_boxes\n",
    "    ) = process_plate(img)\n",
    "\n",
    "    show_images([d_reg, l_reg], [\"Digits Region\", \"Letters Region\"])\n",
    "    show_images([d_mask, l_mask], [\"Digits Mask\", \"Letters Mask\"])\n",
    "    show_images([d_boxes, l_boxes], [\"Digits Mask + Boxes\", \"Letters Mask + Boxes\"])\n",
    "\n",
    "    digit_titles = [f\"Digit {j}\" for j in range(len(digits))]\n",
    "    show_images(digits, digit_titles)\n",
    "\n",
    "    letter_titles = [f\"Letter {j}\" for j in range(len(letters))]\n",
    "    show_images(letters, letter_titles)\n",
    "\n",
    "\n",
    "#RUN LOOP\n",
    "\n",
    "\n",
    "'''\n",
    "'''\n",
    "MAAW SEGMENTATION\n",
    "'''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf60faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MAAW DIGIT AND LETTER RECOGNITION\n",
    "'''\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import os\n",
    "\n",
    "\n",
    "english_to_arabic = {\n",
    "    1: '١',\n",
    "    2: '٢',\n",
    "    3: '٣',\n",
    "    4: '٤',\n",
    "    5: '٥',\n",
    "    6: '٦',\n",
    "    7: '٧',\n",
    "    8: '٨',\n",
    "    9: '٩'\n",
    "    }\n",
    "\n",
    "\n",
    "def normalize_digit(img):\n",
    "    img = img.copy()\n",
    "\n",
    "    if np.mean(img) > 127:\n",
    "        img = cv2.bitwise_not(img)\n",
    "\n",
    "    ys, xs = np.where(img > 0)\n",
    "    if len(xs) == 0:\n",
    "        return cv2.resize(img, (64, 64))\n",
    "\n",
    "    x0, x1 = xs.min(), xs.max()\n",
    "    y0, y1 = ys.min(), ys.max()\n",
    "    img = img[y0:y1+1, x0:x1+1]\n",
    "\n",
    "    img = cv2.copyMakeBorder(img, 12, 12, 12, 12, cv2.BORDER_CONSTANT, value=0)\n",
    "\n",
    "    img = cv2.resize(img, (64, 64), interpolation=cv2.INTER_NEAREST)\n",
    "    return img.astype(np.uint8)\n",
    "\n",
    "\n",
    "def match_digit(img, refs_folder=\"digits_reference\"):\n",
    "    img = normalize_digit(img)\n",
    "\n",
    "    scores = {}\n",
    "\n",
    "    for d in range(1,10):\n",
    "        digit_folder = os.path.join(refs_folder, str(d))\n",
    "        if not os.path.exists(digit_folder):\n",
    "            continue\n",
    "\n",
    "        best_local = -1\n",
    "\n",
    "        for fname in os.listdir(digit_folder):\n",
    "            ref = cv2.imread(os.path.join(digit_folder, fname), 0)\n",
    "            ref = normalize_digit(ref)\n",
    "\n",
    "            score = ssim(img, ref)\n",
    "            best_local = max(best_local, score)\n",
    "\n",
    "        scores[d] = best_local\n",
    "\n",
    "    best_digit = max(scores, key=scores.get)\n",
    "\n",
    "    return best_digit\n",
    "\n",
    "final_digits_english = []\n",
    "final_digits_arabic  = []\n",
    "\n",
    "for d in digits:\n",
    "    d_img = d.astype(np.uint8) \n",
    "    digit = match_digit(d_img)\n",
    "\n",
    "    final_digits_english.append(str(digit))\n",
    "    final_digits_arabic.append(english_to_arabic[digit])\n",
    "\n",
    "print(\"Plate Digits In English:\", \"\".join(final_digits_english))\n",
    "print(\"Plate Digits In Arabic: \", \"\".join(final_digits_arabic))\n",
    "\n",
    "\n",
    "\n",
    "letter_id_to_arabic = {\n",
    "    1: 'أ',\n",
    "    2: 'ب',\n",
    "    3: 'ج',\n",
    "    4: 'د',\n",
    "    5: 'ر',\n",
    "    6: 'ز',\n",
    "    7: 'س',\n",
    "    8: 'ص',\n",
    "    9: 'ض',\n",
    "    10: 'ط',\n",
    "    11: 'ع',\n",
    "    12: 'ف',\n",
    "    13: 'ق',\n",
    "    14: 'ك',\n",
    "    15: 'ل',\n",
    "    16: 'م',\n",
    "    17: 'ن',\n",
    "    18: 'ه',\n",
    "    19: 'و',\n",
    "    20: 'ي',\n",
    "    21: 'ى'\n",
    "}\n",
    "\n",
    "\n",
    "def normalize_letter(img):\n",
    "    img = img.copy()\n",
    "\n",
    "    if np.mean(img) > 127:\n",
    "        img = cv2.bitwise_not(img)\n",
    "\n",
    "    ys, xs = np.where(img > 0)\n",
    "    if len(xs) == 0:\n",
    "        return cv2.resize(img, (64, 64))\n",
    "\n",
    "    x0, x1 = xs.min(), xs.max()\n",
    "    y0, y1 = ys.min(), ys.max()\n",
    "    img = img[y0:y1+1, x0:x1+1]\n",
    "\n",
    "    img = cv2.copyMakeBorder(\n",
    "        img, 12, 12, 12, 12,\n",
    "        cv2.BORDER_CONSTANT, value=0\n",
    "    )\n",
    "\n",
    "    img = cv2.resize(img, (64, 64), interpolation=cv2.INTER_NEAREST)\n",
    "    return img.astype(np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "def match_letter(img, refs_folder=\"letters_reference\"):\n",
    "    img = normalize_letter(img)\n",
    "\n",
    "    scores = {}\n",
    "\n",
    "    for letter_id in range(1, 22):\n",
    "        letter_folder = os.path.join(refs_folder, str(letter_id))\n",
    "        if not os.path.exists(letter_folder):\n",
    "            continue\n",
    "\n",
    "        best_local = -1\n",
    "\n",
    "        for fname in os.listdir(letter_folder):\n",
    "            ref = cv2.imread(os.path.join(letter_folder, fname), 0)\n",
    "            if ref is None:\n",
    "                continue\n",
    "\n",
    "            ref = normalize_letter(ref)\n",
    "            score = ssim(img, ref)\n",
    "            best_local = max(best_local, score)\n",
    "\n",
    "        scores[letter_id] = best_local\n",
    "\n",
    "    best_letter_id = max(scores, key=scores.get)\n",
    "    return best_letter_id\n",
    "\n",
    "\n",
    "final_letters_arabic = []\n",
    "\n",
    "for l in letters:\n",
    "    l_img = l.astype(np.uint8)   \n",
    "    letter_id = match_letter(l_img)\n",
    "\n",
    "\n",
    "    final_letters_arabic.append(letter_id_to_arabic[letter_id])\n",
    "\n",
    "final_plate_letters = \" \".join(final_letters_arabic[::-1])\n",
    "\n",
    "print(\"Plate Letters: \", final_plate_letters)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "MAAW DIGIT AND LETTER RECOGNITION\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4522eea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import easyocr\n",
    "os.environ['TESSDATA_PREFIX'] = os.path.abspath(\"Dataset\")\n",
    "# os.environ.pop('TESSDATA_PREFIX', None)\n",
    "def add_padding(img, pad=10):\n",
    "    return cv2.copyMakeBorder(\n",
    "        img, pad, pad, pad, pad,\n",
    "        borderType=cv2.BORDER_CONSTANT,\n",
    "        value=255\n",
    "    )\n",
    "\n",
    "def add_paddingblack(img, pad=50):\n",
    "    return cv2.copyMakeBorder(\n",
    "        img, pad, pad, pad, pad,\n",
    "        borderType=cv2.BORDER_CONSTANT,\n",
    "        value=0\n",
    "    )\n",
    "\n",
    "\n",
    "def pad_for_easyocr(img):\n",
    "    h, w = img.shape\n",
    "    new_img = np.zeros((h, w*3), dtype=np.uint8)  # black background\n",
    "    new_img[:, w:w*2] = img  # center the character\n",
    "    return new_img\n",
    "\n",
    "\n",
    "def recognize_arabic_digit(image_path, show_preprocessed=False):\n",
    "    \"\"\"\n",
    "    Recognize a single Arabic digit from an image.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to image file.\n",
    "        show_preprocessed (bool): If True, shows the binary preprocessed image.\n",
    "    \n",
    "    Returns:\n",
    "        str: Detected Arabic digit or empty string if not recognized.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Load image\n",
    "    img = io.imread(image_path)\n",
    "    # img=add_paddingblack(img)\n",
    "    # img=pad_for_easyocr(img)\n",
    "    \n",
    "    # img=add_padding(img)\n",
    "    # img=d_mask\n",
    "    if img.dtype == bool:\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "\n",
    "    # # Ensure grayscale, not weird format\n",
    "    # if len(img.shape) == 2:\n",
    "    #     img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    # # 2. Convert to grayscale if needed\n",
    "    # gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img\n",
    "    \n",
    "    # # 3. Resize image up to help OCR\n",
    "    # gray = cv2.resize(gray, None, fx=5, fy=5, interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    # # 4. Smooth image to reduce noise\n",
    "    # blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "    \n",
    "    # # 5. Threshold to get binary image\n",
    "    # _, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # # 6. Invert if background is dark\n",
    "    # if np.mean(thresh) < 127:\n",
    "    #     thresh = cv2.bitwise_not(thresh)\n",
    "    \n",
    "    # # Optional: show preprocessed image\n",
    "    if show_preprocessed:\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    # 7. Configure Tesseract for single character + Arabic digits only\n",
    "    # config = f'--oem 3 --psm 10 -c tessedit_char_whitelist={ARABIC_DIGITS}'\n",
    "    \n",
    "    # 8. Run OCR\n",
    "    # text = pytesseract.image_to_string(thresh, lang='ara')\n",
    "\n",
    "    reader = easyocr.Reader(['ar'])\n",
    "    results = reader.readtext(img)\n",
    "    texts = [text for bbox, text, prob in results]\n",
    "\n",
    "\n",
    "    # 9. Clean result\n",
    "    # text = text.strip()\n",
    "    return texts\n",
    "\n",
    "# Example usage:\n",
    "digit = recognize_arabic_digit(\"letter_0.png\", show_preprocessed=True)\n",
    "print(\"Detected Arabic digit EASYOCR:\", repr(digit))\n",
    "# print(\"Detected Arabic digit:\", repr(digit))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f5b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "reader = easyocr.Reader(['ar'], gpu=False)  # make this global or at module level\n",
    "\n",
    "def prepare_for_easyocr_char(img):\n",
    "    \"\"\"\n",
    "    img: numpy array (grayscale or RGB) containing ONE character.\n",
    "    Returns a padded, upscaled image suitable for EasyOCR.\n",
    "    \"\"\"\n",
    "\n",
    "    # If bool -> uint8\n",
    "    if img.dtype == bool:\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    if img.ndim == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        img = img.astype(np.uint8)\n",
    "\n",
    "    # Normalize range\n",
    "    if img.max() <= 1:\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "\n",
    "    # Binarize a bit to stabilize\n",
    "    _, img = cv2.threshold(img, 0, 255,\n",
    "                           cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Make sure text is dark on light (helps EasyOCR)\n",
    "    if img.mean() < 127:      # mostly dark => likely white on black\n",
    "        img = 255 - img       # invert to black text on white\n",
    "\n",
    "    # ---- FIX #1: add margin so glyph doesn't touch borders ----\n",
    "    border = 20\n",
    "    img = cv2.copyMakeBorder(\n",
    "        img, border, border, border, border,\n",
    "        borderType=cv2.BORDER_CONSTANT,\n",
    "        value=255  # white background\n",
    "    )\n",
    "\n",
    "    # ---- FIX #2: upscale ----\n",
    "    img = cv2.resize(img, None, fx=5, fy=5,\n",
    "                     interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def recognize_single_char_easyocr(image_path, show=False):\n",
    "    # load from file\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    prep = prepare_for_easyocr_char(img)\n",
    "\n",
    "    if show:\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.imshow(prep, cmap='gray')\n",
    "        plt.axis('off'); plt.show()\n",
    "\n",
    "    # detail=0 -> just texts; paragraph=False so it doesn't merge things\n",
    "    texts = reader.readtext(prep, detail=0, paragraph=False)\n",
    "\n",
    "    return texts[0] if texts else \"\"\n",
    "\n",
    "digit0 = recognize_single_char_easyocr(\"clean_digits.png\", show=True)\n",
    "letter0 = recognize_single_char_easyocr(\"clean_letters.png\", show=True)\n",
    "print(\"digit_0:\", repr(digit0))\n",
    "print(\"letter_0:\", repr(letter0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cddadb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MAAW FORTNITE BATTLE ROYALE\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2                         ### <<< you were using cv2 in save_characters\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray, rgba2rgb\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.morphology import (\n",
    "    remove_small_holes,\n",
    "    remove_small_objects,\n",
    "    binary_closing,\n",
    "    square,\n",
    ")\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.transform import resize\n",
    "from skimage.color import gray2rgb\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 1) SIMPLE GEOMETRIC UTILITIES\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def crop_bottom(img, top_ratio=0.40):\n",
    "    \"\"\"\n",
    "    Keep the lower part of the plate (digits + letters).\n",
    "    top_ratio is the fraction of height we cut from the top.\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    return img[int(h * top_ratio):, :]\n",
    "\n",
    "\n",
    "def split_digits_letters(bottom):\n",
    "    \"\"\"\n",
    "    Egyptian plate: digits on the left half, letters on the right half.\n",
    "    \"\"\"\n",
    "    h, w = bottom.shape[:2]\n",
    "    mid = w // 2\n",
    "    return bottom[:, :mid], bottom[:, mid:]\n",
    "\n",
    "\n",
    "def get_mask(region):\n",
    "    gray = rgb2gray(region)\n",
    "    T = threshold_otsu(gray)\n",
    "    mask = gray < T\n",
    "\n",
    "    # ✅ KEEP holes & dots (light cleaning only)\n",
    "    mask = remove_small_objects(mask, 25)\n",
    "    return mask\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Helper: create a crop that is friendly for OCR\n",
    "# ---------------------------------------------------\n",
    "def make_ocr_char_crop(gray_sub, r0, c0, r1, c1,\n",
    "                       pad=3, scale=3):\n",
    "    \"\"\"\n",
    "    gray_sub : grayscale version of sub-image (0–1)\n",
    "    (r0,c0,r1,c1) : bbox in sub coordinates\n",
    "    pad : extra pixels around character\n",
    "    scale : upscaling factor (so text is not tiny)\n",
    "    \"\"\"\n",
    "    H, W = gray_sub.shape\n",
    "\n",
    "    rr0 = max(r0 - pad, 0)\n",
    "    cc0 = max(c0 - pad, 0)\n",
    "    rr1 = min(r1 + pad, H)\n",
    "    cc1 = min(c1 + pad, W)\n",
    "\n",
    "    crop = gray_sub[rr0:rr1, cc0:cc1]        # 0–1 float from rgb2gray\n",
    "\n",
    "    # upscale (don’t DOWNsize to 40×40)\n",
    "    h, w = crop.shape\n",
    "    crop = resize(crop, (int(h * scale), int(w * scale)),\n",
    "                  anti_aliasing=True)\n",
    "\n",
    "    return crop   # still float 0–1\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2) DIGITS EXTRACTION\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def touches_border(r0, c0, r1, c1, H, W, margin_ratio=0.005):\n",
    "    mr = int(margin_ratio * H)\n",
    "    mc = int(margin_ratio * W)\n",
    "\n",
    "    if r0 <= mr: return True        # top\n",
    "    if c0 <= mc: return True        # left\n",
    "    if r1 >= H - mr: return True    # bottom\n",
    "    if c1 >= W - mc: return True    # right\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def extract_digits(digits_region, max_chars=4, debug=False):\n",
    "    H0, W0 = digits_region.shape[:2]\n",
    "    border_ratio = 0.04\n",
    "    by = int(border_ratio * H0)\n",
    "    bx = int(border_ratio * W0)\n",
    "    sub = digits_region[by:H0 - by, bx:W0 - bx]\n",
    "\n",
    "    # segmentation is done on mask\n",
    "    mask = get_mask(sub)\n",
    "    gray_sub = rgb2gray(sub)          ### <<< NEW: grayscale for OCR crops\n",
    "    H, W = mask.shape\n",
    "\n",
    "    lbl = label(mask)\n",
    "\n",
    "    candidates = []\n",
    "    for p in regionprops(lbl):\n",
    "        r0, c0, r1, c1 = p.bbox\n",
    "\n",
    "        touches = touches_border(r0, c0, r1, c1, H, W, margin_ratio=0.01)\n",
    "        if touches:\n",
    "            h = r1 - r0\n",
    "            w = c1 - c0\n",
    "            ar = p.area / (H * W)\n",
    "            # ✅ only reject if it looks like a FRAME, not a digit\n",
    "            if h > 0.9 * H or w < 0.02 * W or ar < 0.002:\n",
    "                continue\n",
    "\n",
    "        h = r1 - r0\n",
    "        w = c1 - c0\n",
    "        area = p.area\n",
    "        wr = w / W\n",
    "        ar = area / (H * W)\n",
    "\n",
    "        if wr < 0.035 or wr > 0.75:\n",
    "            continue\n",
    "        if ar < 0.001:\n",
    "            continue\n",
    "\n",
    "        candidates.append({\"bbox\": [r0, c0, r1, c1], \"area\": area})\n",
    "\n",
    "    # sort left → right\n",
    "    candidates.sort(key=lambda c: c[\"bbox\"][1])\n",
    "\n",
    "    # merge overlapping boxes\n",
    "    merged = []\n",
    "    for c in candidates:\n",
    "        if not merged:\n",
    "            merged.append(c)\n",
    "            continue\n",
    "\n",
    "        r0, c0, r1, c1 = c[\"bbox\"]\n",
    "        r0m, c0m, r1m, c1m = merged[-1][\"bbox\"]\n",
    "        overlap_x = min(c1, c1m) - max(c0, c0m)\n",
    "\n",
    "        if overlap_x > 0:\n",
    "            merged[-1][\"bbox\"] = [\n",
    "                min(r0, r0m), min(c0, c0m),\n",
    "                max(r1, r1m), max(c1, c1m)\n",
    "            ]\n",
    "        else:\n",
    "            merged.append(c)\n",
    "\n",
    "    boxed_mask = gray2rgb(mask.astype(np.uint8) * 255)\n",
    "\n",
    "    chars = []\n",
    "    for m in merged:\n",
    "        r0, c0, r1, c1 = m[\"bbox\"]\n",
    "        if (r1 - r0) < 0.22 * H:\n",
    "            continue\n",
    "\n",
    "        # draw box for debug\n",
    "        boxed_mask[r0:r1, [c0, c1-1]] = [255, 0, 0]\n",
    "        boxed_mask[[r0, r1-1], c0:c1] = [255, 0, 0]\n",
    "\n",
    "        # <<< OLD:\n",
    "        # crop = resize(mask[r0:r1, c0:c1].astype(float), (40, 40))\n",
    "        # chars.append((c0 + bx, crop))\n",
    "\n",
    "        # >>> NEW: OCR-friendly grayscale crop with padding + upscaling\n",
    "        crop = make_ocr_char_crop(gray_sub, r0, c0, r1, c1,\n",
    "                                  pad=3, scale=3)\n",
    "        chars.append((c0 + bx, crop))\n",
    "\n",
    "    chars.sort(key=lambda x: x[0])\n",
    "\n",
    "    if debug:\n",
    "        return [c for _, c in chars][:max_chars], mask, boxed_mask\n",
    "    else:\n",
    "        return [c for _, c in chars][:max_chars]\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 3) LETTERS EXTRACTION\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def extract_letters(letters_region, max_chars=3, debug=False):\n",
    "    H0, W0 = letters_region.shape[:2]\n",
    "    by = int(0.04 * H0)\n",
    "    bx = int(0.04 * W0)\n",
    "    sub = letters_region[by:H0 - by, bx:W0 - bx]\n",
    "\n",
    "    mask = get_mask(sub)\n",
    "    gray_sub = rgb2gray(sub)            ### <<< NEW: grayscale for OCR crops\n",
    "    H, W = mask.shape\n",
    "    lbl = label(mask)\n",
    "\n",
    "    boxed_mask = gray2rgb(mask.astype(np.uint8) * 255)\n",
    "\n",
    "    big_blobs = []   # main letter bodies\n",
    "    small_blobs = [] # dots\n",
    "\n",
    "    # -----------------------------\n",
    "    # 1) SPLIT BIG BLOBS & DOTS\n",
    "    # -----------------------------\n",
    "    for p in regionprops(lbl):\n",
    "        r0, c0, r1, c1 = p.bbox\n",
    "\n",
    "        if touches_border(r0, c0, r1, c1, H, W, margin_ratio=0.02):\n",
    "            continue\n",
    "\n",
    "        h = r1 - r0\n",
    "        w = c1 - c0\n",
    "        area = p.area\n",
    "        cy = p.centroid[0] / H\n",
    "        wr = w / W\n",
    "        ar = area / (H * W)\n",
    "\n",
    "        # 👉 DOT = any small area < 0.015\n",
    "        if ar < 0.015:\n",
    "            small_blobs.append((r0, c0, r1, c1))\n",
    "            continue\n",
    "\n",
    "        # 👉 MAIN LETTER FILTER (no lower area limit now)\n",
    "        if wr < 0.08 or wr > 0.75:\n",
    "            continue\n",
    "        if ar > 0.22:\n",
    "            continue\n",
    "        if cy > 0.75:\n",
    "            continue\n",
    "\n",
    "        big_blobs.append([r0, c0, r1, c1])\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # 2) ATTACH EACH DOT TO NEAREST LETTER BOX\n",
    "    # -----------------------------------------\n",
    "    for dr0, dc0, dr1, dc1 in small_blobs:\n",
    "        dc = (dc0 + dc1) / 2\n",
    "        dr = (dr0 + dr1) / 2\n",
    "\n",
    "        best_i = -1\n",
    "        best_dx = 1e9\n",
    "\n",
    "        for i, box in enumerate(big_blobs):\n",
    "            r0, c0, r1, c1 = box\n",
    "            bc = (c0 + c1) / 2\n",
    "            br = (r0 + r1) / 2\n",
    "\n",
    "            dx = abs(dc - bc)\n",
    "            dy = abs(dr - br)\n",
    "\n",
    "            # ✅ must be vertically close AND horizontally closest\n",
    "            if dx < best_dx and dy < 120:\n",
    "                best_dx = dx\n",
    "                best_i = i\n",
    "\n",
    "        # ✅ attach dot ONLY to the nearest valid letter\n",
    "        if best_i != -1:\n",
    "            box = big_blobs[best_i]\n",
    "            box[0] = min(box[0], dr0)\n",
    "            box[1] = min(box[1], dc0)\n",
    "            box[2] = max(box[2], dr1)\n",
    "            box[3] = max(box[3], dc1)\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # 3) SORT & CROP FINAL LETTERS\n",
    "    # -----------------------------------------\n",
    "    big_blobs.sort(key=lambda b: b[1])\n",
    "\n",
    "    chars = []\n",
    "    for r0, c0, r1, c1 in big_blobs:\n",
    "        boxed_mask[r0:r1, [c0, c1-1]] = [255, 0, 0]\n",
    "        boxed_mask[[r0, r1-1], c0:c1] = [255, 0, 0]\n",
    "\n",
    "        # <<< OLD:\n",
    "        # crop = resize(mask[r0:r1, c0:c1].astype(float), (40, 40))\n",
    "        # chars.append((c0 + bx, crop))\n",
    "\n",
    "        # >>> NEW: grayscale + padding + upscaling\n",
    "        crop = make_ocr_char_crop(gray_sub, r0, c0, r1, c1,\n",
    "                                  pad=3, scale=3)\n",
    "        chars.append((c0 + bx, crop))\n",
    "\n",
    "    if debug:\n",
    "        return [c for _, c in chars][:max_chars], mask, boxed_mask\n",
    "    else:\n",
    "        return [c for _, c in chars][:max_chars]\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4) FULL PIPELINE FOR ONE IMAGE\n",
    "# ---------------------------------------------------\n",
    "def process_plate(img):\n",
    "    bottom = crop_bottom(img)\n",
    "    digits_region, letters_region = split_digits_letters(bottom)\n",
    "\n",
    "    digits, d_mask, d_boxes = extract_digits(digits_region, debug=True)\n",
    "    letters, l_mask, l_boxes = extract_letters(letters_region, debug=True)\n",
    "\n",
    "    return digits_region, letters_region, digits, letters, d_mask, d_boxes, l_mask, l_boxes\n",
    "\n",
    "\n",
    "# Choose your plate image\n",
    "img22 = imread('Dataset/Limousines & tourist buses.png')\n",
    "\n",
    "def save_characters(digits, letters):\n",
    "    # digits / letters are floats 0–1 → uint8 0–255\n",
    "    for i, img in enumerate(digits):\n",
    "        out = (img * 255).astype(np.uint8)\n",
    "        cv2.imwrite(f\"digit_{i}.png\", out)\n",
    "\n",
    "    for i, img in enumerate(letters):\n",
    "        out = (img * 255).astype(np.uint8)\n",
    "        cv2.imwrite(f\"letter_{i}.png\", out)\n",
    "\n",
    "\n",
    "d_reg, l_reg, digits, letters, d_mask, d_boxes, l_mask, l_boxes = process_plate(img22)\n",
    "\n",
    "# (show_images assumed defined elsewhere)\n",
    "show_images([d_reg, l_reg], [\"Digits Region\", \"Letters Region\"])\n",
    "show_images([d_mask, l_mask], [\"Digits Mask\", \"Letters Mask\"])\n",
    "show_images([d_boxes, l_boxes], [\"Digits Mask + Boxes\", \"Letters Mask + Boxes\"])\n",
    "\n",
    "digit_titles = [f\"Digit {i}\" for i in range(len(digits))]\n",
    "show_images(digits, digit_titles)\n",
    "\n",
    "letter_titles = [f\"Letter {i}\" for i in range(len(letters))]\n",
    "show_images(letters, letter_titles)\n",
    "\n",
    "save_characters(digits, letters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a88c53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
